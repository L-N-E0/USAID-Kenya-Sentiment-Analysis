{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47578532",
   "metadata": {},
   "source": [
    "# Data Collection Experimentation\n",
    "- The announcement of the USAID funding cuts was made on March 28, 2025\n",
    "## 1. Environments\n",
    "- tweepy, PRAW requests (pip install)\n",
    "\n",
    "## 2. Reddit Data collection\n",
    "- Create connection with Reddit: [link to create script->(https://www.reddit.com/prefs/apps)](https://www.reddit.com/prefs/apps)\n",
    "- Get `client_id`, `client_secret`\n",
    "```\n",
    "reddit = praw.Reddit(\n",
    "    client_id='tWd763iMgmjp8YamFF96Wg',\n",
    "    client_secret='\tXmaO9oO_kioW-8DzCLipxz-A4hffSA',\n",
    "    user_agent='usaid-sentiment-KE'\n",
    ")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277dd337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching r/Kenya...\n",
      "Searching r/EastAfrica...\n",
      "‚úÖ Scraped 24 posts. Saved to ../data/raw/leo_reddit_posts.csv'.\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id='tWd763iMgmjp8YamFF96Wg',\n",
    "    client_secret='XmaO9oO_kioW-8DzCLipxz-A4hffSA',\n",
    "    user_agent='usaid-sentiment-KE'\n",
    ")\n",
    "\n",
    "# --- PARAMETERS ---\n",
    "subreddits = ['Kenya', 'EastAfrica']\n",
    "\n",
    "\"\"\"keywords = [\n",
    "    \"USAID\", \"usaid\", \n",
    "    \"foreign aid\", \"foreign assistance\", \n",
    "    \"donor\", \"donour\", \n",
    "    \"funding\", \"funds\", \n",
    "    \"budget cuts\", \"aid cuts\", \n",
    "    \"development aid\", \n",
    "    \"healthcare\", \"health care\", \n",
    "    \"NGOs\", \"nonprofits\", \"non-profits\"\n",
    "]\"\"\"\n",
    "\n",
    "\n",
    "keywords = [\n",
    "    \"USAID\", \"usaid\", \n",
    "    \"foreign aid\", \"foreign funding\"  \n",
    "]\n",
    "\n",
    "# Combine keywords and phrases\n",
    "search_terms = keywords\n",
    "\n",
    "# Earliest date (after funding cuts) ‚Üí March 28, 2025\n",
    "cutoff_date = datetime(2025, 3, 28, tzinfo=timezone.utc).timestamp()\n",
    "\n",
    "# --- SCRAPING ---\n",
    "data = []\n",
    "\n",
    "for sub in subreddits:\n",
    "    subreddit = reddit.subreddit(sub)\n",
    "    print(f\"Searching r/{sub}...\")\n",
    "    \n",
    "    for term in search_terms:\n",
    "        try:\n",
    "            for post in subreddit.search(term, sort='new', limit=200):\n",
    "                if post.created_utc < cutoff_date:\n",
    "                    continue  # skip posts before March 28, 2025\n",
    "                \n",
    "                data.append({\n",
    "                    'subreddit': sub,\n",
    "                    'search_term': term,\n",
    "                    'title': post.title,\n",
    "                    'text': post.selftext,\n",
    "                    'created_utc': post.created_utc,\n",
    "                    'created_date': datetime.fromtimestamp(post.created_utc),\n",
    "                    'score': post.score,\n",
    "                    'num_comments': post.num_comments,\n",
    "                    'permalink': f\"https://reddit.com{post.permalink}\",\n",
    "                    'url': post.url\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Error searching term '{term}' in r/{sub}: {e}\")\n",
    "\n",
    "# --- SAVE TO CSV ---\n",
    "df = pd.DataFrame(data)\n",
    "df['created_date'] = pd.to_datetime(df['created_utc'], unit='s')\n",
    "df.to_csv('../data/raw/leo_reddit_posts.csv', index=False)\n",
    "\n",
    "print(f\" Scraped {len(df)} posts. Saved to ../data/raw/leo_reddit_posts.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3267d53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Searching r/Kenya with base keywords...\n",
      "üîé Searching r/EastAfrica with base keywords...\n",
      "üîé Searching r/worldnews with 'Kenya' + keyword...\n",
      "üîé Searching r/InternationalDev with 'Kenya' + keyword...\n",
      "üîé Searching r/globalhealth with 'Kenya' + keyword...\n",
      "üîé Searching r/AskAfrica with 'Kenya' + keyword...\n",
      "üîé Searching r/development with 'Kenya' + keyword...\n",
      "‚úÖ Scraped 151 posts. Saved to ../data/raw/leo_reddit_posts.csv\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# --- AUTHENTICATION ---\n",
    "reddit = praw.Reddit(\n",
    "    client_id='tWd763iMgmjp8YamFF96Wg',\n",
    "    client_secret='XmaO9oO_kioW-8DzCLipxz-A4hffSA',\n",
    "    user_agent='usaid-sentiment-KE'\n",
    ")\n",
    "\n",
    "# --- SUBREDDITS ---\n",
    "# Local & regional subreddits vs global/sectoral ones\n",
    "local_subreddits = ['Kenya', 'EastAfrica']\n",
    "broad_subreddits = [\n",
    "    'worldnews',\n",
    "    'InternationalDev',\n",
    "    'globalhealth',\n",
    "    'AskAfrica',\n",
    "    'development'\n",
    "]\n",
    "\n",
    "# --- KEYWORDS ---\n",
    "base_keywords = [\n",
    "    \"USAID\", \"usaid\", \n",
    "    \"foreign aid\", \"foreign funding\",\n",
    "    \"donor\", \"donour\",\n",
    "    \"development aid\",\n",
    "    \"budget cuts\", \"aid cut\"\n",
    "]\n",
    "additional_keywords = [\n",
    "    \"PEPFAR\", \"Feed the Future\", \"Tusome\", \"Power Africa\",\n",
    "    \"USAID Kenya\", \"USAID education\", \"USAID health\",\n",
    "    \"nutrition assistance\", \"malaria program\", \"HIV funding\",\n",
    "    \"Kenya Crops and Dairy\", \"WASH Kenya\", \"USAID climate\",\n",
    "    \"USAID governance\", \"USAID transparency\",\"HIV USAID\"\n",
    "    \"resilience programs\", \"USAID devolution\", \"Youth program\"\n",
    "]\n",
    "usaid_programs_keywords = [# searching through USAID- funded projects\n",
    "    \"USAID\",\n",
    "    \"foreign aid\",\n",
    "    \"aid cuts\",\n",
    "    \"Trump aid cuts\",\n",
    "    \"USAID funding\",\n",
    "    \"project shutdown\",\n",
    "    \"development funding\",\n",
    "    \"NGO funding\",\n",
    "    \"foreign assistance\",\n",
    "    \"terminated projects\",\n",
    "    \"EECA\",\n",
    "    \"RTI\",\n",
    "    \"KPLP\",\n",
    "    \"SoCha\",\n",
    "    \"ABT\",\n",
    "    \"Prosper Africa USAID\",\n",
    "    \"BCG\",\n",
    "    \"IDG\",\n",
    "    \"KHPQS\",\n",
    "    \"OVC\",\n",
    "    \"Tujitegemee\",\n",
    "    \"Tujenge Jamii\",\n",
    "    \"supply chain USAID\",\n",
    "    \"PMI Evolve\",\n",
    "    \"sanitation project USAID\",\n",
    "    \"community resilience USAID\",\n",
    "    \"Owod project\",\n",
    "    \"nutrition program USAID\",\n",
    "    \"resilience project USAID\",\n",
    "    \"digital transformation USAID\",\n",
    "    \"Africa Water Facility\",\n",
    "    \"trade reforms USAID\",\n",
    "    \"solar health USAID\",\n",
    "    \"elections grant USAID\"\n",
    "]\n",
    "\n",
    "base_keywords.extend(additional_keywords)\n",
    "base_keywords.extend(usaid_programs_keywords)\n",
    "\n",
    "\n",
    "# --- CUTOFF DATE ---\n",
    "# Posts must be after USAID budget announcement ‚Äî March 28, 2025\n",
    "cutoff_date = datetime(2025, 3, 28, tzinfo=timezone.utc).timestamp()\n",
    "\n",
    "# --- SCRAPING START ---\n",
    "data = []\n",
    "\n",
    "# 1. Scrape local/regional subreddits with normal keywords\n",
    "for sub in local_subreddits:\n",
    "    subreddit = reddit.subreddit(sub)\n",
    "    print(f\"üîé Searching r/{sub} with base keywords...\")\n",
    "\n",
    "    for term in base_keywords:\n",
    "        try:\n",
    "            for post in subreddit.search(term, sort='new', limit=200):\n",
    "                if post.created_utc < cutoff_date:\n",
    "                    continue  # Skip older posts\n",
    "\n",
    "                data.append({\n",
    "                    'subreddit': sub,\n",
    "                    'search_term': term,\n",
    "                    'title': post.title,\n",
    "                    'text': post.selftext,\n",
    "                    'created_utc': post.created_utc,\n",
    "                    'created_date': datetime.fromtimestamp(post.created_utc),\n",
    "                    'score': post.score,\n",
    "                    'num_comments': post.num_comments,\n",
    "                    'permalink': f\"https://reddit.com{post.permalink}\",\n",
    "                    'url': post.url\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error searching term '{term}' in r/{sub}: {e}\")\n",
    "\n",
    "# 2. Scrape broader subreddits ‚Äî keywords include \"Kenya\" to keep relevance\n",
    "for sub in broad_subreddits:\n",
    "    subreddit = reddit.subreddit(sub)\n",
    "    print(f\"üîé Searching r/{sub} with 'Kenya' + keyword...\")\n",
    "\n",
    "    for term in base_keywords:\n",
    "        try:\n",
    "            # Search for 'Kenya AND <keyword>'\n",
    "            query = f'\"Kenya\" AND \"{term}\"'\n",
    "            for post in subreddit.search(query, sort='new', limit=200):\n",
    "                if post.created_utc < cutoff_date:\n",
    "                    continue  # Skip older posts\n",
    "\n",
    "                data.append({\n",
    "                    'subreddit': sub,\n",
    "                    'search_term': f\"Kenya AND {term}\",\n",
    "                    'title': post.title,\n",
    "                    'text': post.selftext,\n",
    "                    'created_utc': post.created_utc,\n",
    "                    'created_date': datetime.fromtimestamp(post.created_utc),\n",
    "                    'score': post.score,\n",
    "                    'num_comments': post.num_comments,\n",
    "                    'permalink': f\"https://reddit.com{post.permalink}\",\n",
    "                    'url': post.url\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error searching term '{term}' in r/{sub}: {e}\")\n",
    "\n",
    "# --- SAVE RESULTS ---\n",
    "df = pd.DataFrame(data)\n",
    "df['created_date'] = pd.to_datetime(df['created_utc'], unit='s')\n",
    "df.to_csv('../data/raw/leo_reddit_posts.csv', index=False)\n",
    "\n",
    "print(f\"‚úÖ Scraped {len(df)} posts. Saved to ../data/raw/leo_reddit_posts.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "565c8a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>search_term</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>created_date</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>permalink</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>WASH Kenya</td>\n",
       "      <td>This part of my life is called Homeless and Jo...</td>\n",
       "      <td>Hey Redditors, it‚Äôs me again with an update fr...</td>\n",
       "      <td>1.749456e+09</td>\n",
       "      <td>2025-06-09 07:52:13</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>https://reddit.com/r/Kenya/comments/1l6yy0t/th...</td>\n",
       "      <td>https://www.reddit.com/r/Kenya/comments/1l6yy0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>foreign funding</td>\n",
       "      <td>Are there Kenyans who are into FIRE (Financial...</td>\n",
       "      <td>FIRE stands for Financial Independence, Retire...</td>\n",
       "      <td>1.747667e+09</td>\n",
       "      <td>2025-05-19 14:55:26</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>https://reddit.com/r/Kenya/comments/1kqdr0i/ar...</td>\n",
       "      <td>https://www.reddit.com/r/Kenya/comments/1kqdr0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>ABT</td>\n",
       "      <td>Is it really expensive taste?</td>\n",
       "      <td>Lemme list a couple of things I don't  like an...</td>\n",
       "      <td>1.744692e+09</td>\n",
       "      <td>2025-04-15 04:44:50</td>\n",
       "      <td>12</td>\n",
       "      <td>87</td>\n",
       "      <td>https://reddit.com/r/Kenya/comments/1jzjf0c/is...</td>\n",
       "      <td>https://www.reddit.com/r/Kenya/comments/1jzjf0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>USAID</td>\n",
       "      <td>USAID left a month ago, do we have ARVs in Kenya?</td>\n",
       "      <td>Someone on a different group (different websit...</td>\n",
       "      <td>1.744723e+09</td>\n",
       "      <td>2025-04-15 13:16:53</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>https://reddit.com/r/Kenya/comments/1jzrn2s/us...</td>\n",
       "      <td>https://www.reddit.com/r/Kenya/comments/1jzrn2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>Youth program</td>\n",
       "      <td>We need to get a President who will make loote...</td>\n",
       "      <td>By Peter Mburu | Monday, May 05, 2025 \\n\\nIf t...</td>\n",
       "      <td>1.746517e+09</td>\n",
       "      <td>2025-05-06 07:42:54</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>https://reddit.com/r/Kenya/comments/1kfyt7w/we...</td>\n",
       "      <td>https://nation.africa/kenya/business/scandal-o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>development aid</td>\n",
       "      <td>Is There a Better Way to Fund Africa‚Äôs Infrast...</td>\n",
       "      <td>I'm researching a fintech concept rooted in a ...</td>\n",
       "      <td>1.745161e+09</td>\n",
       "      <td>2025-04-20 14:49:50</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>https://reddit.com/r/Kenya/comments/1k3o7to/is...</td>\n",
       "      <td>https://www.reddit.com/r/Kenya/comments/1k3o7t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>Power Africa</td>\n",
       "      <td>Is Data the missing link for Kenya's entrepren...</td>\n",
       "      <td>Africa‚Äôs economic future is being redefined by...</td>\n",
       "      <td>1.743351e+09</td>\n",
       "      <td>2025-03-30 16:08:25</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>https://reddit.com/r/Kenya/comments/1jnfssf/is...</td>\n",
       "      <td>https://www.reddit.com/r/Kenya/comments/1jnfss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa Water Facility</td>\n",
       "      <td>River yala; the ‚Äúgovernment mortuary‚Äù</td>\n",
       "      <td>In the heart of western Kenya, where the River...</td>\n",
       "      <td>1.743625e+09</td>\n",
       "      <td>2025-04-02 20:17:15</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>https://reddit.com/r/Kenya/comments/1jpynsd/ri...</td>\n",
       "      <td>https://i.redd.it/uwfm2jcfchse1.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>Kenya Crops and Dairy</td>\n",
       "      <td>Kenyan comfort food - ugali, nyama na sukuma w...</td>\n",
       "      <td>\\nI swear anytime anywhere, nyama ugali and su...</td>\n",
       "      <td>1.748437e+09</td>\n",
       "      <td>2025-05-28 12:53:50</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>https://reddit.com/r/Kenya/comments/1kxgbt1/ke...</td>\n",
       "      <td>https://www.reddit.com/r/Kenya/comments/1kxgbt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>foreign aid</td>\n",
       "      <td>Foreign aid/Philanthropy</td>\n",
       "      <td>I see the aid or philanthropic activities that...</td>\n",
       "      <td>1.745754e+09</td>\n",
       "      <td>2025-04-27 11:32:24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>https://reddit.com/r/Kenya/comments/1k91v58/fo...</td>\n",
       "      <td>https://www.reddit.com/r/Kenya/comments/1k91v5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subreddit            search_term  \\\n",
       "73      Kenya             WASH Kenya   \n",
       "18      Kenya        foreign funding   \n",
       "118     Kenya                    ABT   \n",
       "78      Kenya                  USAID   \n",
       "76      Kenya          Youth program   \n",
       "31      Kenya        development aid   \n",
       "64      Kenya           Power Africa   \n",
       "141     Kenya  Africa Water Facility   \n",
       "68      Kenya  Kenya Crops and Dairy   \n",
       "82      Kenya            foreign aid   \n",
       "\n",
       "                                                 title  \\\n",
       "73   This part of my life is called Homeless and Jo...   \n",
       "18   Are there Kenyans who are into FIRE (Financial...   \n",
       "118                      Is it really expensive taste?   \n",
       "78   USAID left a month ago, do we have ARVs in Kenya?   \n",
       "76   We need to get a President who will make loote...   \n",
       "31   Is There a Better Way to Fund Africa‚Äôs Infrast...   \n",
       "64   Is Data the missing link for Kenya's entrepren...   \n",
       "141              River yala; the ‚Äúgovernment mortuary‚Äù   \n",
       "68   Kenyan comfort food - ugali, nyama na sukuma w...   \n",
       "82                            Foreign aid/Philanthropy   \n",
       "\n",
       "                                                  text   created_utc  \\\n",
       "73   Hey Redditors, it‚Äôs me again with an update fr...  1.749456e+09   \n",
       "18   FIRE stands for Financial Independence, Retire...  1.747667e+09   \n",
       "118  Lemme list a couple of things I don't  like an...  1.744692e+09   \n",
       "78   Someone on a different group (different websit...  1.744723e+09   \n",
       "76   By Peter Mburu | Monday, May 05, 2025 \\n\\nIf t...  1.746517e+09   \n",
       "31   I'm researching a fintech concept rooted in a ...  1.745161e+09   \n",
       "64   Africa‚Äôs economic future is being redefined by...  1.743351e+09   \n",
       "141  In the heart of western Kenya, where the River...  1.743625e+09   \n",
       "68   \\nI swear anytime anywhere, nyama ugali and su...  1.748437e+09   \n",
       "82   I see the aid or philanthropic activities that...  1.745754e+09   \n",
       "\n",
       "           created_date  score  num_comments  \\\n",
       "73  2025-06-09 07:52:13     16             6   \n",
       "18  2025-05-19 14:55:26      2             8   \n",
       "118 2025-04-15 04:44:50     12            87   \n",
       "78  2025-04-15 13:16:53      3             5   \n",
       "76  2025-05-06 07:42:54      3             0   \n",
       "31  2025-04-20 14:49:50      9             9   \n",
       "64  2025-03-30 16:08:25      2             5   \n",
       "141 2025-04-02 20:17:15     13             1   \n",
       "68  2025-05-28 12:53:50      5             2   \n",
       "82  2025-04-27 11:32:24      1             0   \n",
       "\n",
       "                                             permalink  \\\n",
       "73   https://reddit.com/r/Kenya/comments/1l6yy0t/th...   \n",
       "18   https://reddit.com/r/Kenya/comments/1kqdr0i/ar...   \n",
       "118  https://reddit.com/r/Kenya/comments/1jzjf0c/is...   \n",
       "78   https://reddit.com/r/Kenya/comments/1jzrn2s/us...   \n",
       "76   https://reddit.com/r/Kenya/comments/1kfyt7w/we...   \n",
       "31   https://reddit.com/r/Kenya/comments/1k3o7to/is...   \n",
       "64   https://reddit.com/r/Kenya/comments/1jnfssf/is...   \n",
       "141  https://reddit.com/r/Kenya/comments/1jpynsd/ri...   \n",
       "68   https://reddit.com/r/Kenya/comments/1kxgbt1/ke...   \n",
       "82   https://reddit.com/r/Kenya/comments/1k91v58/fo...   \n",
       "\n",
       "                                                   url  \n",
       "73   https://www.reddit.com/r/Kenya/comments/1l6yy0...  \n",
       "18   https://www.reddit.com/r/Kenya/comments/1kqdr0...  \n",
       "118  https://www.reddit.com/r/Kenya/comments/1jzjf0...  \n",
       "78   https://www.reddit.com/r/Kenya/comments/1jzrn2...  \n",
       "76   https://nation.africa/kenya/business/scandal-o...  \n",
       "31   https://www.reddit.com/r/Kenya/comments/1k3o7t...  \n",
       "64   https://www.reddit.com/r/Kenya/comments/1jnfss...  \n",
       "141               https://i.redd.it/uwfm2jcfchse1.jpeg  \n",
       "68   https://www.reddit.com/r/Kenya/comments/1kxgbt...  \n",
       "82   https://www.reddit.com/r/Kenya/comments/1k91v5...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(random_state=42, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d97461f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# newsapi_scraper.py\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from newspaper import Article\n",
    "import time\n",
    "\n",
    "# --- PARAMETERS ---\n",
    "api_key = 'bc6c52fd05ee4e63827b7cf45fa0bdb2'\n",
    "keywords = [\n",
    "    \"USAID\", \"foreign aid\", \"aid cuts\", \"Trump aid cuts\", \"USAID funding\",\n",
    "    \"project shutdown\", \"development funding\", \"NGO funding\", \"foreign assistance\",\n",
    "    \"terminated projects\", \"EECA\", \"RTI\", \"KPLP\", \"SoCha\", \"ABT\", \"Prosper Africa\",\n",
    "    \"BCG\", \"IDG\", \"KHPQS\", \"OVC\", \"Tujitegemee\", \"Tujenge Jamii\", \"supply chain\",\n",
    "    \"PMI Evolve\", \"sanitation project\", \"community resilience\", \"Owod project\",\n",
    "    \"nutrition program\", \"resilience project\", \"digital transformation\",\n",
    "    \"Africa Water Facility\", \"trade reforms\", \"solar health\", \"elections grant\"\n",
    "]\n",
    "\n",
    "from_date = '2025-01-01'\n",
    "page_size = 100\n",
    "max_pages = 3  # Loop through multiple pages\n",
    "\n",
    "# --- FETCH ARTICLES ---\n",
    "all_articles = []\n",
    "for keyword in keywords:\n",
    "    print(f\"üîç Searching for articles with keyword: {keyword}\")\n",
    "    for page in range(1, max_pages + 1):\n",
    "        url = (\n",
    "            f'https://newsapi.org/v2/everything?'\n",
    "            f'q=\"{keyword}\"&'\n",
    "            f'from={from_date}&'\n",
    "            f'sortBy=publishedAt&'\n",
    "            f'pageSize={page_size}&'\n",
    "            f'page={page}&'\n",
    "            f'apiKey={api_key}'\n",
    "        )\n",
    "\n",
    "        response = requests.get(url)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"‚ùå Error: {response.status_code} - {response.json()}\")\n",
    "            break\n",
    "\n",
    "        articles = response.json().get('articles', [])\n",
    "        if not articles:\n",
    "            break\n",
    "\n",
    "        for article in articles:\n",
    "            all_articles.append({\n",
    "                'keyword': keyword,\n",
    "                'source': article['source']['name'],\n",
    "                'author': article.get('author'),\n",
    "                'title': article.get('title'),\n",
    "                'description': article.get('description'),\n",
    "                'content': article.get('content'),\n",
    "                'url': article.get('url'),\n",
    "                'published_at': article.get('publishedAt')\n",
    "            })\n",
    "\n",
    "# --- CONVERT TO DATAFRAME ---\n",
    "df = pd.DataFrame(all_articles)\n",
    "df.drop_duplicates(subset='url', inplace=True)\n",
    "df['published_at'] = pd.to_datetime(df['published_at'])\n",
    "\n",
    "# --- SAVE RAW ARTICLES ---\n",
    "raw_path = '../data/raw/leo_newsapi_articles.csv'\n",
    "df.to_csv(raw_path, index=False)\n",
    "print(f\"‚úÖ Fetched {len(df)} articles. Saved to {raw_path}\")\n",
    "\n",
    "# --- EXTRACT FULL TEXT USING newspaper3k ---\n",
    "print(\"üì∞ Extracting full text from article URLs...\")\n",
    "full_texts = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    url = row['url']\n",
    "    try:\n",
    "        article = Article(url)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        full_texts.append(article.text)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed at index {i} ({url}): {e}\")\n",
    "        full_texts.append(None)\n",
    "    if i % 10 == 0:\n",
    "        # Save progress checkpoint\n",
    "        df['full_text'] = pd.Series(full_texts)\n",
    "        df.to_csv('../data/raw/leo_newsapi_articles_checkpoint.csv', index=False)\n",
    "    time.sleep(1)\n",
    "\n",
    "# --- ADD TO DATAFRAME & SAVE FINAL ---\n",
    "df['full_text'] = full_texts\n",
    "final_path = '../data/raw/leo_newsapi_articles_enriched.csv'\n",
    "df.to_csv(final_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Done. Saved full-text articles to {final_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "368050bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Searching for articles with keyword: USAID\n",
      "üîç Searching for articles with keyword: foreign aid\n",
      "üîç Searching for articles with keyword: aid cuts\n",
      "üîç Searching for articles with keyword: Trump aid cuts\n",
      "üîç Searching for articles with keyword: USAID funding\n",
      "üîç Searching for articles with keyword: project shutdown\n",
      "üîç Searching for articles with keyword: development funding\n",
      "üîç Searching for articles with keyword: NGO funding\n",
      "üîç Searching for articles with keyword: foreign assistance\n",
      "üîç Searching for articles with keyword: terminated projects\n",
      "üîç Searching for articles with keyword: PEPFAR\n",
      "üîç Searching for articles with keyword: Feed the Future\n",
      "üîç Searching for articles with keyword: Tusome\n",
      "üîç Searching for articles with keyword: Power Africa\n",
      "üîç Searching for articles with keyword: USAID education\n",
      "üîç Searching for articles with keyword: USAID health\n",
      "üîç Searching for articles with keyword: nutrition assistance\n",
      "üîç Searching for articles with keyword: malaria program\n",
      "üîç Searching for articles with keyword: HIV funding\n",
      "üîç Searching for articles with keyword: Crops and Dairy\n",
      "üîç Searching for articles with keyword: WASH\n",
      "üîç Searching for articles with keyword: USAID climate\n",
      "üîç Searching for articles with keyword: USAID governance\n",
      "üîç Searching for articles with keyword: USAID transparency\n",
      "üîç Searching for articles with keyword: HIV USAID\n",
      "üîç Searching for articles with keyword: resilience programs\n",
      "üîç Searching for articles with keyword: USAID devolution\n",
      "üîç Searching for articles with keyword: Youth program\n",
      "üîç Searching for articles with keyword: EECA\n",
      "üîç Searching for articles with keyword: RTI\n",
      "üîç Searching for articles with keyword: KPLP\n",
      "üîç Searching for articles with keyword: SoCha\n",
      "üîç Searching for articles with keyword: ABT\n",
      "üîç Searching for articles with keyword: Prosper Africa\n",
      "üîç Searching for articles with keyword: BCG\n",
      "üîç Searching for articles with keyword: IDG\n",
      "üîç Searching for articles with keyword: KHPQS\n",
      "üîç Searching for articles with keyword: OVC\n",
      "üîç Searching for articles with keyword: Tujitegemee\n",
      "üîç Searching for articles with keyword: Tujenge Jamii\n",
      "üîç Searching for articles with keyword: supply chain\n",
      "üîç Searching for articles with keyword: PMI Evolve\n",
      "üîç Searching for articles with keyword: sanitation project\n",
      "üîç Searching for articles with keyword: community resilience\n",
      "üîç Searching for articles with keyword: Owod project\n",
      "üîç Searching for articles with keyword: nutrition program\n",
      "üîç Searching for articles with keyword: resilience project\n",
      "üîç Searching for articles with keyword: digital transformation\n",
      "üîç Searching for articles with keyword: Africa Water Facility\n",
      "üîç Searching for articles with keyword: trade reforms\n",
      "üîç Searching for articles with keyword: solar health\n",
      "üîç Searching for articles with keyword: elections grant\n",
      "‚úÖ Fetched 1498 articles. Saved to ../data/raw/leo_newsapi_articles.csv\n",
      "üì∞ Extracting full text from article URLs...\n",
      "‚ùå Failed at index 12 (https://www.rawstory.com/raw-investigates/trump-is-evil/): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.rawstory.com/raw-investigates/trump-is-evil/ on URL https://www.rawstory.com/raw-investigates/trump-is-evil/\n",
      "‚ùå Failed at index 40 (https://www.ibtimes.com/whats-not-being-discussed-g7-trump-shapes-agenda-3775843): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.ibtimes.com/whats-not-being-discussed-g7-trump-shapes-agenda-3775843 on URL https://www.ibtimes.com/whats-not-being-discussed-g7-trump-shapes-agenda-3775843\n",
      "‚ùå Failed at index 48 (https://www.foxnews.com/politics/how-johnson-pulled-off-another-impossible-win-just-1-vote-margin-9-4b-spending-cut-bill): Article `download()` failed with 404 Client Error: Not Found for url: https://www.foxnews.com/politics/how-johnson-pulled-off-another-impossible-win-just-1-vote-margin-9-4b-spending-cut-bill on URL https://www.foxnews.com/politics/how-johnson-pulled-off-another-impossible-win-just-1-vote-margin-9-4b-spending-cut-bill\n",
      "‚ùå Failed at index 51 (https://www.forbes.com/sites/daniellechemtob/2025/06/16/forbes-daily-no-israel-and-iran-deal-in-sight-as-trump-calls-for-peace/): Article `download()` failed with 403 Client Error: Max restarts limit reached for url: https://www.forbes.com/sites/daniellechemtob/2025/06/16/forbes-daily-no-israel-and-iran-deal-in-sight-as-trump-calls-for-peace/ on URL https://www.forbes.com/sites/daniellechemtob/2025/06/16/forbes-daily-no-israel-and-iran-deal-in-sight-as-trump-calls-for-peace/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /home/leo/anaconda3/envs/learn-env/lib/python3.8/site-packages/jieba/dict.txt ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 2.017775774002075 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Failed at index 81 (https://www.foxnews.com/politics/senate-republicans-carefully-weighing-controversial-tax-provisions-debt-ceiling-legislation-bringing-big-beautiful-bill-floor): Article `download()` failed with 404 Client Error: Not Found for url: https://www.foxnews.com/politics/senate-republicans-carefully-weighing-controversial-tax-provisions-debt-ceiling-legislation-bringing-big-beautiful-bill-floor on URL https://www.foxnews.com/politics/senate-republicans-carefully-weighing-controversial-tax-provisions-debt-ceiling-legislation-bringing-big-beautiful-bill-floor\n",
      "‚ùå Failed at index 82 (https://www.foxnews.com/politics/senate-gops-carefully-weighing-controversial-tax-provisions-before-bringing-big-beautiful-bill-floor): Article `download()` failed with 404 Client Error: Not Found for url: https://www.foxnews.com/politics/senate-gops-carefully-weighing-controversial-tax-provisions-before-bringing-big-beautiful-bill-floor on URL https://www.foxnews.com/politics/senate-gops-carefully-weighing-controversial-tax-provisions-before-bringing-big-beautiful-bill-floor\n",
      "‚ùå Failed at index 86 (https://www.elconfidencial.com/tecnologia/2025-06-14/doge-juguete-musk-experimento-liderazgo-motosierra-trump-gebbia_4151111/): Article `download()` failed with 403 Client Error: Forbidden!!! for url: https://www.elconfidencial.com/tecnologia/2025-06-14/doge-juguete-musk-experimento-liderazgo-motosierra-trump-gebbia_4151111/ on URL https://www.elconfidencial.com/tecnologia/2025-06-14/doge-juguete-musk-experimento-liderazgo-motosierra-trump-gebbia_4151111/\n",
      "‚ùå Failed at index 88 (https://www.forbes.com/sites/kellyphillipserb/2025/06/14/tax-breaks-the-new-chapter-is-beginning-at-the-irs-edition/): Article `download()` failed with 403 Client Error: Max restarts limit reached for url: https://www.forbes.com/sites/kellyphillipserb/2025/06/14/tax-breaks-the-new-chapter-is-beginning-at-the-irs-edition/ on URL https://www.forbes.com/sites/kellyphillipserb/2025/06/14/tax-breaks-the-new-chapter-is-beginning-at-the-irs-edition/\n",
      "‚ùå Failed at index 102 (https://www.fastcompany.com/91336445/gilead-sciences-lenacapavir-prep-end-hiv-epidemic): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.fastcompany.com/91336445/gilead-sciences-lenacapavir-prep-end-hiv-epidemic on URL https://www.fastcompany.com/91336445/gilead-sciences-lenacapavir-prep-end-hiv-epidemic\n",
      "‚ùå Failed at index 105 (https://www.forbes.com/sites/hessiejones/2025/06/17/the-death-of-privacy-and-the-radical-reshaping-of-a-political-system/): Article `download()` failed with 403 Client Error: Max restarts limit reached for url: https://www.forbes.com/sites/hessiejones/2025/06/17/the-death-of-privacy-and-the-radical-reshaping-of-a-political-system/ on URL https://www.forbes.com/sites/hessiejones/2025/06/17/the-death-of-privacy-and-the-radical-reshaping-of-a-political-system/\n",
      "‚ùå Failed at index 108 (https://www.foxnews.com/politics/key-republican-calls-emergency-funding-israel-amid-worsening-iran-conflict): Article `download()` failed with 404 Client Error: Not Found for url: https://www.foxnews.com/politics/key-republican-calls-emergency-funding-israel-amid-worsening-iran-conflict on URL https://www.foxnews.com/politics/key-republican-calls-emergency-funding-israel-amid-worsening-iran-conflict\n",
      "‚ùå Failed at index 129 (https://www.forbes.com/sites/unicefusa/2025/06/16/what-it-takes-to-support-children-fleeing-violence-in-eastern-drc/): Article `download()` failed with 403 Client Error: Max restarts limit reached for url: https://www.forbes.com/sites/unicefusa/2025/06/16/what-it-takes-to-support-children-fleeing-violence-in-eastern-drc/ on URL https://www.forbes.com/sites/unicefusa/2025/06/16/what-it-takes-to-support-children-fleeing-violence-in-eastern-drc/\n",
      "‚ùå Failed at index 130 (https://www.ibtimes.com/un-refugee-agency-says-will-shed-3500-jobs-due-funding-cuts-3775813): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.ibtimes.com/un-refugee-agency-says-will-shed-3500-jobs-due-funding-cuts-3775813 on URL https://www.ibtimes.com/un-refugee-agency-says-will-shed-3500-jobs-due-funding-cuts-3775813\n",
      "‚ùå Failed at index 138 (https://www.ibtimes.com/un-slashes-global-aid-plan-over-deepest-funding-cuts-ever-3775777): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.ibtimes.com/un-slashes-global-aid-plan-over-deepest-funding-cuts-ever-3775777 on URL https://www.ibtimes.com/un-slashes-global-aid-plan-over-deepest-funding-cuts-ever-3775777\n",
      "‚ùå Failed at index 157 (https://www.forbes.com/sites/unicefusa/2025/06/14/unicef-helps-dads-give-their-children-the-best-possible-start-in-life/): Article `download()` failed with 403 Client Error: Max restarts limit reached for url: https://www.forbes.com/sites/unicefusa/2025/06/14/unicef-helps-dads-give-their-children-the-best-possible-start-in-life/ on URL https://www.forbes.com/sites/unicefusa/2025/06/14/unicef-helps-dads-give-their-children-the-best-possible-start-in-life/\n",
      "‚ùå Failed at index 159 (https://www.forbes.com/sites/thomasbrewster/2025/06/13/trump-defunding-an-agency-saving-billions-in-taxpayer-money/): Article `download()` failed with 403 Client Error: Max restarts limit reached for url: https://www.forbes.com/sites/thomasbrewster/2025/06/13/trump-defunding-an-agency-saving-billions-in-taxpayer-money/ on URL https://www.forbes.com/sites/thomasbrewster/2025/06/13/trump-defunding-an-agency-saving-billions-in-taxpayer-money/\n",
      "‚ùå Failed at index 169 (https://www.forbes.com/sites/davidhessekiel/2025/06/13/career-advice-for-unemployed-social-impact-workers-hit-by-federal-cuts/): Article `download()` failed with 403 Client Error: Max restarts limit reached for url: https://www.forbes.com/sites/davidhessekiel/2025/06/13/career-advice-for-unemployed-social-impact-workers-hit-by-federal-cuts/ on URL https://www.forbes.com/sites/davidhessekiel/2025/06/13/career-advice-for-unemployed-social-impact-workers-hit-by-federal-cuts/\n",
      "‚ùå Failed at index 174 (https://www.forbes.com/sites/kellyphillipserb/2025/06/13/house-approves-bill-that-would-claw-back-94-billion-in-funding-now-moves-to-senate/): Article `download()` failed with 403 Client Error: Max restarts limit reached for url: https://www.forbes.com/sites/kellyphillipserb/2025/06/13/house-approves-bill-that-would-claw-back-94-billion-in-funding-now-moves-to-senate/ on URL https://www.forbes.com/sites/kellyphillipserb/2025/06/13/house-approves-bill-that-would-claw-back-94-billion-in-funding-now-moves-to-senate/\n",
      "‚ùå Failed at index 211 (https://www.newsweek.com/list-republicans-voted-against-doge-cuts-2084838): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.newsweek.com/list-republicans-voted-against-doge-cuts-2084838 on URL https://www.newsweek.com/list-republicans-voted-against-doge-cuts-2084838\n",
      "‚ùå Failed at index 214 (https://www.foxnews.com/politics/fate-trumps-9-4-billion-spending-cut-package-hangs-house-gop-moderates): Article `download()` failed with 404 Client Error: Not Found for url: https://www.foxnews.com/politics/fate-trumps-9-4-billion-spending-cut-package-hangs-house-gop-moderates on URL https://www.foxnews.com/politics/fate-trumps-9-4-billion-spending-cut-package-hangs-house-gop-moderates\n",
      "‚ùå Failed at index 229 (https://www.forbes.com/sites/ceciliarodriguez/2025/06/08/16-iconic-wild-animal-photos-celebrating-10-years-of-remembering-wildlife/): Article `download()` failed with 403 Client Error: Max restarts limit reached for url: https://www.forbes.com/sites/ceciliarodriguez/2025/06/08/16-iconic-wild-animal-photos-celebrating-10-years-of-remembering-wildlife/ on URL https://www.forbes.com/sites/ceciliarodriguez/2025/06/08/16-iconic-wild-animal-photos-celebrating-10-years-of-remembering-wildlife/\n",
      "‚ùå Failed at index 234 (https://abcnews.go.com/International/aid-workers-usaid-cuts-putting-lives-children-hiv/story?id=122489405): Article `download()` failed with HTTPSConnectionPool(host='abcnews.go.com', port=443): Read timed out. (read timeout=7) on URL https://abcnews.go.com/International/aid-workers-usaid-cuts-putting-lives-children-hiv/story?id=122489405\n",
      "‚ùå Failed at index 244 (https://www.newsweek.com/nigerias-minister-information-after-aid-cuts-africa-only-markets-can-deliver-opinion-2079080): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.newsweek.com/nigerias-minister-information-after-aid-cuts-africa-only-markets-can-deliver-opinion-2079080 on URL https://www.newsweek.com/nigerias-minister-information-after-aid-cuts-africa-only-markets-can-deliver-opinion-2079080\n",
      "‚ùå Failed at index 251 (https://www.newsweek.com/hunger-warwhy-world-cant-look-away-opinion-2079057): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.newsweek.com/hunger-warwhy-world-cant-look-away-opinion-2079057 on URL https://www.newsweek.com/hunger-warwhy-world-cant-look-away-opinion-2079057\n",
      "‚ùå Failed at index 260 (https://www.rawstory.com/doge-deaths-breaking-news-msnbc/): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.rawstory.com/doge-deaths-breaking-news-msnbc/ on URL https://www.rawstory.com/doge-deaths-breaking-news-msnbc/\n",
      "‚ùå Failed at index 261 (https://www.abc.net.au/news/2025-05-30/richard-marles-pete-hegseth-defence-spending/105360768): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.abc.net.au/news/2025-05-30/richard-marles-pete-hegseth-defence-spending/105360768 on URL https://www.abc.net.au/news/2025-05-30/richard-marles-pete-hegseth-defence-spending/105360768\n",
      "‚ùå Failed at index 274 (https://www.forbes.com/sites/kellyphillipserb/2025/06/12/house-moves-to-claw-back-money-from-public-broadcasting-and-foreign-aid/): Article `download()` failed with 403 Client Error: Max restarts limit reached for url: https://www.forbes.com/sites/kellyphillipserb/2025/06/12/house-moves-to-claw-back-money-from-public-broadcasting-and-foreign-aid/ on URL https://www.forbes.com/sites/kellyphillipserb/2025/06/12/house-moves-to-claw-back-money-from-public-broadcasting-and-foreign-aid/\n",
      "‚ùå Failed at index 275 (https://www.globalresearch.ca/daniel-ortega-no-bukele/5890635): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.globalresearch.ca/daniel-ortega-no-bukele/5890635 on URL https://www.globalresearch.ca/daniel-ortega-no-bukele/5890635\n",
      "‚ùå Failed at index 281 (https://diggers.news/opinion/2025/06/11/empower-local-drug-manufacturers-build-health-sovereignty/): Article `download()` failed with HTTPSConnectionPool(host='diggers.news', port=443): Read timed out. (read timeout=7) on URL https://diggers.news/opinion/2025/06/11/empower-local-drug-manufacturers-build-health-sovereignty/\n",
      "‚ùå Failed at index 292 (https://www.newsweek.com/how-ruin-countrys-image-economy-global-standing-six-easy-steps-opinion-2080454): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.newsweek.com/how-ruin-countrys-image-economy-global-standing-six-easy-steps-opinion-2080454 on URL https://www.newsweek.com/how-ruin-countrys-image-economy-global-standing-six-easy-steps-opinion-2080454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/anaconda3/envs/learn-env/lib/python3.8/site-packages/dateutil/parser/_parser.py:1213: UnknownTimezoneWarning: tzname EDT identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Failed at index 302 (https://www.foxnews.com/opinion/democrats-dont-need-left-wing-joe-rogan-need-win-back-real-one): Article `download()` failed with 404 Client Error: Not Found for url: https://www.foxnews.com/opinion/democrats-dont-need-left-wing-joe-rogan-need-win-back-real-one on URL https://www.foxnews.com/opinion/democrats-dont-need-left-wing-joe-rogan-need-win-back-real-one\n",
      "‚ùå Failed at index 305 (https://abcnews.go.com/Health/wireStory/haitians-hiv-defy-stigma-publicly-denounce-usaid-cuts-122146010): Article `download()` failed with 404 Client Error: Not Found for url: https://abcnews.go.com/Health/wireStory/haitians-hiv-defy-stigma-publicly-denounce-usaid-cuts-122146010 on URL https://abcnews.go.com/Health/wireStory/haitians-hiv-defy-stigma-publicly-denounce-usaid-cuts-122146010\n",
      "‚ùå Failed at index 312 (https://abcnews.go.com/Business/wireStory/mali-usaid-funding-cuts-hit-local-language-learning-122018337): Article `download()` failed with 404 Client Error: Not Found for url: https://abcnews.go.com/Business/wireStory/mali-usaid-funding-cuts-hit-local-language-learning-122018337 on URL https://abcnews.go.com/Business/wireStory/mali-usaid-funding-cuts-hit-local-language-learning-122018337\n",
      "‚ùå Failed at index 313 (https://financialpost.com/pmn/in-mali-usaid-funding-cuts-hit-a-local-language-learning-program-that-empowered-thousands): Article `download()` failed with 403 Client Error: Forbidden for url: https://financialpost.com/pmn/in-mali-usaid-funding-cuts-hit-a-local-language-learning-program-that-empowered-thousands on URL https://financialpost.com/pmn/in-mali-usaid-funding-cuts-hit-a-local-language-learning-program-that-empowered-thousands\n",
      "‚ùå Failed at index 315 (https://www.foodsafetynews.com/2025/05/foreign-aid-cuts-enter-war-of-humans-vs-pathogens/): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.foodsafetynews.com/2025/05/foreign-aid-cuts-enter-war-of-humans-vs-pathogens/ on URL https://www.foodsafetynews.com/2025/05/foreign-aid-cuts-enter-war-of-humans-vs-pathogens/\n",
      "‚ùå Failed at index 322 (https://www.forbes.com/sites/drkathmackay/2025/06/17/why-the-uk-must-bridge-funding-gaps-to-position-itself-as-a-global-hub-for-rd-talent/): Article `download()` failed with 403 Client Error: Max restarts limit reached for url: https://www.forbes.com/sites/drkathmackay/2025/06/17/why-the-uk-must-bridge-funding-gaps-to-position-itself-as-a-global-hub-for-rd-talent/ on URL https://www.forbes.com/sites/drkathmackay/2025/06/17/why-the-uk-must-bridge-funding-gaps-to-position-itself-as-a-global-hub-for-rd-talent/\n",
      "‚ùå Failed at index 327 (https://www.globalresearch.ca/washington-targets-social-achievements-cuba-nicaragua-venezuela/5890708): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.globalresearch.ca/washington-targets-social-achievements-cuba-nicaragua-venezuela/5890708 on URL https://www.globalresearch.ca/washington-targets-social-achievements-cuba-nicaragua-venezuela/5890708\n",
      "‚ùå Failed at index 352 (https://www.forbes.com/sites/investor-hub/article/best-stocks-buy-now-june-2025/): Article `download()` failed with 403 Client Error: Max restarts limit reached for url: https://www.forbes.com/sites/investor-hub/article/best-stocks-buy-now-june-2025/ on URL https://www.forbes.com/sites/investor-hub/article/best-stocks-buy-now-june-2025/\n",
      "‚ùå Failed at index 361 (https://www.globalresearch.ca/hhs-terminates-moderna-bird-flu-injection/5888691): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.globalresearch.ca/hhs-terminates-moderna-bird-flu-injection/5888691 on URL https://www.globalresearch.ca/hhs-terminates-moderna-bird-flu-injection/5888691\n",
      "‚ùå Failed at index 367 (https://www.cbinsights.com/research/ai-drug-research-development-market-map/): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.cbinsights.com/research/ai-drug-research-development-market-map/ on URL https://www.cbinsights.com/research/ai-drug-research-development-market-map/\n",
      "‚ùå Failed at index 380 (https://www.euractiv.com/section/politics/news/eu-parliament-contemplates-permanent-body-to-monitor-ngo-funding/): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.euractiv.com/section/politics/news/eu-parliament-contemplates-permanent-body-to-monitor-ngo-funding/ on URL https://www.euractiv.com/section/politics/news/eu-parliament-contemplates-permanent-body-to-monitor-ngo-funding/\n",
      "‚ùå Failed at index 382 (https://www.euractiv.com/section/politics/news/the-capitals-merz-survives-and-even-thrives-in-the-oval-office/): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.euractiv.com/section/politics/news/the-capitals-merz-survives-and-even-thrives-in-the-oval-office/ on URL https://www.euractiv.com/section/politics/news/the-capitals-merz-survives-and-even-thrives-in-the-oval-office/\n",
      "‚ùå Failed at index 385 (https://www.euractiv.com/section/health-consumers/news/commission-under-pressure-as-citizens-push-to-ban-conversion-therapy/): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.euractiv.com/section/health-consumers/news/commission-under-pressure-as-citizens-push-to-ban-conversion-therapy/ on URL https://www.euractiv.com/section/health-consumers/news/commission-under-pressure-as-citizens-push-to-ban-conversion-therapy/\n",
      "‚ùå Failed at index 386 (https://www.globalresearch.ca/intro-chapter-twilight-american-imperialism/5889249): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.globalresearch.ca/intro-chapter-twilight-american-imperialism/5889249 on URL https://www.globalresearch.ca/intro-chapter-twilight-american-imperialism/5889249\n",
      "‚ùå Failed at index 418 (https://www.forbes.com/sites/unicefusa/2025/06/07/breast-milk-bank-helps-babies-thrive-in-nepal/): Article `download()` failed with 403 Client Error: Max restarts limit reached for url: https://www.forbes.com/sites/unicefusa/2025/06/07/breast-milk-bank-helps-babies-thrive-in-nepal/ on URL https://www.forbes.com/sites/unicefusa/2025/06/07/breast-milk-bank-helps-babies-thrive-in-nepal/\n",
      "‚ùå Failed at index 420 (https://www.foxnews.com/politics/risch-urges-top-bottom-usaid-spending-review-after-waste-fraud-exposed): Article `download()` failed with 404 Client Error: Not Found for url: https://www.foxnews.com/politics/risch-urges-top-bottom-usaid-spending-review-after-waste-fraud-exposed on URL https://www.foxnews.com/politics/risch-urges-top-bottom-usaid-spending-review-after-waste-fraud-exposed\n",
      "‚ùå Failed at index 423 (https://www.forbes.com/sites/unicefusa/2025/06/05/unicef-protects-sudans-children-from-malaria-cholera-as-cases-rise/): Article `download()` failed with 403 Client Error: Max restarts limit reached for url: https://www.forbes.com/sites/unicefusa/2025/06/05/unicef-protects-sudans-children-from-malaria-cholera-as-cases-rise/ on URL https://www.forbes.com/sites/unicefusa/2025/06/05/unicef-protects-sudans-children-from-malaria-cholera-as-cases-rise/\n",
      "‚ùå Failed at index 441 (https://www.forbes.com/sites/unicefusa/2025/05/30/the-power-of-the-human-spirit-comes-alive-in-peru/): Article `download()` failed with 403 Client Error: Max restarts limit reached for url: https://www.forbes.com/sites/unicefusa/2025/05/30/the-power-of-the-human-spirit-comes-alive-in-peru/ on URL https://www.forbes.com/sites/unicefusa/2025/05/30/the-power-of-the-human-spirit-comes-alive-in-peru/\n",
      "‚ùå Failed at index 446 (https://www.foxnews.com/politics/rubio-spearheads-massive-state-dept-reorganization-set-eliminate-merge-more-than-300-offices): Article `download()` failed with 404 Client Error: Not Found for url: https://www.foxnews.com/politics/rubio-spearheads-massive-state-dept-reorganization-set-eliminate-merge-more-than-300-offices on URL https://www.foxnews.com/politics/rubio-spearheads-massive-state-dept-reorganization-set-eliminate-merge-more-than-300-offices\n",
      "‚ùå Failed at index 453 (https://www.forbes.com/sites/unicefusa/2025/05/28/more-than-50000-children-killed-or-injured-in-gaza/): Article `download()` failed with 403 Client Error: Max restarts limit reached for url: https://www.forbes.com/sites/unicefusa/2025/05/28/more-than-50000-children-killed-or-injured-in-gaza/ on URL https://www.forbes.com/sites/unicefusa/2025/05/28/more-than-50000-children-killed-or-injured-in-gaza/\n",
      "‚ùå Failed at index 465 (https://www.forbes.com/sites/thomasbrewster/2025/05/27/a-massive-week-in-cyber-takedowns/): Article `download()` failed with 403 Client Error: Max restarts limit reached for url: https://www.forbes.com/sites/thomasbrewster/2025/05/27/a-massive-week-in-cyber-takedowns/ on URL https://www.forbes.com/sites/thomasbrewster/2025/05/27/a-massive-week-in-cyber-takedowns/\n",
      "‚ùå Failed at index 468 (https://www.ibtimes.com.au/syria-help-locate-missing-americans-us-envoy-1859056): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.ibtimes.com.au/syria-help-locate-missing-americans-us-envoy-1859056 on URL https://www.ibtimes.com.au/syria-help-locate-missing-americans-us-envoy-1859056\n",
      "‚ùå Failed at index 470 (https://www.ibtimes.com/syria-help-locate-missing-americans-us-envoy-3774445): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.ibtimes.com/syria-help-locate-missing-americans-us-envoy-3774445 on URL https://www.ibtimes.com/syria-help-locate-missing-americans-us-envoy-3774445\n",
      "‚ùå Failed at index 474 (https://www.foxnews.com/politics/trump-administration-plans-overhaul-national-security-council-weeks-after-waltzs-departure): Article `download()` failed with 404 Client Error: Not Found for url: https://www.foxnews.com/politics/trump-administration-plans-overhaul-national-security-council-weeks-after-waltzs-departure on URL https://www.foxnews.com/politics/trump-administration-plans-overhaul-national-security-council-weeks-after-waltzs-departure\n",
      "‚ùå Failed at index 488 (https://www.lemonde.fr/international/article/2025/06/13/aux-etats-unis-la-chambre-des-representants-revoque-9-4-milliards-de-dollars-de-fonds-publics-federaux_6612601_3210.html): Article `download()` failed with 406 Client Error: Not Acceptable for url: https://www.lemonde.fr/international/article/2025/06/13/aux-etats-unis-la-chambre-des-representants-revoque-9-4-milliards-de-dollars-de-fonds-publics-federaux_6612601_3210.html on URL https://www.lemonde.fr/international/article/2025/06/13/aux-etats-unis-la-chambre-des-representants-revoque-9-4-milliards-de-dollars-de-fonds-publics-federaux_6612601_3210.html\n",
      "‚ùå Failed at index 507 (https://financialpost.com/pmn/whats-targeted-in-trumps-request-for-9-4-billion-in-budget-cuts-from-congress): Article `download()` failed with 403 Client Error: Forbidden for url: https://financialpost.com/pmn/whats-targeted-in-trumps-request-for-9-4-billion-in-budget-cuts-from-congress on URL https://financialpost.com/pmn/whats-targeted-in-trumps-request-for-9-4-billion-in-budget-cuts-from-congress\n",
      "‚ùå Failed at index 511 (https://www.foxnews.com/politics/republican-rep-indicates-hes-a-no-trump-backed-rescissions-proposal): Article `download()` failed with 404 Client Error: Not Found for url: https://www.foxnews.com/politics/republican-rep-indicates-hes-a-no-trump-backed-rescissions-proposal on URL https://www.foxnews.com/politics/republican-rep-indicates-hes-a-no-trump-backed-rescissions-proposal\n",
      "‚ùå Failed at index 512 (https://www.foxnews.com/politics/republican-rep-indicates-he-a-no-trump-backed-rescissions-measure-aids-relief-cut): Article `download()` failed with 404 Client Error: Not Found for url: https://www.foxnews.com/politics/republican-rep-indicates-he-a-no-trump-backed-rescissions-measure-aids-relief-cut on URL https://www.foxnews.com/politics/republican-rep-indicates-he-a-no-trump-backed-rescissions-measure-aids-relief-cut\n",
      "‚ùå Failed at index 522 (https://www.forbes.com/sites/jenniferlotito/2025/06/05/experts-warn-of-decade-long-setback-after-trump-cuts-hiv-vaccine-research/): Article `download()` failed with 403 Client Error: Max restarts limit reached for url: https://www.forbes.com/sites/jenniferlotito/2025/06/05/experts-warn-of-decade-long-setback-after-trump-cuts-hiv-vaccine-research/ on URL https://www.forbes.com/sites/jenniferlotito/2025/06/05/experts-warn-of-decade-long-setback-after-trump-cuts-hiv-vaccine-research/\n",
      "‚ùå Failed at index 535 (https://www.foxnews.com/politics/house-republicans-push-spending-cancellations-elon-musk-conservatives-demand-deeper-budget-cuts): Article `download()` failed with 404 Client Error: Not Found for url: https://www.foxnews.com/politics/house-republicans-push-spending-cancellations-elon-musk-conservatives-demand-deeper-budget-cuts on URL https://www.foxnews.com/politics/house-republicans-push-spending-cancellations-elon-musk-conservatives-demand-deeper-budget-cuts\n",
      "‚ùå Failed at index 538 (https://abcnews.go.com/Business/wireStory/trump-formally-asks-congress-claw-back-approved-spending-122467621): Article `download()` failed with 404 Client Error: Not Found for url: https://abcnews.go.com/Business/wireStory/trump-formally-asks-congress-claw-back-approved-spending-122467621 on URL https://abcnews.go.com/Business/wireStory/trump-formally-asks-congress-claw-back-approved-spending-122467621\n",
      "‚ùå Failed at index 547 (https://www.foxnews.com/media/ny-times-columnist-compares-elon-musk-historys-worst-murderers-over-usaid-cuts): Article `download()` failed with 404 Client Error: Not Found for url: https://www.foxnews.com/media/ny-times-columnist-compares-elon-musk-historys-worst-murderers-over-usaid-cuts on URL https://www.foxnews.com/media/ny-times-columnist-compares-elon-musk-historys-worst-murderers-over-usaid-cuts\n",
      "‚ùå Failed at index 566 (https://www.forbes.com/sites/daniellenierenberg/2025/06/06/food-safety-depends-on-every-link-in-the-supply-chain/): Article `download()` failed with 403 Client Error: Max restarts limit reached for url: https://www.forbes.com/sites/daniellenierenberg/2025/06/06/food-safety-depends-on-every-link-in-the-supply-chain/ on URL https://www.forbes.com/sites/daniellenierenberg/2025/06/06/food-safety-depends-on-every-link-in-the-supply-chain/\n",
      "‚ùå Failed at index 570 (https://www.newsweek.com/new-york-state-lawsuit-snap-benefit-theft-2087190): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.newsweek.com/new-york-state-lawsuit-snap-benefit-theft-2087190 on URL https://www.newsweek.com/new-york-state-lawsuit-snap-benefit-theft-2087190\n",
      "‚ùå Failed at index 604 (https://www.newsweek.com/snap-recipients-get-extra-money-this-month-california-2085401): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.newsweek.com/snap-recipients-get-extra-money-this-month-california-2085401 on URL https://www.newsweek.com/snap-recipients-get-extra-money-this-month-california-2085401\n",
      "‚ùå Failed at index 605 (https://www.newsweek.com/trump-wont-kingunless-we-bow-opinion-2084503): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.newsweek.com/trump-wont-kingunless-we-bow-opinion-2084503 on URL https://www.newsweek.com/trump-wont-kingunless-we-bow-opinion-2084503\n",
      "‚ùå Failed at index 611 (https://www.forbes.com/sites/elainemaag/2025/06/12/one-big-beautiful-bill-designed-for-wealthy-senate-can-change-that/): Article `download()` failed with 403 Client Error: Max restarts limit reached for url: https://www.forbes.com/sites/elainemaag/2025/06/12/one-big-beautiful-bill-designed-for-wealthy-senate-can-change-that/ on URL https://www.forbes.com/sites/elainemaag/2025/06/12/one-big-beautiful-bill-designed-for-wealthy-senate-can-change-that/\n",
      "‚ùå Failed at index 613 (https://gothamist.com/news/victims-of-food-benefits-theft-sue-ny-over-outdated-tech-they-say-put-them-at-risk): Article `download()` failed with 403 Client Error: Forbidden for url: https://gothamist.com/news/victims-of-food-benefits-theft-sue-ny-over-outdated-tech-they-say-put-them-at-risk on URL https://gothamist.com/news/victims-of-food-benefits-theft-sue-ny-over-outdated-tech-they-say-put-them-at-risk\n",
      "‚ùå Failed at index 634 (https://www.newsweek.com/three-states-ban-junk-food-snap-benefits-2083778): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.newsweek.com/three-states-ban-junk-food-snap-benefits-2083778 on URL https://www.newsweek.com/three-states-ban-junk-food-snap-benefits-2083778\n",
      "‚ùå Failed at index 639 (https://www.foxnews.com/politics/trump-admin-approves-waivers-three-states-ban-soda-other-junk-food-from-public-food-programs): Article `download()` failed with 404 Client Error: Not Found for url: https://www.foxnews.com/politics/trump-admin-approves-waivers-three-states-ban-soda-other-junk-food-from-public-food-programs on URL https://www.foxnews.com/politics/trump-admin-approves-waivers-three-states-ban-soda-other-junk-food-from-public-food-programs\n",
      "‚ùå Failed at index 640 (https://financialpost.com/globe-newswire/the-north-west-company-inc-announces-first-quarter-earnings-and-a-quarterly-dividend-5): Article `download()` failed with 403 Client Error: Forbidden for url: https://financialpost.com/globe-newswire/the-north-west-company-inc-announces-first-quarter-earnings-and-a-quarterly-dividend-5 on URL https://financialpost.com/globe-newswire/the-north-west-company-inc-announces-first-quarter-earnings-and-a-quarterly-dividend-5\n",
      "‚ùå Failed at index 649 (https://www.newsweek.com/snap-cuts-warning-85-million-rhode-island-2083296): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.newsweek.com/snap-cuts-warning-85-million-rhode-island-2083296 on URL https://www.newsweek.com/snap-cuts-warning-85-million-rhode-island-2083296\n",
      "‚ùå Failed at index 656 (https://www.newsweek.com/snap-benefit-theft-explodes-across-us-2082664): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.newsweek.com/snap-benefit-theft-explodes-across-us-2082664 on URL https://www.newsweek.com/snap-benefit-theft-explodes-across-us-2082664\n",
      "‚ùå Failed at index 658 (https://financialpost.com/pmn/republican-senators-to-watch-in-the-maneuvering-over-trumps-big-bill): Article `download()` failed with 403 Client Error: Forbidden for url: https://financialpost.com/pmn/republican-senators-to-watch-in-the-maneuvering-over-trumps-big-bill on URL https://financialpost.com/pmn/republican-senators-to-watch-in-the-maneuvering-over-trumps-big-bill\n",
      "‚ùå Failed at index 663 (https://www.newsweek.com/how-snap-benefits-impacted-trump-tax-bill-2081781): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.newsweek.com/how-snap-benefits-impacted-trump-tax-bill-2081781 on URL https://www.newsweek.com/how-snap-benefits-impacted-trump-tax-bill-2081781\n",
      "‚ùå Failed at index 674 (https://financialpost.com/globe-newswire/rental-living-reinvented-signal-delivers-more-than-500-rental-residences-to-south-vancouvers-cambie-corridor): Article `download()` failed with 403 Client Error: Forbidden for url: https://financialpost.com/globe-newswire/rental-living-reinvented-signal-delivers-more-than-500-rental-residences-to-south-vancouvers-cambie-corridor on URL https://financialpost.com/globe-newswire/rental-living-reinvented-signal-delivers-more-than-500-rental-residences-to-south-vancouvers-cambie-corridor\n",
      "‚ùå Failed at index 683 (https://www.globalresearch.ca/brits-ukrainians-plotting-manipulate-trump-russia/5891465): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.globalresearch.ca/brits-ukrainians-plotting-manipulate-trump-russia/5891465 on URL https://www.globalresearch.ca/brits-ukrainians-plotting-manipulate-trump-russia/5891465\n",
      "‚ùå Failed at index 684 (https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_72612d04-fa21-4bd6-8c96-5642e0c8a31d): Article `download()` failed with 401 Client Error: Unauthorized for url: https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_72612d04-fa21-4bd6-8c96-5642e0c8a31d on URL https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_72612d04-fa21-4bd6-8c96-5642e0c8a31d\n",
      "‚ùå Failed at index 690 (https://www.forbes.com/sites/andrewwilliams/2025/06/18/garmin-ditches-screens-for-dedicated-sleep-tracking-wearable/): Article `download()` failed with 403 Client Error: Max restarts limit reached for url: https://www.forbes.com/sites/andrewwilliams/2025/06/18/garmin-ditches-screens-for-dedicated-sleep-tracking-wearable/ on URL https://www.forbes.com/sites/andrewwilliams/2025/06/18/garmin-ditches-screens-for-dedicated-sleep-tracking-wearable/\n",
      "‚ùå Failed at index 721 (https://articles.mercola.com/sites/articles/archive/2025/06/18/scalp-microbiome.aspx): Article `download()` failed with 403 Client Error: Forbidden for url: https://articles.mercola.com/sites/articles/archive/2025/06/18/scalp-microbiome.aspx on URL https://articles.mercola.com/sites/articles/archive/2025/06/18/scalp-microbiome.aspx\n",
      "‚ùå Failed at index 739 (https://www.forbes.com/sites/angelicagutierrez/2025/06/17/steps-to-support-employees-amid-national-turmoil-and-immigration-raids/): Article `download()` failed with 403 Client Error: Max restarts limit reached for url: https://www.forbes.com/sites/angelicagutierrez/2025/06/17/steps-to-support-employees-amid-national-turmoil-and-immigration-raids/ on URL https://www.forbes.com/sites/angelicagutierrez/2025/06/17/steps-to-support-employees-amid-national-turmoil-and-immigration-raids/\n",
      "‚ùå Failed at index 747 (https://financialpost.com/globe-newswire/youtube-star-kyler-ferris-brings-164m-team-to-exp-realty-launches-first-of-its-kind-video-powered-mega-team-in-houston): Article `download()` failed with 403 Client Error: Forbidden for url: https://financialpost.com/globe-newswire/youtube-star-kyler-ferris-brings-164m-team-to-exp-realty-launches-first-of-its-kind-video-powered-mega-team-in-houston on URL https://financialpost.com/globe-newswire/youtube-star-kyler-ferris-brings-164m-team-to-exp-realty-launches-first-of-its-kind-video-powered-mega-team-in-houston\n",
      "‚ùå Failed at index 762 (https://www.irishtimes.comhttps://www.nytimes.com/2025/06/16/world/canada/trump-g7-russia-ukraine.html): Article `download()` failed with HTTPSConnectionPool(host='www.irishtimes.comhttps', port=443): Max retries exceeded with url: //www.nytimes.com/2025/06/16/world/canada/trump-g7-russia-ukraine.html (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x72b3ab438790>: Failed to establish a new connection: [Errno -2] Name or service not known')) on URL https://www.irishtimes.comhttps://www.nytimes.com/2025/06/16/world/canada/trump-g7-russia-ukraine.html\n",
      "‚ùå Failed at index 764 (https://www.foxnews.com/travel/message-bottle-from-1983-washes-up-remote-island-historical-contents-intact): Article `download()` failed with 404 Client Error: Not Found for url: https://www.foxnews.com/travel/message-bottle-from-1983-washes-up-remote-island-historical-contents-intact on URL https://www.foxnews.com/travel/message-bottle-from-1983-washes-up-remote-island-historical-contents-intact\n",
      "‚ùå Failed at index 774 (https://www.forbes.com/sites/chuckbrooks/2025/05/28/public-private-sector-partnerships--for-space-systems-innovation-and-security/): Article `download()` failed with 403 Client Error: Max restarts limit reached for url: https://www.forbes.com/sites/chuckbrooks/2025/05/28/public-private-sector-partnerships--for-space-systems-innovation-and-security/ on URL https://www.forbes.com/sites/chuckbrooks/2025/05/28/public-private-sector-partnerships--for-space-systems-innovation-and-security/\n",
      "‚ùå Failed at index 776 (https://abcnews.go.com/US/wireStory/alabama-study-reveals-hurricane-resilience-programs-paying-off-122147193): Article `download()` failed with 404 Client Error: Not Found for url: https://abcnews.go.com/US/wireStory/alabama-study-reveals-hurricane-resilience-programs-paying-off-122147193 on URL https://abcnews.go.com/US/wireStory/alabama-study-reveals-hurricane-resilience-programs-paying-off-122147193\n",
      "‚ùå Failed at index 777 (https://financialpost.com/pmn/alabama-study-reveals-hurricane-resilience-programs-are-paying-off-for-homeowners-and-insurers): Article `download()` failed with 403 Client Error: Forbidden for url: https://financialpost.com/pmn/alabama-study-reveals-hurricane-resilience-programs-are-paying-off-for-homeowners-and-insurers on URL https://financialpost.com/pmn/alabama-study-reveals-hurricane-resilience-programs-are-paying-off-for-homeowners-and-insurers\n",
      "‚ùå Failed at index 778 (https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_d5ab933e-ad3a-4de5-98c8-044ce40430fe): Article `download()` failed with 401 Client Error: Unauthorized for url: https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_d5ab933e-ad3a-4de5-98c8-044ce40430fe on URL https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_d5ab933e-ad3a-4de5-98c8-044ce40430fe\n",
      "‚ùå Failed at index 779 (https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_9ff74930-26e9-41e1-bf43-ae1e0b579d74): Article `download()` failed with 401 Client Error: Unauthorized for url: https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_9ff74930-26e9-41e1-bf43-ae1e0b579d74 on URL https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_9ff74930-26e9-41e1-bf43-ae1e0b579d74\n",
      "‚ùå Failed at index 781 (https://www.forbes.com/councils/forbesbusinesscouncil/2025/05/19/your-brain-and-resilience-the-science-behind-handling-work-stress/): Article `download()` failed with 403 Client Error: Max restarts limit reached for url: https://www.forbes.com/councils/forbesbusinesscouncil/2025/05/19/your-brain-and-resilience-the-science-behind-handling-work-stress/ on URL https://www.forbes.com/councils/forbesbusinesscouncil/2025/05/19/your-brain-and-resilience-the-science-behind-handling-work-stress/\n",
      "‚ùå Failed at index 791 (https://www.singletracks.com/?p=695115): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.singletracks.com/?p=695115 on URL https://www.singletracks.com/?p=695115\n",
      "‚ùå Failed at index 797 (https://www.rand.org/pubs/research_reports/RRA2120-2.html): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.rand.org/pubs/research_reports/RRA2120-2.html on URL https://www.rand.org/pubs/research_reports/RRA2120-2.html\n",
      "‚ùå Failed at index 800 (https://entrepreneurship.blogs.ie.edu/unleash-the-potential-creative-church-youth-programs-ideas-pdf-resources-included/): Article `download()` failed with 410 Client Error: Gone for url: https://entrepreneurship.blogs.ie.edu/unleash-the-potential-creative-church-youth-programs-ideas-pdf-resources-included/ on URL https://entrepreneurship.blogs.ie.edu/unleash-the-potential-creative-church-youth-programs-ideas-pdf-resources-included/\n",
      "‚ùå Failed at index 830 (https://statetimes.in/cat-grants-relief-to-po-rajesh-bakshi-in-seniority-dispute-orders-restoration-of-merit-based-position/): Article `download()` failed with HTTPSConnectionPool(host='statetimes.in', port=443): Read timed out. on URL https://statetimes.in/cat-grants-relief-to-po-rajesh-bakshi-in-seniority-dispute-orders-restoration-of-merit-based-position/\n",
      "‚ùå Failed at index 833 (https://www.abc.net.au/news/2025-06-12/brisbane-council-trees-damage-cyclone-alfred/105374802): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.abc.net.au/news/2025-06-12/brisbane-council-trees-damage-cyclone-alfred/105374802 on URL https://www.abc.net.au/news/2025-06-12/brisbane-council-trees-damage-cyclone-alfred/105374802\n",
      "‚ùå Failed at index 903 (https://www.finextra.com/pressarticle/105708/rti-and-step2-participants-across-14-countries-to-adopt-ebas-vop-solution): Article `download()` failed with 403 Client Error: Forbidden: Access is denied. for url: https://www.finextra.com/pressarticle/105708/rti-and-step2-participants-across-14-countries-to-adopt-ebas-vop-solution on URL https://www.finextra.com/pressarticle/105708/rti-and-step2-participants-across-14-countries-to-adopt-ebas-vop-solution\n",
      "‚ùå Failed at index 943 (https://tvn24.pl/biznes/z-kraju/znaczna-czesc-swiadczen-jest-finansowana-z-biezacych-skladek-raport-zus-st8501782): Article `download()` failed with HTTPSConnectionPool(host='tvn24.pl', port=443): Read timed out. (read timeout=7) on URL https://tvn24.pl/biznes/z-kraju/znaczna-czesc-swiadczen-jest-finansowana-z-biezacych-skladek-raport-zus-st8501782\n",
      "‚ùå Failed at index 1028 (https://www.justjared.com/2025/06/16/aubrey-anderson-emmons-comes-out-as-bisexual-by-quoting-iconic-modern-family-scene/): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.justjared.com/2025/06/16/aubrey-anderson-emmons-comes-out-as-bisexual-by-quoting-iconic-modern-family-scene/ on URL https://www.justjared.com/2025/06/16/aubrey-anderson-emmons-comes-out-as-bisexual-by-quoting-iconic-modern-family-scene/\n",
      "‚ùå Failed at index 1055 (https://www.newsweek.com/woman-asked-dog-sit-problem-leash-2082777): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.newsweek.com/woman-asked-dog-sit-problem-leash-2082777 on URL https://www.newsweek.com/woman-asked-dog-sit-problem-leash-2082777\n",
      "‚ùå Failed at index 1069 (https://www.forbes.com/sites/karlmoore/2025/06/05/beyond-the-fare-why-account-based-ticketing-is-a-leadership-move/): Article `download()` failed with 403 Client Error: Max restarts limit reached for url: https://www.forbes.com/sites/karlmoore/2025/06/05/beyond-the-fare-why-account-based-ticketing-is-a-leadership-move/ on URL https://www.forbes.com/sites/karlmoore/2025/06/05/beyond-the-fare-why-account-based-ticketing-is-a-leadership-move/\n",
      "‚ùå Failed at index 1075 (https://www.forbes.com/sites/jerylbrunner/2025/06/04/curtain-up-on-85-years-of-american-ballet-theatre/): Article `download()` failed with 403 Client Error: Max restarts limit reached for url: https://www.forbes.com/sites/jerylbrunner/2025/06/04/curtain-up-on-85-years-of-american-ballet-theatre/ on URL https://www.forbes.com/sites/jerylbrunner/2025/06/04/curtain-up-on-85-years-of-american-ballet-theatre/\n",
      "‚ùå Failed at index 1093 (https://book.douban.com/review/16748525/): Article `download()` failed with HTTPSConnectionPool(host='book.douban.com', port=443): Read timed out. (read timeout=7) on URL https://book.douban.com/review/16748525/\n",
      "‚ùå Failed at index 1120 (https://www.forbes.com/sites/cfo/2025/06/17/why-2026-will-be-a-big-year-for-ai-in-business-finance/): Article `download()` failed with 403 Client Error: Max restarts limit reached for url: https://www.forbes.com/sites/cfo/2025/06/17/why-2026-will-be-a-big-year-for-ai-in-business-finance/ on URL https://www.forbes.com/sites/cfo/2025/06/17/why-2026-will-be-a-big-year-for-ai-in-business-finance/\n",
      "‚ùå Failed at index 1127 (https://financialpost.com/pmn/business-wire-news-releases-pmn/engene-reports-inducement-grants-under-nasdaq-listing-rule-5635c4-5): Article `download()` failed with 403 Client Error: Forbidden for url: https://financialpost.com/pmn/business-wire-news-releases-pmn/engene-reports-inducement-grants-under-nasdaq-listing-rule-5635c4-5 on URL https://financialpost.com/pmn/business-wire-news-releases-pmn/engene-reports-inducement-grants-under-nasdaq-listing-rule-5635c4-5\n",
      "‚ùå Failed at index 1130 (https://www.nouvelobs.com/economie/20250617.OBS105024/decarbonation-le-backlash-n-a-pas-encore-contamine-les-entreprises-europeennes.html): Article `download()` failed with 406 Client Error: Not Acceptable for url: https://www.nouvelobs.com/economie/20250617.OBS105024/decarbonation-le-backlash-n-a-pas-encore-contamine-les-entreprises-europeennes.html on URL https://www.nouvelobs.com/economie/20250617.OBS105024/decarbonation-le-backlash-n-a-pas-encore-contamine-les-entreprises-europeennes.html\n",
      "‚ùå Failed at index 1136 (https://www.forbes.com/sites/digital-assets/2025/06/16/10-trends-in-ai-and-blockchain-from-singularity-chile/): Article `download()` failed with 403 Client Error: Max restarts limit reached for url: https://www.forbes.com/sites/digital-assets/2025/06/16/10-trends-in-ai-and-blockchain-from-singularity-chile/ on URL https://www.forbes.com/sites/digital-assets/2025/06/16/10-trends-in-ai-and-blockchain-from-singularity-chile/\n",
      "‚ùå Failed at index 1152 (https://www.forbes.com/councils/forbesbusinesscouncil/2025/06/13/why-the-emotion-of-leadership-matters-just-as-much-as-strategy/): Article `download()` failed with 403 Client Error: Max restarts limit reached for url: https://www.forbes.com/councils/forbesbusinesscouncil/2025/06/13/why-the-emotion-of-leadership-matters-just-as-much-as-strategy/ on URL https://www.forbes.com/councils/forbesbusinesscouncil/2025/06/13/why-the-emotion-of-leadership-matters-just-as-much-as-strategy/\n",
      "‚ùå Failed at index 1162 (https://financialpost.com/pmn/business-wire-news-releases-pmn/engene-reports-second-quarter-2025-financial-results-and-provides-business-update): Article `download()` failed with 403 Client Error: Forbidden for url: https://financialpost.com/pmn/business-wire-news-releases-pmn/engene-reports-second-quarter-2025-financial-results-and-provides-business-update on URL https://financialpost.com/pmn/business-wire-news-releases-pmn/engene-reports-second-quarter-2025-financial-results-and-provides-business-update\n",
      "‚ùå Failed at index 1165 (https://www.forbes.com/sites/christopherhelman/2025/06/12/amid-oil-downturn-fast-growing-permian-resources-still-shines/): Article `download()` failed with 403 Client Error: Max restarts limit reached for url: https://www.forbes.com/sites/christopherhelman/2025/06/12/amid-oil-downturn-fast-growing-permian-resources-still-shines/ on URL https://www.forbes.com/sites/christopherhelman/2025/06/12/amid-oil-downturn-fast-growing-permian-resources-still-shines/\n",
      "‚ùå Failed at index 1170 (https://www.forbes.com/sites/alexanderpuutio/2025/06/11/tracksuits-25m-raise-shows-why-brand-metrics-are-the-next-growth-engine/): Article `download()` failed with 403 Client Error: Max restarts limit reached for url: https://www.forbes.com/sites/alexanderpuutio/2025/06/11/tracksuits-25m-raise-shows-why-brand-metrics-are-the-next-growth-engine/ on URL https://www.forbes.com/sites/alexanderpuutio/2025/06/11/tracksuits-25m-raise-shows-why-brand-metrics-are-the-next-growth-engine/\n",
      "‚ùå Failed at index 1178 (https://www.forbes.com/sites/feliciajackson/2025/06/11/the-9-trillion-climate-opportunity-hiding-in-plain-sight/): Article `download()` failed with 403 Client Error: Max restarts limit reached for url: https://www.forbes.com/sites/feliciajackson/2025/06/11/the-9-trillion-climate-opportunity-hiding-in-plain-sight/ on URL https://www.forbes.com/sites/feliciajackson/2025/06/11/the-9-trillion-climate-opportunity-hiding-in-plain-sight/\n",
      "‚ùå Failed at index 1182 (https://www.forbes.com/sites/alexanderpuutio/2025/06/10/why-this-nasdaq-listed-ceo-changed-his-mind-about-ai-and-what-it-took/): Article `download()` failed with 403 Client Error: Max restarts limit reached for url: https://www.forbes.com/sites/alexanderpuutio/2025/06/10/why-this-nasdaq-listed-ceo-changed-his-mind-about-ai-and-what-it-took/ on URL https://www.forbes.com/sites/alexanderpuutio/2025/06/10/why-this-nasdaq-listed-ceo-changed-his-mind-about-ai-and-what-it-took/\n",
      "‚ùå Failed at index 1221 (https://www.forbes.com/sites/catzxwang/2025/06/11/founder-of-chinese-camera-maker-insta360-becomes-a-billionaire-upon-ipo/): Article `download()` failed with 403 Client Error: Max restarts limit reached for url: https://www.forbes.com/sites/catzxwang/2025/06/11/founder-of-chinese-camera-maker-insta360-becomes-a-billionaire-upon-ipo/ on URL https://www.forbes.com/sites/catzxwang/2025/06/11/founder-of-chinese-camera-maker-insta360-becomes-a-billionaire-upon-ipo/\n",
      "‚ùå Failed at index 1228 (https://www.forbes.com/sites/zinnialee/2025/06/09/midas-list-2025-asias-top-venture-capitalists-ride-ai-wave-as-china-reclaims-tech-spotlight/): Article `download()` failed with 403 Client Error: Max restarts limit reached for url: https://www.forbes.com/sites/zinnialee/2025/06/09/midas-list-2025-asias-top-venture-capitalists-ride-ai-wave-as-china-reclaims-tech-spotlight/ on URL https://www.forbes.com/sites/zinnialee/2025/06/09/midas-list-2025-asias-top-venture-capitalists-ride-ai-wave-as-china-reclaims-tech-spotlight/\n",
      "‚ùå Failed at index 1242 (https://epravda.com.ua/projects/drugiy-nayuspishnishiy-807447/): Article `download()` failed with 403 Client Error: Forbidden for url: https://epravda.com.ua/projects/drugiy-nayuspishnishiy-807447/ on URL https://epravda.com.ua/projects/drugiy-nayuspishnishiy-807447/\n",
      "‚ùå Failed at index 1251 (https://www.dino.com.br/releases/paco-do-frevo-anuncia-inauguracao-de-exposicao-principal-dino890304214131): Article `download()` failed with HTTPSConnectionPool(host='www.dino.com.br', port=443): Max retries exceeded with url: /releases/paco-do-frevo-anuncia-inauguracao-de-exposicao-principal-dino890304214131 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1123)'))) on URL https://www.dino.com.br/releases/paco-do-frevo-anuncia-inauguracao-de-exposicao-principal-dino890304214131\n",
      "‚ùå Failed at index 1296 (https://financialpost.com/pmn/business-wire-news-releases-pmn/c3-solutions-releases-insightful-white-paper-on-todays-automotive-supply-chain-challenges): Article `download()` failed with 403 Client Error: Forbidden for url: https://financialpost.com/pmn/business-wire-news-releases-pmn/c3-solutions-releases-insightful-white-paper-on-todays-automotive-supply-chain-challenges on URL https://financialpost.com/pmn/business-wire-news-releases-pmn/c3-solutions-releases-insightful-white-paper-on-todays-automotive-supply-chain-challenges\n",
      "‚ùå Failed at index 1326 (https://www.newsweek.com/trump-phone-made-usa-price-2087213): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.newsweek.com/trump-phone-made-usa-price-2087213 on URL https://www.newsweek.com/trump-phone-made-usa-price-2087213\n",
      "‚ùå Failed at index 1344 (https://www.forbes.com/sites/greatspeculations/2025/06/18/how-will-kroger-stock-react-to-its-upcoming-earnings/): Article `download()` failed with 403 Client Error: Max restarts limit reached for url: https://www.forbes.com/sites/greatspeculations/2025/06/18/how-will-kroger-stock-react-to-its-upcoming-earnings/ on URL https://www.forbes.com/sites/greatspeculations/2025/06/18/how-will-kroger-stock-react-to-its-upcoming-earnings/\n",
      "‚ùå Failed at index 1346 (https://www.forbes.com/sites/juliadhar/2025/06/18/exactly-what-is-an-ai-first-company/): Article `download()` failed with 403 Client Error: Max restarts limit reached for url: https://www.forbes.com/sites/juliadhar/2025/06/18/exactly-what-is-an-ai-first-company/ on URL https://www.forbes.com/sites/juliadhar/2025/06/18/exactly-what-is-an-ai-first-company/\n",
      "‚ùå Failed at index 1352 (https://financialpost.com/pmn/business-pmn/ex-spacex-staffers-raise-cash-for-defense-manufacturing-startup): Article `download()` failed with 403 Client Error: Forbidden for url: https://financialpost.com/pmn/business-pmn/ex-spacex-staffers-raise-cash-for-defense-manufacturing-startup on URL https://financialpost.com/pmn/business-pmn/ex-spacex-staffers-raise-cash-for-defense-manufacturing-startup\n",
      "‚ùå Failed at index 1354 (https://cryptoslate.com/chinese-bitcoin-mining-giants-move-production-to-us-amid-tariff-tensions/): Article `download()` failed with 403 Client Error: Forbidden for url: https://cryptoslate.com/chinese-bitcoin-mining-giants-move-production-to-us-amid-tariff-tensions/ on URL https://cryptoslate.com/chinese-bitcoin-mining-giants-move-production-to-us-amid-tariff-tensions/\n",
      "‚ùå Failed at index 1355 (https://financialpost.com/globe-newswire/dynacor-group-announces-election-of-directors): Article `download()` failed with 403 Client Error: Forbidden for url: https://financialpost.com/globe-newswire/dynacor-group-announces-election-of-directors on URL https://financialpost.com/globe-newswire/dynacor-group-announces-election-of-directors\n",
      "‚ùå Failed at index 1361 (https://thehackernews.com/2025/06/water-curse-hijacks-76-github-accounts.html): Article `download()` failed with 403 Client Error: Forbidden for url: https://thehackernews.com/2025/06/water-curse-hijacks-76-github-accounts.html on URL https://thehackernews.com/2025/06/water-curse-hijacks-76-github-accounts.html\n",
      "‚ùå Failed at index 1370 (https://financialpost.com/pmn/construction-sector-ramping-up-tech-investments-to-address-labour-gap-kpmg-survey): Article `download()` failed with 403 Client Error: Forbidden for url: https://financialpost.com/pmn/construction-sector-ramping-up-tech-investments-to-address-labour-gap-kpmg-survey on URL https://financialpost.com/pmn/construction-sector-ramping-up-tech-investments-to-address-labour-gap-kpmg-survey\n",
      "‚ùå Failed at index 1371 (https://www.euractiv.com/section/eet/news/eu-commission-sides-with-berlin-in-switchgear-row-with-france/): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.euractiv.com/section/eet/news/eu-commission-sides-with-berlin-in-switchgear-row-with-france/ on URL https://www.euractiv.com/section/eet/news/eu-commission-sides-with-berlin-in-switchgear-row-with-france/\n",
      "‚ùå Failed at index 1412 (https://www.forbes.com/councils/forbesnonprofitcouncil/2025/06/06/why-every-nonprofit-needs-a-trauma-informed-virtual-safe-space/): Article `download()` failed with 403 Client Error: Max restarts limit reached for url: https://www.forbes.com/councils/forbesnonprofitcouncil/2025/06/06/why-every-nonprofit-needs-a-trauma-informed-virtual-safe-space/ on URL https://www.forbes.com/councils/forbesnonprofitcouncil/2025/06/06/why-every-nonprofit-needs-a-trauma-informed-virtual-safe-space/\n",
      "‚ùå Failed at index 1421 (https://financialpost.com/globe-newswire/igniting-awareness-extinguishing-risk-enhancing-fire-safety-in-indigenous-communities-across-canada-to-help-save-more-lives): Article `download()` failed with 403 Client Error: Forbidden for url: https://financialpost.com/globe-newswire/igniting-awareness-extinguishing-risk-enhancing-fire-safety-in-indigenous-communities-across-canada-to-help-save-more-lives on URL https://financialpost.com/globe-newswire/igniting-awareness-extinguishing-risk-enhancing-fire-safety-in-indigenous-communities-across-canada-to-help-save-more-lives\n",
      "‚ùå Failed at index 1440 (https://www.forbes.com/sites/we-dont-have-time/2025/05/29/will-climate-week-nyc-2025-be-a-bust-no-says-six-key-insiders/): Article `download()` failed with 403 Client Error: Max restarts limit reached for url: https://www.forbes.com/sites/we-dont-have-time/2025/05/29/will-climate-week-nyc-2025-be-a-bust-no-says-six-key-insiders/ on URL https://www.forbes.com/sites/we-dont-have-time/2025/05/29/will-climate-week-nyc-2025-be-a-bust-no-says-six-key-insiders/\n",
      "‚ùå Failed at index 1455 (https://entrepreneurship.blogs.ie.edu/navigating-hurricane-season-in-st-john-us-virgin-islands-a-comprehensive-guide/): Article `download()` failed with 410 Client Error: Gone for url: https://entrepreneurship.blogs.ie.edu/navigating-hurricane-season-in-st-john-us-virgin-islands-a-comprehensive-guide/ on URL https://entrepreneurship.blogs.ie.edu/navigating-hurricane-season-in-st-john-us-virgin-islands-a-comprehensive-guide/\n",
      "‚ùå Failed at index 1461 (https://www.forbes.com/councils/forbesbusinesscouncil/2025/05/20/how-c-stores-can-function-as-essential-infrastructure-during-crises/): Article `download()` failed with 403 Client Error: Max restarts limit reached for url: https://www.forbes.com/councils/forbesbusinesscouncil/2025/05/20/how-c-stores-can-function-as-essential-infrastructure-during-crises/ on URL https://www.forbes.com/councils/forbesbusinesscouncil/2025/05/20/how-c-stores-can-function-as-essential-infrastructure-during-crises/\n",
      "‚ùå Failed at index 1475 (https://www.singletracks.com/mtb-tips/heat-acclimation-training-tips-to-get-ready-for-hot-summer-rides/): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.singletracks.com/mtb-tips/heat-acclimation-training-tips-to-get-ready-for-hot-summer-rides/ on URL https://www.singletracks.com/mtb-tips/heat-acclimation-training-tips-to-get-ready-for-hot-summer-rides/\n",
      "‚ùå Failed at index 1496 (https://www.abc.net.au/news/2025-06-01/seawalls-in-the-pacific-climate-change-adaptation/105342110): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.abc.net.au/news/2025-06-01/seawalls-in-the-pacific-climate-change-adaptation/105342110 on URL https://www.abc.net.au/news/2025-06-01/seawalls-in-the-pacific-climate-change-adaptation/105342110\n",
      "‚ùå Failed at index 1516 (https://www.finextra.com/blogposting/28706/beware-the-delta-why-bank-boards-brilliant-strategies-vanish-inside-their-mobile-apps): Article `download()` failed with 403 Client Error: Forbidden: Access is denied. for url: https://www.finextra.com/blogposting/28706/beware-the-delta-why-bank-boards-brilliant-strategies-vanish-inside-their-mobile-apps on URL https://www.finextra.com/blogposting/28706/beware-the-delta-why-bank-boards-brilliant-strategies-vanish-inside-their-mobile-apps\n",
      "‚ùå Failed at index 1517 (https://financialpost.com/pmn/business-wire-news-releases-pmn/bts-named-a-2025-top-50-consulting-firm-by-the-consulting-report): Article `download()` failed with 403 Client Error: Forbidden for url: https://financialpost.com/pmn/business-wire-news-releases-pmn/bts-named-a-2025-top-50-consulting-firm-by-the-consulting-report on URL https://financialpost.com/pmn/business-wire-news-releases-pmn/bts-named-a-2025-top-50-consulting-firm-by-the-consulting-report\n",
      "‚ùå Failed at index 1519 (https://www.euractiv.com/section/politics/opinion/the-brief-between-a-rock-and-a-hard-place-what-to-do-with-macron/): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.euractiv.com/section/politics/opinion/the-brief-between-a-rock-and-a-hard-place-what-to-do-with-macron/ on URL https://www.euractiv.com/section/politics/opinion/the-brief-between-a-rock-and-a-hard-place-what-to-do-with-macron/\n",
      "‚ùå Failed at index 1525 (https://www.euractiv.com/section/tech/opinion/revitalizing-europes-regions-amazons-investment-in-central-and-eastern-europe/): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.euractiv.com/section/tech/opinion/revitalizing-europes-regions-amazons-investment-in-central-and-eastern-europe/ on URL https://www.euractiv.com/section/tech/opinion/revitalizing-europes-regions-amazons-investment-in-central-and-eastern-europe/\n",
      "‚ùå Failed at index 1546 (https://www.ibtimes.com/rakesh-kumar-mali-leader-revolutionizing-software-engineering-3776047): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.ibtimes.com/rakesh-kumar-mali-leader-revolutionizing-software-engineering-3776047 on URL https://www.ibtimes.com/rakesh-kumar-mali-leader-revolutionizing-software-engineering-3776047\n",
      "‚ùå Failed at index 1548 (https://financialpost.com/pmn/business-wire-news-releases-pmn/sunmi-opens-its-first-north-american-experience-center-in-atlanta): Article `download()` failed with 403 Client Error: Forbidden for url: https://financialpost.com/pmn/business-wire-news-releases-pmn/sunmi-opens-its-first-north-american-experience-center-in-atlanta on URL https://financialpost.com/pmn/business-wire-news-releases-pmn/sunmi-opens-its-first-north-american-experience-center-in-atlanta\n",
      "‚ùå Failed at index 1560 (https://www.forbes.com/councils/forbestechcouncil/2025/06/17/secure-by-design-in-the-ai-and-cloud-era-safeguarding-modern-applications/): Article `download()` failed with 403 Client Error: Max restarts limit reached for url: https://www.forbes.com/councils/forbestechcouncil/2025/06/17/secure-by-design-in-the-ai-and-cloud-era-safeguarding-modern-applications/ on URL https://www.forbes.com/councils/forbestechcouncil/2025/06/17/secure-by-design-in-the-ai-and-cloud-era-safeguarding-modern-applications/\n",
      "‚ùå Failed at index 1565 (https://www.forbes.com/councils/forbestechcouncil/2025/06/17/pilot-scale-succeed-in-the-digital-era-an-agile-blueprint-for-modernizing-global-supply-chains/): Article `download()` failed with 403 Client Error: Max restarts limit reached for url: https://www.forbes.com/councils/forbestechcouncil/2025/06/17/pilot-scale-succeed-in-the-digital-era-an-agile-blueprint-for-modernizing-global-supply-chains/ on URL https://www.forbes.com/councils/forbestechcouncil/2025/06/17/pilot-scale-succeed-in-the-digital-era-an-agile-blueprint-for-modernizing-global-supply-chains/\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-837f5f0dfc41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0marticle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArticle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0marticle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0marticle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mfull_texts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/newspaper/article.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self, input_html, title, recursion_counter)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput_html\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                 \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_html_2XX_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequestException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArticleDownloadState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFAILED_RESPONSE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/newspaper/network.py\u001b[0m in \u001b[0;36mget_html_2XX_only\u001b[0;34m(url, config, response)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_get_html_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     response = requests.get(\n\u001b[0m\u001b[1;32m     63\u001b[0m         url=url, **get_request_kwargs(timeout, useragent, proxies, headers))\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    528\u001b[0m         }\n\u001b[1;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    671\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    424\u001b[0m                     \u001b[0;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    419\u001b[0m                 \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1345\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1347\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1348\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1241\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# newsapi_scraper.py\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from newspaper import Article\n",
    "import time\n",
    "\n",
    "# --- PARAMETERS ---\n",
    "api_key = 'bc6c52fd05ee4e63827b7cf45fa0bdb2'\n",
    "keywords = [\n",
    "    # Core USAID and aid-related\n",
    "    \"USAID\", \"foreign aid\", \"aid cuts\", \"Trump aid cuts\", \"USAID funding\",\n",
    "    \"project shutdown\", \"development funding\", \"NGO funding\", \"foreign assistance\",\n",
    "    \"terminated projects\",\n",
    "\n",
    "    # Specific USAID programs and acronyms\n",
    "    \"PEPFAR\", \"Feed the Future\", \"Tusome\", \"Power Africa\", \"USAID education\", \"USAID health\",\n",
    "    \"nutrition assistance\", \"malaria program\", \"HIV funding\", \"Crops and Dairy\", \"WASH\",\n",
    "    \"USAID climate\", \"USAID governance\", \"USAID transparency\", \"HIV USAID\",\n",
    "    \"resilience programs\", \"USAID devolution\", \"Youth program\",\n",
    "\n",
    "    # Organizations and initiatives\n",
    "    \"EECA\", \"RTI\", \"KPLP\", \"SoCha\", \"ABT\", \"Prosper Africa\", \"BCG\", \"IDG\",\n",
    "    \"KHPQS\", \"OVC\", \"Tujitegemee\", \"Tujenge Jamii\", \"supply chain\", \"PMI Evolve\",\n",
    "    \"sanitation project\", \"community resilience\", \"Owod project\", \"nutrition program\",\n",
    "    \"resilience project\", \"digital transformation\", \"Africa Water Facility\", \"trade reforms\",\n",
    "    \"solar health\", \"elections grant\"\n",
    "]\n",
    "\n",
    "from_date = '2025-05-19'\n",
    "page_size = 100\n",
    "max_pages = 1  # Loop through multiple pages\n",
    "filter_for_kenya = True  # Toggle to filter only articles that mention Kenya\n",
    "\n",
    "# --- FETCH ARTICLES ---\n",
    "all_articles = []\n",
    "for keyword in keywords:\n",
    "    print(f\"üîç Searching for articles with keyword: {keyword}\")\n",
    "    for page in range(1, max_pages + 1):\n",
    "        url = (\n",
    "            f'https://newsapi.org/v2/everything?'\n",
    "            f'q=\"{keyword}\"&'\n",
    "            f'from={from_date}&'\n",
    "            f'sortBy=publishedAt&'\n",
    "            f'pageSize={page_size}&'\n",
    "            f'page={page}&'\n",
    "            f'apiKey={api_key}'\n",
    "        )\n",
    "\n",
    "        response = requests.get(url)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"‚ùå Error: {response.status_code} - {response.json()}\")\n",
    "            break\n",
    "\n",
    "        articles = response.json().get('articles', [])\n",
    "        if not articles:\n",
    "            break\n",
    "\n",
    "        for article in articles:\n",
    "            all_articles.append({\n",
    "                'keyword': keyword,\n",
    "                'source': article['source']['name'],\n",
    "                'author': article.get('author'),\n",
    "                'title': article.get('title'),\n",
    "                'description': article.get('description'),\n",
    "                'content': article.get('content'),\n",
    "                'url': article.get('url'),\n",
    "                'published_at': article.get('publishedAt')\n",
    "            })\n",
    "\n",
    "# --- CONVERT TO DATAFRAME ---\n",
    "df = pd.DataFrame(all_articles)\n",
    "df.drop_duplicates(subset='url', inplace=True)\n",
    "df['published_at'] = pd.to_datetime(df['published_at'])\n",
    "\n",
    "# --- SAVE RAW ARTICLES ---\n",
    "raw_path = '../data/raw/leo_newsapi_articles.csv'\n",
    "df.to_csv(raw_path, index=False)\n",
    "print(f\"‚úÖ Fetched {len(df)} articles. Saved to {raw_path}\")\n",
    "\n",
    "# --- EXTRACT FULL TEXT USING newspaper3k ---\n",
    "print(\"üì∞ Extracting full text from article URLs...\")\n",
    "full_texts = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    url = row['url']\n",
    "    try:\n",
    "        article = Article(url)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        full_texts.append(article.text)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed at index {i} ({url}): {e}\")\n",
    "        full_texts.append(None)\n",
    "    if i % 10 == 0:\n",
    "        # Save progress checkpoint\n",
    "        df['full_text'] = pd.Series(full_texts)\n",
    "        df.to_csv('../data/raw/leo_newsapi_articles_checkpoint.csv', index=False)\n",
    "    time.sleep(1)\n",
    "\n",
    "# --- ADD FULL TEXT TO DATAFRAME ---\n",
    "df['full_text'] = full_texts\n",
    "\n",
    "# --- FINAL FILTER BASED ON FULL TEXT ---\n",
    "if filter_for_kenya:\n",
    "    df = df[\n",
    "        df['title'].str.contains('Kenya', case=False, na=False) |\n",
    "        df['description'].str.contains('Kenya', case=False, na=False) |\n",
    "        df['full_text'].str.contains('Kenya', case=False, na=False)\n",
    "    ]\n",
    "    print(f\"üìå Final filtered count: {len(df)} articles mentioning 'Kenya' after full text extraction.\")\n",
    "\n",
    "# --- SAVE FINAL ENRICHED ARTICLES ---\n",
    "final_path = '../data/raw/leo_newsapi_articles_enriched_full__2.csv'\n",
    "df.to_csv(final_path, index=False)\n",
    "print(f\"‚úÖ Done. Saved full-text articles to {final_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7427d1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Final article count after cleaning: 31\n",
      "üíæ Saved to '../data/raw/leo_newsapi_articles_cleaned_final.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Add full_text to the DataFrame (if not already added)\n",
    "df['full_text'] = pd.Series(full_texts)\n",
    "\n",
    "# 1. Drop rows where full_text is missing or empty\n",
    "df = df[df['full_text'].notna() & df['full_text'].str.strip().astype(bool)]\n",
    "\n",
    "# 2. Optional: Keep only articles that mention \"Kenya\"\n",
    "df = df[\n",
    "    df['title'].str.contains('Kenya', case=False, na=False) |\n",
    "    df['description'].str.contains('Kenya', case=False, na=False) |\n",
    "    df['full_text'].str.contains('Kenya', case=False, na=False)\n",
    "]\n",
    "\n",
    "print(f\"‚úÖ Final article count after cleaning: {len(df)}\")\n",
    "\n",
    "# 3. Save the clean version\n",
    "df.to_csv('../data/raw/leo_newsapi_articles_cleaned_final.csv', index=False)\n",
    "print(\"üíæ Saved to '../data/raw/leo_newsapi_articles_cleaned_final.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c119be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1472"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1355f91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I\\'m researching a fintech concept rooted in a simple but powerful idea: What if African citizens could directly micro-invest in their own infrastructure and economic development ‚Äî from as little as $1 ‚Äî instead of relying so heavily on foreign loans or aid?\\n\\nThe idea is inspired by:\\n\\nEthiopia\\'s Renaissance Dam, where despite China funding most of the $5B project, citizens contributed around $1B through bonds and mobile payments. It was a unifying act of nation-building.\\n\\nDenmark‚Äôs wind cooperatives, where tens of thousands of Danes co-own wind turbines, investing small amounts and earning steady returns from green energy sales.\\n\\nArla Foods, one of the world‚Äôs largest dairy companies, is owned by thousands of farmer-members across Europe.\\n\\nPark Slope Food Co-op (Brooklyn, USA) ‚Äì over 17,000 members run and own this highly successful grocery store. Members contribute labor and share in decision-making and cost savings ‚Äî a small-scale but high-functioning democratic economic model.\\n\\nThe concept:\\n\\nA micro-investment platform where citizens can fund infrastructure and industrial projects such as:\\n\\nSolar mini-grids\\n\\nRoads, ports, water systems\\n\\nLocal processing plants or factories\\n\\nAffordable housing\\n\\nAgricultural or logistics ventures\\n\\n\\nUsers invest tiny amounts (e.g. $1‚Äì$10) and track the project‚Äôs progress. They may receive a return over time or non-cash benefits (e.g. discounts, usage credits).\\n\\n\\nWhy this matters:\\n\\nToo often, African development is externally financed ‚Äî with debt, strings attached, and little citizen engagement. This model flips that:\\n\\nPeople co-own what they rely on\\n\\nGovernments gain domestic funding alternatives\\n\\nTrust, pride, and engagement are built from the ground up\\n\\n\\nChallenges (based on Reddit and expert feedback):\\n\\n1. Corruption and trust ‚Äî Citizens must see where every dollar goes. This means transparent ledgers, project dashboards, public audits, and perhaps smart contracts.\\n\\n\\n2. Regulation hell ‚Äî Securities laws differ by country. Government support or sandbox frameworks would be key.\\n\\n\\n3. Profitability ‚Äî Many infrastructure projects don‚Äôt generate immediate returns. The model may need to combine financial ROI with social ROI (access, pride, service).\\n\\n\\n4. Liquidity and exits ‚Äî Who buys your stake in a toll road if you need cash tomorrow?\\n\\n\\n5. \"Isn‚Äôt this just a tax?\" ‚Äî Not quite. Unlike taxes, citizens choose projects and can receive returns or benefits.\\n\\n\\nWhat I‚Äôm exploring:\\n\\nStarting with small-scale, single-country pilots (e.g. local solar or transport infrastructure)\\n\\nIntegrating traditional savings models like stokvels or SACCOs for community-level buy-in\\n\\nBuilding a trust layer first: partnerships with co-ops, municipalities, development banks, etc.\\n\\nExploring hybrid returns (financial + utility discounts) and different legal structures (co-ops, trusts, SPVs)\\n\\n\\nI\\'m not claiming this is the silver bullet ‚Äî but I do believe there\\'s space for a new model of citizen-led development funding in Africa.\\n\\nWhat are the biggest red flags? Where does this break down? Are there other models you think I should study or emulate?\\n\\nI‚Äôd love to hear your take.\\n\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[104,]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6df348bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/raw/leo_newsapi_articles_enriched_full.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-58dafbdb1413>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/raw/leo_newsapi_articles_enriched_full.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2008\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/raw/leo_newsapi_articles_enriched_full.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df =pd.read_csv('../data/raw/leo_newsapi_articles_enriched_full.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ccf7e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>search_term</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>created_date</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>permalink</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>usaid</td>\n",
       "      <td>Economy</td>\n",
       "      <td>For the experts in matters economy and finance...</td>\n",
       "      <td>1.743959e+09</td>\n",
       "      <td>2025-04-06 17:01:41</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>https://reddit.com/r/Kenya/comments/1jsytyp/ec...</td>\n",
       "      <td>https://www.reddit.com/r/Kenya/comments/1jsyty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>foreign funding</td>\n",
       "      <td>Be very cautious of the UAE</td>\n",
       "      <td>Kasongo has been cozying up to the UAE recentl...</td>\n",
       "      <td>1.748512e+09</td>\n",
       "      <td>2025-05-29 09:51:51</td>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>https://reddit.com/r/Kenya/comments/1ky6sma/be...</td>\n",
       "      <td>https://www.reddit.com/r/Kenya/comments/1ky6sm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>USAID</td>\n",
       "      <td>USAID Repercussions + Economy</td>\n",
       "      <td>My neighbour‚Äôs wife was a very big shot in USA...</td>\n",
       "      <td>1.747235e+09</td>\n",
       "      <td>2025-05-14 15:11:02</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>https://reddit.com/r/Kenya/comments/1kmhn87/us...</td>\n",
       "      <td>https://www.reddit.com/r/Kenya/comments/1kmhn8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>foreign funding</td>\n",
       "      <td>Daily Nation</td>\n",
       "      <td></td>\n",
       "      <td>1.747811e+09</td>\n",
       "      <td>2025-05-21 07:09:24</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>https://reddit.com/r/Kenya/comments/1krrnpb/da...</td>\n",
       "      <td>https://www.reddit.com/gallery/1krrnpb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>foreign aid</td>\n",
       "      <td>Is There a Better Way to Fund Africa‚Äôs Infrast...</td>\n",
       "      <td>I'm researching a fintech concept rooted in a ...</td>\n",
       "      <td>1.745161e+09</td>\n",
       "      <td>2025-04-20 14:49:50</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>https://reddit.com/r/Kenya/comments/1k3o7to/is...</td>\n",
       "      <td>https://www.reddit.com/r/Kenya/comments/1k3o7t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit      search_term  \\\n",
       "8      Kenya            usaid   \n",
       "16     Kenya  foreign funding   \n",
       "0      Kenya            USAID   \n",
       "18     Kenya  foreign funding   \n",
       "11     Kenya      foreign aid   \n",
       "\n",
       "                                                title  \\\n",
       "8                                             Economy   \n",
       "16                        Be very cautious of the UAE   \n",
       "0                       USAID Repercussions + Economy   \n",
       "18                                       Daily Nation   \n",
       "11  Is There a Better Way to Fund Africa‚Äôs Infrast...   \n",
       "\n",
       "                                                 text   created_utc  \\\n",
       "8   For the experts in matters economy and finance...  1.743959e+09   \n",
       "16  Kasongo has been cozying up to the UAE recentl...  1.748512e+09   \n",
       "0   My neighbour‚Äôs wife was a very big shot in USA...  1.747235e+09   \n",
       "18                                                     1.747811e+09   \n",
       "11  I'm researching a fintech concept rooted in a ...  1.745161e+09   \n",
       "\n",
       "          created_date  score  num_comments  \\\n",
       "8  2025-04-06 17:01:41      1            15   \n",
       "16 2025-05-29 09:51:51     32            13   \n",
       "0  2025-05-14 15:11:02     12            32   \n",
       "18 2025-05-21 07:09:24      1             8   \n",
       "11 2025-04-20 14:49:50      9             9   \n",
       "\n",
       "                                            permalink  \\\n",
       "8   https://reddit.com/r/Kenya/comments/1jsytyp/ec...   \n",
       "16  https://reddit.com/r/Kenya/comments/1ky6sma/be...   \n",
       "0   https://reddit.com/r/Kenya/comments/1kmhn87/us...   \n",
       "18  https://reddit.com/r/Kenya/comments/1krrnpb/da...   \n",
       "11  https://reddit.com/r/Kenya/comments/1k3o7to/is...   \n",
       "\n",
       "                                                  url  \n",
       "8   https://www.reddit.com/r/Kenya/comments/1jsyty...  \n",
       "16  https://www.reddit.com/r/Kenya/comments/1ky6sm...  \n",
       "0   https://www.reddit.com/r/Kenya/comments/1kmhn8...  \n",
       "18             https://www.reddit.com/gallery/1krrnpb  \n",
       "11  https://www.reddit.com/r/Kenya/comments/1k3o7t...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = df.sample(n=5,random_state= 42)\n",
    "display(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcfa1737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For the experts in matters economy and finance I ask this politely(mnielezee Kama mtoto tafadhali). How is our country still semi functional? Everyday we hear cases of billions lost here billions lost there. Sometime there was reports of I think 1.3 trillion irregularly withdrawn from the treasury, the dollar has surprisingly been stable at around 129 despite all this and there was the case where funding would be halted by the USAID. How has the economy not crashed yet? Is it normal to lose a third of the budget and still have a running country?'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Kasongo has been cozying up to the UAE recently and as Kenyans we should be very careful here, if you look at their foreign policy they a pattern of fostering chaos and undermining democracy and legitimate governments.\\n\\n- In Sudan they fund and support the RSF ,in fact there are reports that they are the ones who pushed the RSF into launching the war.\\n- In Somalia they support the breakaway region of Somaliland.\\n- In Libya they fund and support the warlord, Khalifa Haftar.\\n- In Egypt they orchestrated a coup to overthrow Morsy, the only democratically elected leader in Egypt.\\n\\nI don't know but who's to say that they will not try and help Kasongo in subverting the 2027 elections? After all they wouldn't wanna lose their logistics hub.  As the Swahili say 'Ukiona cha mwenzako kinanyolewa ,chako tia maji' and btw all those countries you see above all thought it couldn't happen to them.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'My neighbour‚Äôs wife was a very big shot in USAID and has now lost her job. Children have been removed from big private school. Husband is a big guy at PWC. Lifestyle changes are occurring rapidly as her income has vanished. Thousands of her USAID coworkers were sent home with no salaries. \\n\\nUSAID Vendors, contractors, non-profits that received funding from them have all been left in a lurch. Sasa machozi zimeanza. \\n\\nNext is empty apartments around ‚Äúhigh class‚Äù areas.\\n\\nUN is laying people off left right and center.\\n\\nAdditionally, public assistance programs in the Europe and America are being slashed so remittances by a certain sector are falling.\\n\\nIf you think things are hard, ngojeni mpaka December. A lot of your highlife hotspots are about to close. A lot of these restaurants are about to close. \\n\\nCrime shall return so please rudini mashambani mulime.\\n\\nAvoid Mombasa, Lamu and malls.\\n\\n\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'I\\'m researching a fintech concept rooted in a simple but powerful idea: What if African citizens could directly micro-invest in their own infrastructure and economic development ‚Äî from as little as $1 ‚Äî instead of relying so heavily on foreign loans or aid?\\n\\nThe idea is inspired by:\\n\\nEthiopia\\'s Renaissance Dam, where despite China funding most of the $5B project, citizens contributed around $1B through bonds and mobile payments. It was a unifying act of nation-building.\\n\\nDenmark‚Äôs wind cooperatives, where tens of thousands of Danes co-own wind turbines, investing small amounts and earning steady returns from green energy sales.\\n\\nArla Foods, one of the world‚Äôs largest dairy companies, is owned by thousands of farmer-members across Europe.\\n\\nPark Slope Food Co-op (Brooklyn, USA) ‚Äì over 17,000 members run and own this highly successful grocery store. Members contribute labor and share in decision-making and cost savings ‚Äî a small-scale but high-functioning democratic economic model.\\n\\nThe concept:\\n\\nA micro-investment platform where citizens can fund infrastructure and industrial projects such as:\\n\\nSolar mini-grids\\n\\nRoads, ports, water systems\\n\\nLocal processing plants or factories\\n\\nAffordable housing\\n\\nAgricultural or logistics ventures\\n\\n\\nUsers invest tiny amounts (e.g. $1‚Äì$10) and track the project‚Äôs progress. They may receive a return over time or non-cash benefits (e.g. discounts, usage credits).\\n\\n\\nWhy this matters:\\n\\nToo often, African development is externally financed ‚Äî with debt, strings attached, and little citizen engagement. This model flips that:\\n\\nPeople co-own what they rely on\\n\\nGovernments gain domestic funding alternatives\\n\\nTrust, pride, and engagement are built from the ground up\\n\\n\\nChallenges (based on Reddit and expert feedback):\\n\\n1. Corruption and trust ‚Äî Citizens must see where every dollar goes. This means transparent ledgers, project dashboards, public audits, and perhaps smart contracts.\\n\\n\\n2. Regulation hell ‚Äî Securities laws differ by country. Government support or sandbox frameworks would be key.\\n\\n\\n3. Profitability ‚Äî Many infrastructure projects don‚Äôt generate immediate returns. The model may need to combine financial ROI with social ROI (access, pride, service).\\n\\n\\n4. Liquidity and exits ‚Äî Who buys your stake in a toll road if you need cash tomorrow?\\n\\n\\n5. \"Isn‚Äôt this just a tax?\" ‚Äî Not quite. Unlike taxes, citizens choose projects and can receive returns or benefits.\\n\\n\\nWhat I‚Äôm exploring:\\n\\nStarting with small-scale, single-country pilots (e.g. local solar or transport infrastructure)\\n\\nIntegrating traditional savings models like stokvels or SACCOs for community-level buy-in\\n\\nBuilding a trust layer first: partnerships with co-ops, municipalities, development banks, etc.\\n\\nExploring hybrid returns (financial + utility discounts) and different legal structures (co-ops, trusts, SPVs)\\n\\n\\nI\\'m not claiming this is the silver bullet ‚Äî but I do believe there\\'s space for a new model of citizen-led development funding in Africa.\\n\\nWhat are the biggest red flags? Where does this break down? Are there other models you think I should study or emulate?\\n\\nI‚Äôd love to hear your take.\\n\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_text= sample['text'].to_list()\n",
    "for x in sample_text:\n",
    "    display(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac31c76",
   "metadata": {},
   "source": [
    "- As seen above, some texts in our dataset contains mixed languages; we shall therefore have some preprocessing before analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52b7fe4",
   "metadata": {},
   "source": [
    "## 3. NewsAPI Data Collection\n",
    "- Sign up at [newsapi.org](newsapi.org)\n",
    "- Create account and get api key : `bc6c52fd05ee4e63827b7cf45fa0bdb2`\n",
    "- Limitations\n",
    "    - The free version allows me to search back until 2025-05-03, 2 months after USAID funding cuts were already announced\n",
    "    - Paywalled Websites like Daily Nation won't have content\n",
    "    - Limited to 100 results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fb696a",
   "metadata": {},
   "source": [
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb18d9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error: 426 - {'status': 'error', 'code': 'parameterInvalid', 'message': 'You are trying to request results too far in the past. Your plan permits you to request articles as far back as 2025-05-12, but you have requested 2025-05-04. You may need to upgrade to a paid plan.'}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'published_at'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'published_at'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fc4c350ad008>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# --- SAVE TO CSV ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_articles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'published_at'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'published_at'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/raw/leo_newsapi_articles.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2902\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2903\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'published_at'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# --- PARAMETERS ---\n",
    "api_key = 'bc6c52fd05ee4e63827b7cf45fa0bdb2'\n",
    "query = 'USAID'\n",
    "from_date = '2025-05-04'  # YYYY-MM-DD\n",
    "country = 'ke'  # Kenya\n",
    "page_size = 100  # max per request\n",
    "max_pages = 1    # you can loop through more if needed\n",
    "\n",
    "# --- FETCH ARTICLES ---\n",
    "all_articles = []\n",
    "\n",
    "for page in range(1, max_pages + 1):\n",
    "    url = (\n",
    "        f'https://newsapi.org/v2/everything?'\n",
    "        f'q={query}&'\n",
    "        f'from={from_date}&'\n",
    "        f'sortBy=publishedAt&'\n",
    "        f'pageSize={page_size}&'\n",
    "        f'page={page}&'\n",
    "        f'apiKey={api_key}'\n",
    "    )\n",
    "\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"‚ùå Error: {response.status_code} - {response.json()}\")\n",
    "        break\n",
    "\n",
    "    articles = response.json().get('articles', [])\n",
    "    if not articles:\n",
    "        break  # no more results\n",
    "\n",
    "    for article in articles:\n",
    "        all_articles.append({\n",
    "            'source': article['source']['name'],\n",
    "            'author': article.get('author'),\n",
    "            'title': article.get('title'),\n",
    "            'description': article.get('description'),\n",
    "            'content': article.get('content'),\n",
    "            'url': article.get('url'),\n",
    "            'published_at': article.get('publishedAt')\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(all_articles)\n",
    "# --- SAVE TO CSV ---\n",
    "df = pd.DataFrame(all_articles)\n",
    "df['published_at'] = pd.to_datetime(df['published_at'])\n",
    "df.to_csv('../data/raw/leo_newsapi_articles.csv', index=False)\n",
    "\n",
    "print(f\"‚úÖ Fetched {len(df)} articles. Saved to ../data/raw/leo_newsapi_articles.csv.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "132d5bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1498 entries, 0 to 1497\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   keyword       1498 non-null   object\n",
      " 1   source        1498 non-null   object\n",
      " 2   author        1379 non-null   object\n",
      " 3   title         1494 non-null   object\n",
      " 4   description   1479 non-null   object\n",
      " 5   content       1498 non-null   object\n",
      " 6   url           1498 non-null   object\n",
      " 7   published_at  1498 non-null   object\n",
      "dtypes: object(8)\n",
      "memory usage: 93.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_news = pd.read_csv('../data/raw/leo_newsapi_articles.csv')\n",
    "df_news.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53f14c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1498 entries, 0 to 1497\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   keyword       1498 non-null   object\n",
      " 1   source        1498 non-null   object\n",
      " 2   author        1379 non-null   object\n",
      " 3   title         1494 non-null   object\n",
      " 4   description   1479 non-null   object\n",
      " 5   content       1498 non-null   object\n",
      " 6   url           1498 non-null   object\n",
      " 7   published_at  1498 non-null   object\n",
      "dtypes: object(8)\n",
      "memory usage: 93.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "df_news = pd.read_csv('../data/raw/leo_newsapi_articles.csv')\n",
    "df_news.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9584701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "397     FIRST ON FOX: New State Department reorganizat...\n",
       "731     : () () , 2005 - 2024 , - - , 36.1% 2025\\r\\n- ...\n",
       "605     Garmin Index Sleep Monitor\\r\\nGarmin\\r\\nSleep ...\n",
       "1264    The EU and US flags flutter next to the milita...\n",
       "1450    Gaspare LoDuca has been appointed MITs vice pr...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news['content'].sample(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d20e96",
   "metadata": {},
   "source": [
    "-Enrich NewsAPI Data with Full Text from `newspaper3k`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68a93c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Loaded 99 articles from NewsAPI.\n",
      "‚ùå Failed at index 11 (https://www.foxnews.com/us/boulder-suspect-spent-year-planning-molotov-cocktail-attack-pro-israel-march-docs): Article `download()` failed with 404 Client Error: Not Found for url: https://www.foxnews.com/us/boulder-suspect-spent-year-planning-molotov-cocktail-attack-pro-israel-march-docs on URL https://www.foxnews.com/us/boulder-suspect-spent-year-planning-molotov-cocktail-attack-pro-israel-march-docs\n",
      "‚ùå Failed at index 13 (https://www.foxnews.com/us/usaid-paperwork-found-car-boulder-terror-attack-suspect-targeting-pro-israel-group): Article `download()` failed with 404 Client Error: Not Found for url: https://www.foxnews.com/us/usaid-paperwork-found-car-boulder-terror-attack-suspect-targeting-pro-israel-group on URL https://www.foxnews.com/us/usaid-paperwork-found-car-boulder-terror-attack-suspect-targeting-pro-israel-group\n",
      "‚ùå Failed at index 15 (https://www.abc.net.au/news/2025-06-03/colorado-terror-attack-suspect-charged-with-us-hate-crime/105369384): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.abc.net.au/news/2025-06-03/colorado-terror-attack-suspect-charged-with-us-hate-crime/105369384 on URL https://www.abc.net.au/news/2025-06-03/colorado-terror-attack-suspect-charged-with-us-hate-crime/105369384\n",
      "‚ùå Failed at index 16 (nan): 'float' object has no attribute 'decode'\n",
      "‚ùå Failed at index 17 (nan): 'float' object has no attribute 'decode'\n",
      "‚ùå Failed at index 28 (https://www.euractiv.com/section/economy-jobs/news/germany-puts-shrunken-development-aid-budget-to-the-test/): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.euractiv.com/section/economy-jobs/news/germany-puts-shrunken-development-aid-budget-to-the-test/ on URL https://www.euractiv.com/section/economy-jobs/news/germany-puts-shrunken-development-aid-budget-to-the-test/\n",
      "‚ùå Failed at index 30 (https://www.foxnews.com/us/boulder-terror-attack-suspect-said-he-wanted-kill-all-zionist-people-used-molotov-cocktails-feds): Article `download()` failed with 404 Client Error: Not Found for url: https://www.foxnews.com/us/boulder-terror-attack-suspect-said-he-wanted-kill-all-zionist-people-used-molotov-cocktails-feds on URL https://www.foxnews.com/us/boulder-terror-attack-suspect-said-he-wanted-kill-all-zionist-people-used-molotov-cocktails-feds\n",
      "‚ùå Failed at index 33 (https://www.globalresearch.ca/intro-chapter-twilight-american-imperialism/5889249): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.globalresearch.ca/intro-chapter-twilight-american-imperialism/5889249 on URL https://www.globalresearch.ca/intro-chapter-twilight-american-imperialism/5889249\n",
      "‚ùå Failed at index 37 (https://www.globalresearch.ca/soon-truth-too-costly-paul-c-roberts/5889186): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.globalresearch.ca/soon-truth-too-costly-paul-c-roberts/5889186 on URL https://www.globalresearch.ca/soon-truth-too-costly-paul-c-roberts/5889186\n",
      "‚ùå Failed at index 49 (https://www.foxnews.com/media/ny-times-columnist-compares-elon-musk-historys-worst-murderers-over-usaid-cuts): Article `download()` failed with 404 Client Error: Not Found for url: https://www.foxnews.com/media/ny-times-columnist-compares-elon-musk-historys-worst-murderers-over-usaid-cuts on URL https://www.foxnews.com/media/ny-times-columnist-compares-elon-musk-historys-worst-murderers-over-usaid-cuts\n",
      "‚ùå Failed at index 66 (https://www.foxnews.com/media/bonos-300000-dead-claim-over-usaid-cuts-gets-smacked-down-rogan-musk-liar-idiot): Article `download()` failed with 404 Client Error: Not Found for url: https://www.foxnews.com/media/bonos-300000-dead-claim-over-usaid-cuts-gets-smacked-down-rogan-musk-liar-idiot on URL https://www.foxnews.com/media/bonos-300000-dead-claim-over-usaid-cuts-gets-smacked-down-rogan-musk-liar-idiot\n",
      "‚ùå Failed at index 81 (https://www.newsweek.com/bono-sparks-maga-backlash-during-joe-rogan-appearance-2079295): Article `download()` failed with 403 Client Error: Forbidden for url: https://www.newsweek.com/bono-sparks-maga-backlash-during-joe-rogan-appearance-2079295 on URL https://www.newsweek.com/bono-sparks-maga-backlash-during-joe-rogan-appearance-2079295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /home/leo/anaconda3/envs/learn-env/lib/python3.8/site-packages/jieba/dict.txt ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 1.4312019348144531 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Done. Saved full-text articles to ../data/raw/leo_newsapi_articles_enriched.csv\n"
     ]
    }
   ],
   "source": [
    "# --- INSTALLATION (if not done) ---\n",
    "# pip install newspaper3k pandas\n",
    "\n",
    "import pandas as pd\n",
    "from newspaper import Article\n",
    "import time\n",
    "\n",
    "# --- LOAD EXISTING DATA ---\n",
    "df = pd.read_csv('../data/raw/leo_newsapi_articles.csv')\n",
    "print(f\"üìÑ Loaded {len(df)} articles from NewsAPI.\")\n",
    "\n",
    "# --- EXTRACT FULL TEXT FROM URL ---\n",
    "full_texts = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    url = row['url']\n",
    "    try:\n",
    "        article = Article(url)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        full_texts.append(article.text)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed at index {i} ({url}): {e}\")\n",
    "        full_texts.append(None)\n",
    "    \n",
    "    time.sleep(1)  # to avoid IP blocks or throttling\n",
    "\n",
    "# --- ADD TO DATAFRAME & SAVE ---\n",
    "df['full_text'] = full_texts\n",
    "df.to_csv('../data/raw/leo_newsapi_articles_enriched.csv', index=False)\n",
    "\n",
    "print(f\"‚úÖ Done. Saved full-text articles to ../data/raw/leo_newsapi_articles_enriched.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab3f5a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c194bfa3",
   "metadata": {},
   "source": [
    "- Trying out alternative news sources due to limitations of `NewsAPI`\n",
    "## News Collection using Gnews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5784fea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Searching from 2025-03-28 to 2025-04-04\n",
      "   ‚úÖ Found 0 articles\n",
      "üîç Searching from 2025-04-04 to 2025-04-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/anaconda3/envs/learn-env/lib/python3.8/site-packages/gnews/gnews.py:130: UserWarning: The start and end dates should be at least 1 day apart, or GNews will return no results\n",
      "  warnings.warn(\"The start and end dates should be at least 1 day apart, or GNews will return no results\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Found 14 articles\n",
      "üîç Searching from 2025-04-11 to 2025-04-18\n",
      "   ‚úÖ Found 10 articles\n",
      "üîç Searching from 2025-04-18 to 2025-04-25\n",
      "   ‚úÖ Found 24 articles\n",
      "üîç Searching from 2025-04-25 to 2025-05-02\n",
      "   ‚úÖ Found 36 articles\n",
      "üîç Searching from 2025-05-02 to 2025-05-09\n",
      "   ‚úÖ Found 31 articles\n",
      "üîç Searching from 2025-05-09 to 2025-05-16\n",
      "   ‚úÖ Found 28 articles\n",
      "üîç Searching from 2025-05-16 to 2025-05-23\n",
      "   ‚úÖ Found 30 articles\n",
      "üîç Searching from 2025-05-23 to 2025-05-30\n",
      "   ‚úÖ Found 35 articles\n",
      "üîç Searching from 2025-05-30 to 2025-06-06\n",
      "   ‚úÖ Found 32 articles\n",
      "üîç Searching from 2025-06-06 to 2025-06-13\n",
      "   ‚úÖ Found 38 articles\n",
      "\n",
      "‚úÖ Done. Saved 278 full-text articles to CSV.\n"
     ]
    }
   ],
   "source": [
    "# --- INSTALLATION ---\n",
    "# pip install gnews newspaper3k pandas\n",
    "\n",
    "from gnews import GNews\n",
    "from newspaper import Article\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# --- PARAMETERS ---\n",
    "query = \"USAID Kenya\"  \n",
    "start_date = datetime(2025, 3, 28)\n",
    "end_date = datetime(2025, 6, 13)\n",
    "chunk_days = 7\n",
    "max_results_per_chunk = 50\n",
    "\n",
    "# --- INITIALIZE ---\n",
    "gnews = GNews(language='en', country='KE', max_results=max_results_per_chunk)\n",
    "current_start = start_date\n",
    "all_articles = []\n",
    "\n",
    "# --- DATE RANGE LOOP ---\n",
    "while current_start < end_date:\n",
    "    current_end = min(current_start + timedelta(days=chunk_days), end_date)\n",
    "    gnews.start_date = current_start\n",
    "    gnews.end_date = current_end\n",
    "    print(f\"üîç Searching from {current_start.date()} to {current_end.date()}\")\n",
    "\n",
    "    try:\n",
    "        results = gnews.get_news(query)\n",
    "        print(f\"   ‚úÖ Found {len(results)} articles\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error during search: {e}\")\n",
    "        results = []\n",
    "\n",
    "    # --- EXTRACT FULL TEXT ---\n",
    "    for article in results:\n",
    "        try:\n",
    "            a = Article(article['url'])\n",
    "            a.download()\n",
    "            a.parse()\n",
    "            all_articles.append({\n",
    "                'title': a.title,\n",
    "                'url': article['url'],\n",
    "                'published_date': article['published date'],\n",
    "                'source': article['publisher']['title'],\n",
    "                'text': a.text\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Failed to parse {article['url']}: {e}\")\n",
    "\n",
    "    current_start += timedelta(days=chunk_days)\n",
    "\n",
    "# --- SAVE TO CSV ---\n",
    "df = pd.DataFrame(all_articles)\n",
    "df['published_date'] = pd.to_datetime(df['published_date'], errors='coerce')\n",
    "df.to_csv(\"../data/raw/gnews_usaid_kenya_full.csv\", index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Done. Saved {len(df)} full-text articles to CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6661e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00f2d157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üåê Searching in language: EN\n",
      "üîç EN: Searching from 2025-03-28 to 2025-04-04\n",
      "   ‚úÖ Found 23 articles\n",
      "üîç EN: Searching from 2025-04-04 to 2025-04-11\n",
      "   ‚úÖ Found 14 articles\n",
      "üîç EN: Searching from 2025-04-11 to 2025-04-18\n",
      "   ‚úÖ Found 10 articles\n",
      "üîç EN: Searching from 2025-04-18 to 2025-04-25\n",
      "   ‚úÖ Found 24 articles\n",
      "üîç EN: Searching from 2025-04-25 to 2025-05-02\n",
      "   ‚úÖ Found 36 articles\n",
      "üîç EN: Searching from 2025-05-02 to 2025-05-09\n",
      "   ‚úÖ Found 31 articles\n",
      "üîç EN: Searching from 2025-05-09 to 2025-05-16\n",
      "   ‚úÖ Found 28 articles\n",
      "üîç EN: Searching from 2025-05-16 to 2025-05-23\n",
      "   ‚úÖ Found 30 articles\n",
      "üîç EN: Searching from 2025-05-23 to 2025-05-30\n",
      "   ‚úÖ Found 35 articles\n",
      "üîç EN: Searching from 2025-05-30 to 2025-06-03\n",
      "   ‚úÖ Found 23 articles\n",
      "\n",
      "üåê Searching in language: SW\n",
      "üîç SW: Searching from 2025-03-28 to 2025-04-04\n",
      "   ‚úÖ Found 23 articles\n",
      "üîç SW: Searching from 2025-04-04 to 2025-04-11\n",
      "   ‚úÖ Found 14 articles\n",
      "üîç SW: Searching from 2025-04-11 to 2025-04-18\n",
      "   ‚úÖ Found 10 articles\n",
      "üîç SW: Searching from 2025-04-18 to 2025-04-25\n",
      "   ‚úÖ Found 24 articles\n",
      "üîç SW: Searching from 2025-04-25 to 2025-05-02\n",
      "   ‚úÖ Found 36 articles\n",
      "üîç SW: Searching from 2025-05-02 to 2025-05-09\n",
      "   ‚úÖ Found 31 articles\n",
      "üîç SW: Searching from 2025-05-09 to 2025-05-16\n",
      "   ‚úÖ Found 28 articles\n",
      "üîç SW: Searching from 2025-05-16 to 2025-05-23\n",
      "   ‚úÖ Found 30 articles\n",
      "üîç SW: Searching from 2025-05-23 to 2025-05-30\n",
      "   ‚úÖ Found 35 articles\n",
      "üîç SW: Searching from 2025-05-30 to 2025-06-03\n",
      "   ‚úÖ Found 23 articles\n",
      "\n",
      "‚úÖ Done. Saved 508 full-text articles (EN + SW) to CSV.\n"
     ]
    }
   ],
   "source": [
    "# --- INSTALLATION ---\n",
    "# pip install gnews newspaper3k pandas\n",
    "\n",
    "from gnews import GNews\n",
    "from newspaper import Article\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# --- PARAMETERS ---\n",
    "query = \"USAID Kenya\"\n",
    "start_date = datetime(2025, 3, 28)\n",
    "end_date = datetime(2025, 6, 3)\n",
    "chunk_days = 7\n",
    "max_results_per_chunk = 50\n",
    "languages = ['en', 'sw']  # English and Swahili\n",
    "\n",
    "# --- STORAGE ---\n",
    "all_articles = []\n",
    "\n",
    "# --- LOOP THROUGH LANGUAGES ---\n",
    "for lang in languages:\n",
    "    print(f\"\\nüåê Searching in language: {lang.upper()}\")\n",
    "    current_start = start_date\n",
    "\n",
    "    while current_start < end_date:\n",
    "        current_end = min(current_start + timedelta(days=chunk_days), end_date)\n",
    "        \n",
    "        gnews = GNews(language=lang, country='KE', max_results=max_results_per_chunk)\n",
    "        gnews.start_date = current_start\n",
    "        gnews.end_date = current_end\n",
    "        \n",
    "        print(f\"üîç {lang.upper()}: Searching from {current_start.date()} to {current_end.date()}\")\n",
    "\n",
    "        try:\n",
    "            results = gnews.get_news(query)\n",
    "            print(f\"   ‚úÖ Found {len(results)} articles\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error during search: {e}\")\n",
    "            results = []\n",
    "\n",
    "        for article in results:\n",
    "            try:\n",
    "                a = Article(article['url'])\n",
    "                a.download()\n",
    "                a.parse()\n",
    "                all_articles.append({\n",
    "                    'title': a.title,\n",
    "                    'url': article['url'],\n",
    "                    'published_date': article.get('published date'),\n",
    "                    'source': article['publisher']['title'],\n",
    "                    'language': lang,\n",
    "                    'text': a.text\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ùå Failed to parse {article['url']}: {e}\")\n",
    "\n",
    "        current_start += timedelta(days=chunk_days)\n",
    "\n",
    "# --- SAVE TO CSV ---\n",
    "df = pd.DataFrame(all_articles)\n",
    "df['published_date'] = pd.to_datetime(df['published_date'], errors='coerce')\n",
    "df.to_csv(\"../data/raw/gnews_usaid_kenya_full_en_sw.csv\", index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Done. Saved {len(df)} full-text articles (EN + SW) to CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74c2b8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 508 entries, 0 to 507\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   title           508 non-null    object \n",
      " 1   url             508 non-null    object \n",
      " 2   published_date  508 non-null    object \n",
      " 3   source          508 non-null    object \n",
      " 4   language        508 non-null    object \n",
      " 5   text            0 non-null      float64\n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 23.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>published_date</th>\n",
       "      <th>source</th>\n",
       "      <th>language</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google News</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMimwFBV...</td>\n",
       "      <td>2025-04-04 07:00:00+00:00</td>\n",
       "      <td>Daily Nation</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Google News</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMirgFBV...</td>\n",
       "      <td>2025-04-01 07:00:00+00:00</td>\n",
       "      <td>Kenyans</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Google News</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiigFBV...</td>\n",
       "      <td>2025-04-02 07:00:00+00:00</td>\n",
       "      <td>NTV Kenya</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Google News</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMimwFBV...</td>\n",
       "      <td>2025-03-31 07:00:00+00:00</td>\n",
       "      <td>KBC Digital</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Google News</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMixwFBV...</td>\n",
       "      <td>2025-04-01 07:00:00+00:00</td>\n",
       "      <td>The EastAfrican</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         title                                                url  \\\n",
       "0  Google News  https://news.google.com/rss/articles/CBMimwFBV...   \n",
       "1  Google News  https://news.google.com/rss/articles/CBMirgFBV...   \n",
       "2  Google News  https://news.google.com/rss/articles/CBMiigFBV...   \n",
       "3  Google News  https://news.google.com/rss/articles/CBMimwFBV...   \n",
       "4  Google News  https://news.google.com/rss/articles/CBMixwFBV...   \n",
       "\n",
       "              published_date           source language  text  \n",
       "0  2025-04-04 07:00:00+00:00     Daily Nation       en   NaN  \n",
       "1  2025-04-01 07:00:00+00:00          Kenyans       en   NaN  \n",
       "2  2025-04-02 07:00:00+00:00        NTV Kenya       en   NaN  \n",
       "3  2025-03-31 07:00:00+00:00      KBC Digital       en   NaN  \n",
       "4  2025-04-01 07:00:00+00:00  The EastAfrican       en   NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv(\"../data/raw/gnews_usaid_kenya_full_en_sw.csv\")\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab8e24bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üåê Searching in language: EN\n",
      "üîç EN: Searching from 2025-03-28 to 2025-04-04\n",
      "   ‚úÖ Found 23 articles\n",
      "üîç EN: Searching from 2025-04-04 to 2025-04-11\n",
      "   ‚úÖ Found 14 articles\n",
      "üîç EN: Searching from 2025-04-11 to 2025-04-18\n",
      "   ‚úÖ Found 10 articles\n",
      "üîç EN: Searching from 2025-04-18 to 2025-04-25\n",
      "   ‚úÖ Found 23 articles\n",
      "üîç EN: Searching from 2025-04-25 to 2025-05-02\n",
      "   ‚úÖ Found 36 articles\n",
      "üîç EN: Searching from 2025-05-02 to 2025-05-09\n",
      "   ‚úÖ Found 31 articles\n",
      "üîç EN: Searching from 2025-05-09 to 2025-05-16\n",
      "   ‚úÖ Found 28 articles\n",
      "üîç EN: Searching from 2025-05-16 to 2025-05-23\n",
      "   ‚úÖ Found 24 articles\n",
      "üîç EN: Searching from 2025-05-23 to 2025-05-30\n",
      "   ‚úÖ Found 35 articles\n",
      "üîç EN: Searching from 2025-05-30 to 2025-06-03\n",
      "   ‚úÖ Found 21 articles\n",
      "\n",
      "üåê Searching in language: SW\n",
      "üîç SW: Searching from 2025-03-28 to 2025-04-04\n",
      "   ‚úÖ Found 23 articles\n",
      "üîç SW: Searching from 2025-04-04 to 2025-04-11\n",
      "   ‚úÖ Found 15 articles\n",
      "üîç SW: Searching from 2025-04-11 to 2025-04-18\n",
      "   ‚úÖ Found 10 articles\n",
      "üîç SW: Searching from 2025-04-18 to 2025-04-25\n",
      "   ‚úÖ Found 23 articles\n",
      "üîç SW: Searching from 2025-04-25 to 2025-05-02\n",
      "   ‚úÖ Found 35 articles\n",
      "üîç SW: Searching from 2025-05-02 to 2025-05-09\n",
      "   ‚úÖ Found 31 articles\n",
      "üîç SW: Searching from 2025-05-09 to 2025-05-16\n",
      "   ‚úÖ Found 28 articles\n",
      "üîç SW: Searching from 2025-05-16 to 2025-05-23\n",
      "   ‚úÖ Found 29 articles\n",
      "üîç SW: Searching from 2025-05-23 to 2025-05-30\n",
      "   ‚úÖ Found 35 articles\n",
      "üîç SW: Searching from 2025-05-30 to 2025-06-03\n",
      "   ‚úÖ Found 22 articles\n",
      "\n",
      "‚úÖ Done. Saved 496 full-text articles (EN + SW) to CSV.\n"
     ]
    }
   ],
   "source": [
    "# --- INSTALLATION ---\n",
    "# pip install gnews newspaper3k pandas requests\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from gnews import GNews\n",
    "from newspaper import Article\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# --- PARAMETERS ---\n",
    "query = \"USAID Kenya\"\n",
    "start_date = datetime(2025, 3, 28)\n",
    "end_date = datetime(2025, 6, 3)\n",
    "chunk_days = 7\n",
    "max_results_per_chunk = 50\n",
    "languages = ['en', 'sw']\n",
    "\n",
    "# --- STORAGE ---\n",
    "all_articles = []\n",
    "\n",
    "# --- LOOP THROUGH LANGUAGES ---\n",
    "for lang in languages:\n",
    "    print(f\"\\nüåê Searching in language: {lang.upper()}\")\n",
    "    current_start = start_date\n",
    "\n",
    "    while current_start < end_date:\n",
    "        current_end = min(current_start + timedelta(days=chunk_days), end_date)\n",
    "        \n",
    "        gnews = GNews(language=lang, country='KE', max_results=max_results_per_chunk)\n",
    "        gnews.start_date = current_start\n",
    "        gnews.end_date = current_end\n",
    "        \n",
    "        print(f\"üîç {lang.upper()}: Searching from {current_start.date()} to {current_end.date()}\")\n",
    "\n",
    "        try:\n",
    "            results = gnews.get_news(query)\n",
    "            print(f\"   ‚úÖ Found {len(results)} articles\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error during search: {e}\")\n",
    "            results = []\n",
    "\n",
    "        for article in results:\n",
    "            try:\n",
    "                # --- Resolve Google News redirect URL to real URL ---\n",
    "                response = requests.get(article['url'], allow_redirects=True, timeout=10)\n",
    "                real_url = response.url\n",
    "\n",
    "                # --- Use real URL to extract content ---\n",
    "                a = Article(real_url)\n",
    "                a.download()\n",
    "                a.parse()\n",
    "\n",
    "                all_articles.append({\n",
    "                    'title': a.title,\n",
    "                    'url': real_url,\n",
    "                    'published_date': article.get('published date'),\n",
    "                    'source': article['publisher']['title'],\n",
    "                    'language': lang,\n",
    "                    'text': a.text\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ùå Failed to parse {article['url']} -> {e}\")\n",
    "\n",
    "        current_start += timedelta(days=chunk_days)\n",
    "\n",
    "# --- SAVE TO CSV ---\n",
    "df = pd.DataFrame(all_articles)\n",
    "df['published_date'] = pd.to_datetime(df['published_date'], errors='coerce')\n",
    "df.to_csv(\"../data/raw/gnews_usaid_kenya_full_en_sw.csv\", index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Done. Saved {len(df)} full-text articles (EN + SW) to CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "829a29e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üåê Searching in language: EN\n",
      "üîç EN: Searching from 2025-03-28 to 2025-04-04\n",
      "   ‚úÖ Found 23 articles\n",
      "üîç EN: Searching from 2025-04-04 to 2025-04-11\n",
      "   ‚úÖ Found 14 articles\n",
      "üîç EN: Searching from 2025-04-11 to 2025-04-18\n",
      "   ‚úÖ Found 10 articles\n",
      "üîç EN: Searching from 2025-04-18 to 2025-04-25\n",
      "   ‚úÖ Found 23 articles\n",
      "üîç EN: Searching from 2025-04-25 to 2025-05-02\n",
      "   ‚úÖ Found 35 articles\n",
      "üîç EN: Searching from 2025-05-02 to 2025-05-09\n",
      "   ‚úÖ Found 31 articles\n",
      "üîç EN: Searching from 2025-05-09 to 2025-05-16\n",
      "   ‚úÖ Found 28 articles\n",
      "üîç EN: Searching from 2025-05-16 to 2025-05-23\n",
      "   ‚úÖ Found 29 articles\n",
      "üîç EN: Searching from 2025-05-23 to 2025-05-30\n",
      "   ‚úÖ Found 33 articles\n",
      "üîç EN: Searching from 2025-05-30 to 2025-06-03\n",
      "   ‚úÖ Found 22 articles\n",
      "\n",
      "üåê Searching in language: SW\n",
      "üîç SW: Searching from 2025-03-28 to 2025-04-04\n",
      "   ‚úÖ Found 23 articles\n",
      "üîç SW: Searching from 2025-04-04 to 2025-04-11\n",
      "   ‚úÖ Found 14 articles\n",
      "üîç SW: Searching from 2025-04-11 to 2025-04-18\n",
      "   ‚úÖ Found 10 articles\n",
      "üîç SW: Searching from 2025-04-18 to 2025-04-25\n",
      "   ‚úÖ Found 23 articles\n",
      "üîç SW: Searching from 2025-04-25 to 2025-05-02\n",
      "   ‚úÖ Found 35 articles\n",
      "üîç SW: Searching from 2025-05-02 to 2025-05-09\n",
      "   ‚úÖ Found 31 articles\n",
      "üîç SW: Searching from 2025-05-09 to 2025-05-16\n",
      "   ‚úÖ Found 28 articles\n",
      "üîç SW: Searching from 2025-05-16 to 2025-05-23\n",
      "   ‚úÖ Found 29 articles\n",
      "üîç SW: Searching from 2025-05-23 to 2025-05-30\n",
      "   ‚úÖ Found 33 articles\n",
      "üîç SW: Searching from 2025-05-30 to 2025-06-03\n",
      "   ‚úÖ Found 22 articles\n",
      "\n",
      "‚úÖ Done. Saved 496 full-text articles (EN + SW) to CSV.\n"
     ]
    }
   ],
   "source": [
    "# --- INSTALLATION ---\n",
    "# pip install gnews newspaper3k pandas requests\n",
    "\n",
    "from gnews import GNews\n",
    "from newspaper import Article\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "\n",
    "# --- FUNCTION TO RESOLVE REDIRECTS ---\n",
    "def resolve_real_url(google_news_url):\n",
    "    try:\n",
    "        response = requests.get(google_news_url, timeout=10, allow_redirects=True)\n",
    "        return response.url  # Final URL after redirects\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Could not resolve URL {google_news_url}: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- PARAMETERS ---\n",
    "query = \"USAID Kenya\"\n",
    "start_date = datetime(2025, 3, 28)\n",
    "end_date = datetime(2025, 6, 3)\n",
    "chunk_days = 7\n",
    "max_results_per_chunk = 50\n",
    "languages = ['en', 'sw']  # English and Swahili\n",
    "\n",
    "# --- STORAGE ---\n",
    "all_articles = []\n",
    "\n",
    "# --- LOOP THROUGH LANGUAGES ---\n",
    "for lang in languages:\n",
    "    print(f\"\\nüåê Searching in language: {lang.upper()}\")\n",
    "    current_start = start_date\n",
    "\n",
    "    while current_start < end_date:\n",
    "        current_end = min(current_start + timedelta(days=chunk_days), end_date)\n",
    "\n",
    "        gnews = GNews(language=lang, country='KE', max_results=max_results_per_chunk)\n",
    "        gnews.start_date = current_start\n",
    "        gnews.end_date = current_end\n",
    "\n",
    "        print(f\"üîç {lang.upper()}: Searching from {current_start.date()} to {current_end.date()}\")\n",
    "\n",
    "        try:\n",
    "            results = gnews.get_news(query)\n",
    "            print(f\"   ‚úÖ Found {len(results)} articles\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error during search: {e}\")\n",
    "            results = []\n",
    "\n",
    "        for article in results:\n",
    "            try:\n",
    "                real_url = resolve_real_url(article['url'])\n",
    "                if real_url is None:\n",
    "                    continue\n",
    "\n",
    "                a = Article(real_url)\n",
    "                a.download()\n",
    "                a.parse()\n",
    "\n",
    "                all_articles.append({\n",
    "                    'title': a.title,\n",
    "                    'url': real_url,\n",
    "                    'published_date': article.get('published date'),\n",
    "                    'source': article['publisher']['title'],\n",
    "                    'language': lang,\n",
    "                    'text': a.text\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ùå Failed to parse article from {article['url']}: {e}\")\n",
    "\n",
    "        current_start += timedelta(days=chunk_days)\n",
    "\n",
    "# --- SAVE TO CSV ---\n",
    "df = pd.DataFrame(all_articles)\n",
    "df['published_date'] = pd.to_datetime(df['published_date'], errors='coerce')\n",
    "df.to_csv(\"../data/raw/gnews_usaid_kenya_full_en_sw.csv\", index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Done. Saved {len(df)} full-text articles (EN + SW) to CSV.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28aeb9b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>published_date</th>\n",
       "      <th>source</th>\n",
       "      <th>language</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google News</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMimwFBV...</td>\n",
       "      <td>2025-04-04 07:00:00+00:00</td>\n",
       "      <td>Daily Nation</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Google News</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMirgFBV...</td>\n",
       "      <td>2025-04-01 07:00:00+00:00</td>\n",
       "      <td>Kenyans</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Google News</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiigFBV...</td>\n",
       "      <td>2025-04-02 07:00:00+00:00</td>\n",
       "      <td>NTV Kenya</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Google News</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMimwFBV...</td>\n",
       "      <td>2025-03-31 07:00:00+00:00</td>\n",
       "      <td>KBC Digital</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Google News</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMixwFBV...</td>\n",
       "      <td>2025-04-01 07:00:00+00:00</td>\n",
       "      <td>The EastAfrican</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         title                                                url  \\\n",
       "0  Google News  https://news.google.com/rss/articles/CBMimwFBV...   \n",
       "1  Google News  https://news.google.com/rss/articles/CBMirgFBV...   \n",
       "2  Google News  https://news.google.com/rss/articles/CBMiigFBV...   \n",
       "3  Google News  https://news.google.com/rss/articles/CBMimwFBV...   \n",
       "4  Google News  https://news.google.com/rss/articles/CBMixwFBV...   \n",
       "\n",
       "             published_date           source language text  \n",
       "0 2025-04-04 07:00:00+00:00     Daily Nation       en       \n",
       "1 2025-04-01 07:00:00+00:00          Kenyans       en       \n",
       "2 2025-04-02 07:00:00+00:00        NTV Kenya       en       \n",
       "3 2025-03-31 07:00:00+00:00      KBC Digital       en       \n",
       "4 2025-04-01 07:00:00+00:00  The EastAfrican       en       "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6816ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üåê Searching in language: EN\n",
      "üîç EN: 2025-03-28 to 2025-04-04\n",
      "   ‚úÖ Found 23 articles\n",
      "   Processing: https://news.google.com/rss/articles/CBMimwFBVV95cUxPcUdHaHV3SHFpaU9jY...\n",
      "   Processing: https://news.google.com/rss/articles/CBMirgFBVV95cUxNeWxTcS1aZUdJOGJFa...\n",
      "   Processing: https://news.google.com/rss/articles/CBMiigFBVV95cUxONDZDNk9IckprMGE2b...\n",
      "   Processing: https://news.google.com/rss/articles/CBMimwFBVV95cUxNSmIzNThpWlBONmpoM...\n",
      "   Processing: https://news.google.com/rss/articles/CBMi0gFBVV95cUxNWGVENGRFcm1MQ0tTa...\n",
      "   Processing: https://news.google.com/rss/articles/CBMixwFBVV95cUxNTjN4clltRkR5eHRVT...\n",
      "   Processing: https://news.google.com/rss/articles/CBMilgFBVV95cUxNN29Lb3Vub0pBNjQ4a...\n",
      "   Processing: https://news.google.com/rss/articles/CBMiswFBVV95cUxPLXE4RThoMVl1Z1pYR...\n",
      "   Processing: https://news.google.com/rss/articles/CBMilgFBVV95cUxNbWtJZVk3d1A0TEFsW...\n",
      "   Processing: https://news.google.com/rss/articles/CBMiwwFBVV95cUxON0FISlpaQjFLOUlZM...\n",
      "   Processing: https://news.google.com/rss/articles/CBMimwFBVV95cUxOekg4c2p2LURJTzUzM...\n",
      "   Processing: https://news.google.com/rss/articles/CBMitAFBVV95cUxOdEVuS0hPa0lnYUlMY...\n",
      "   Processing: https://news.google.com/rss/articles/CBMilwFBVV95cUxPbHJBUDk0SnUwd1VjV...\n",
      "   Processing: https://news.google.com/rss/articles/CBMiswFBVV95cUxNMmdFc0hDaEV4Tjc1R...\n",
      "   Processing: https://news.google.com/rss/articles/CBMipwFBVV95cUxOSkFqU0JHUGw3bC13a...\n",
      "   Processing: https://news.google.com/rss/articles/CBMipgFBVV95cUxNMU9pS2h6OW9XOTBHM...\n",
      "   Processing: https://news.google.com/rss/articles/CBMiggJBVV95cUxPTTA4Uk1EVG5JaVJTN...\n",
      "   Processing: https://news.google.com/rss/articles/CBMinAFBVV95cUxPR3VrRWprRk1MQXcyc...\n",
      "   Processing: https://news.google.com/rss/articles/CBMirgFBVV95cUxPQi11SUtGb1BrRmw3a...\n",
      "   Processing: https://news.google.com/rss/articles/CBMitwFBVV95cUxQajZVRlJOcVFLNEZEe...\n",
      "   Processing: https://news.google.com/rss/articles/CBMilAFBVV95cUxPYjAwUm1oV2lVTkpRV...\n",
      "   Processing: https://news.google.com/rss/articles/CBMie0FVX3lxTE53S2xmRGI3ak9KX0Y2R...\n",
      "   Processing: https://news.google.com/rss/articles/CBMioAFBVV95cUxPcjZMQWF4TldoVXk4d...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/anaconda3/envs/learn-env/lib/python3.8/site-packages/gnews/gnews.py:130: UserWarning: The start and end dates should be at least 1 day apart, or GNews will return no results\n",
      "  warnings.warn(\"The start and end dates should be at least 1 day apart, or GNews will return no results\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç EN: 2025-04-04 to 2025-04-11\n",
      "   ‚úÖ Found 13 articles\n",
      "   Processing: https://news.google.com/rss/articles/CBMimwFBVV95cUxPcUdHaHV3SHFpaU9jY...\n",
      "   Processing: https://news.google.com/rss/articles/CBMi0gFBVV95cUxNWGVENGRFcm1MQ0tTa...\n",
      "   Processing: https://news.google.com/rss/articles/CBMiigFBVV95cUxQNzJwOTR2OWxuT2xmN...\n",
      "   Processing: https://news.google.com/rss/articles/CBMiygFBVV95cUxQVlMtbmtzUEFpUFBCY...\n",
      "   Processing: https://news.google.com/rss/articles/CBMigAJBVV95cUxQNmdTM2x5UE8zY25OL...\n",
      "   Processing: https://news.google.com/rss/articles/CBMilgFBVV95cUxNbWtJZVk3d1A0TEFsW...\n",
      "   Processing: https://news.google.com/rss/articles/CBMiU0FVX3lxTE1wWTdaYUpES1RucnB0Z...\n",
      "   Processing: https://news.google.com/rss/articles/CBMitwFBVV95cUxQdS1ROXlJQkw4VEFaO...\n",
      "   Processing: https://news.google.com/rss/articles/CBMimwFBVV95cUxOekg4c2p2LURJTzUzM...\n",
      "   Processing: https://news.google.com/rss/articles/CBMiwAFBVV95cUxOZGxXdFBwXzNmV3Rod...\n",
      "   Processing: https://news.google.com/rss/articles/CBMivgFBVV95cUxNQnAwNlk5QzJWSk9jS...\n",
      "   Processing: https://news.google.com/rss/articles/CBMipgFBVV95cUxQZV81Wm9NQ0Z0ZmtpN...\n",
      "   Processing: https://news.google.com/rss/articles/CBMickFVX3lxTE9TUXFKLWlZOUZyRGRac...\n",
      "üîç EN: 2025-04-11 to 2025-04-18\n",
      "   ‚úÖ Found 11 articles\n",
      "   Processing: https://news.google.com/rss/articles/CBMiqAFBVV95cUxQemRkYk12ejcwY2tPS...\n",
      "   Processing: https://news.google.com/rss/articles/CBMitAFBVV95cUxNRVpUNWw4anhJTDdxV...\n",
      "   Processing: https://news.google.com/rss/articles/CBMirAFBVV95cUxOSjYyM3o0WDRXOExHd...\n",
      "   Processing: https://news.google.com/rss/articles/CBMingFBVV95cUxQTzlPQmhvY0p2cGxse...\n",
      "   Processing: https://news.google.com/rss/articles/CBMilgFBVV95cUxPY2ZldXVmMzczZE91R...\n",
      "   Processing: https://news.google.com/rss/articles/CBMiUkFVX3lxTFBzWXdic2wtcWxHTEJvM...\n",
      "   Processing: https://news.google.com/rss/articles/CBMikwFBVV95cUxOaUxoNzJQWi1pOVQ4N...\n",
      "   Processing: https://news.google.com/rss/articles/CBMiekFVX3lxTFBLWTV0NVNYRkZTQlNOW...\n",
      "   Processing: https://news.google.com/rss/articles/CBMioAFBVV95cUxQTkc1V0pHWG45RGNqM...\n",
      "   Processing: https://news.google.com/rss/articles/CBMibkFVX3lxTE0zNmhkQmxFek54dHZfe...\n",
      "   Processing: https://news.google.com/rss/articles/CBMikwFBVV95cUxQbUd1TUVYMURMbnRCL...\n",
      "üîç EN: 2025-04-18 to 2025-04-25\n",
      "   ‚úÖ Found 13 articles\n",
      "   Processing: https://news.google.com/rss/articles/CBMiugFBVV95cUxOR1ZibHcyT3RzbG5wd...\n",
      "   Processing: https://news.google.com/rss/articles/CBMipgFBVV95cUxQcm1WdWxJTDNweGxva...\n",
      "   Processing: https://news.google.com/rss/articles/CBMilwFBVV95cUxNSl9KdEVFajV1M0o2c...\n",
      "   Processing: https://news.google.com/rss/articles/CBMi0wFBVV95cUxORDdOUTJsMFVIZWowZ...\n",
      "   Processing: https://news.google.com/rss/articles/CBMirAFBVV95cUxNbnh4bFRjWWRSQUd2N...\n",
      "   Processing: https://news.google.com/rss/articles/CBMirAFBVV95cUxOV3ZDRXFIdG1GOWVBO...\n",
      "   Processing: https://news.google.com/rss/articles/CBMikgFBVV95cUxQcC14OHM1MXU1UjdfM...\n",
      "   Processing: https://news.google.com/rss/articles/CBMikwFBVV95cUxNdHlXTkcxNjFjenNKd...\n",
      "   Processing: https://news.google.com/rss/articles/CBMiZEFVX3lxTFBlRlAwSkg3QWNnU2x0V...\n",
      "   Processing: https://news.google.com/rss/articles/CBMiWkFVX3lxTE92TjNTX3FSQWk4Zjhfb...\n",
      "   Processing: https://news.google.com/rss/articles/CBMitwFBVV95cUxNUFRJVTlwUUFua0J0T...\n",
      "   Processing: https://news.google.com/rss/articles/CBMirAFBVV95cUxQMzhSVkhsZlZWNU1Ud...\n",
      "   Processing: https://news.google.com/rss/articles/CBMikwFBVV95cUxOVDJIRjdqVmJEdGtLU...\n",
      "üîç EN: 2025-04-25 to 2025-05-02\n",
      "   ‚úÖ Found 29 articles\n",
      "   Processing: https://news.google.com/rss/articles/CBMikgFBVV95cUxNeDRqM0laRzdSZEd6c...\n",
      "   Processing: https://news.google.com/rss/articles/CBMipgFBVV95cUxQcm1WdWxJTDNweGxva...\n",
      "   Processing: https://news.google.com/rss/articles/CBMi1AFBVV95cUxPY2pDVnN3dHZoOU9aZ...\n",
      "   Processing: https://news.google.com/rss/articles/CBMilwFBVV95cUxNSl9KdEVFajV1M0o2c...\n",
      "   Processing: https://news.google.com/rss/articles/CBMitwFBVV95cUxNYTMydEN1cXRCUndiV...\n",
      "   Processing: https://news.google.com/rss/articles/CBMikwFBVV95cUxNYmhBSHZRRFdQbHZXN...\n",
      "   Processing: https://news.google.com/rss/articles/CBMixAFBVV95cUxOSXFfc2tSWGc1N3htU...\n",
      "   Processing: https://news.google.com/rss/articles/CBMiXEFVX3lxTE1IQ2N6MzlpYzNXREgtQ...\n",
      "   Processing: https://news.google.com/rss/articles/CBMixwFBVV95cUxQd1hNNno4TWhoTV9sa...\n",
      "   Processing: https://news.google.com/rss/articles/CBMixgFBVV95cUxQaVV5bm54Zy0tcjBMN...\n",
      "   Processing: https://news.google.com/rss/articles/CBMilgFBVV95cUxQQ3VhRmNXaHFlUWVPd...\n",
      "   Processing: https://news.google.com/rss/articles/CBMirAFBVV95cUxPdlctbEZjam5pNjN5b...\n",
      "   Processing: https://news.google.com/rss/articles/CBMicEFVX3lxTFBrTFc0d1NiYXZDWHNPV...\n",
      "   Processing: https://news.google.com/rss/articles/CBMihgFBVV95cUxQVWNwM3pTV0tVeDdzW...\n",
      "   Processing: https://news.google.com/rss/articles/CBMi1AFBVV95cUxPdGVNSGlvUFUtU19JV...\n",
      "   Processing: https://news.google.com/rss/articles/CBMi2gFBVV95cUxOb2V0NGNvbFh3NVpjZ...\n",
      "   Processing: https://news.google.com/rss/articles/CBMitwFBVV95cUxNUFRJVTlwUUFua0J0T...\n",
      "   Processing: https://news.google.com/rss/articles/CBMiiwFBVV95cUxPcnRmQkFMNHJFMjc4W...\n",
      "   Processing: https://news.google.com/rss/articles/CBMiXEFVX3lxTFBKNkN3aC0wdXJDeXdjW...\n",
      "   Processing: https://news.google.com/rss/articles/CBMi3gFBVV95cUxQUG9TSkNHemQ5dm5BZ...\n",
      "   Processing: https://news.google.com/rss/articles/CBMihgFBVV95cUxNTkVhcjZpOUxsaFFTS...\n",
      "   Processing: https://news.google.com/rss/articles/CBMifkFVX3lxTE1MdXFkNVVmRjZtMWdFV...\n",
      "   Processing: https://news.google.com/rss/articles/CBMikAFBVV95cUxOS1d3Z0FlMXNlQXNIT...\n",
      "   Processing: https://news.google.com/rss/articles/CBMiiwFBVV95cUxNUGp4WmIxbldrNVM5W...\n",
      "   Processing: https://news.google.com/rss/articles/CBMisAFBVV95cUxQUDFRSXZZLTE5Vi1OT...\n",
      "   Processing: https://news.google.com/rss/articles/CBMie0FVX3lxTE45ekhLSVA0eXB2V20tc...\n",
      "   Processing: https://news.google.com/rss/articles/CBMiW0FVX3lxTFByS2FfYndFVm0xM0JxO...\n",
      "   Processing: https://news.google.com/rss/articles/CBMi0wFBVV95cUxOSXpiOWlya0lTbnc1N...\n",
      "   Processing: https://news.google.com/rss/articles/CBMikwFBVV95cUxOVDJIRjdqVmJEdGtLU...\n",
      "üîç EN: 2025-05-02 to 2025-05-09\n",
      "   ‚úÖ Found 26 articles\n",
      "   Processing: https://news.google.com/rss/articles/CBMiugFBVV95cUxOY3Yzb2RoR2FHcnJka...\n",
      "   Processing: https://news.google.com/rss/articles/CBMid0FVX3lxTE1ZblkxTGQweFZVTFkya...\n",
      "   Processing: https://news.google.com/rss/articles/CBMitgFBVV95cUxQWklaZkRsbHlPdlFfc...\n",
      "   Processing: https://news.google.com/rss/articles/CBMibkFVX3lxTE9oejBkdkdjdTNJYk1QR...\n",
      "   Processing: https://news.google.com/rss/articles/CBMiswFBVV95cUxPYnN2N3JNWDZXU1ZGT...\n",
      "   Processing: https://news.google.com/rss/articles/CBMinwFBVV95cUxNMXVQakEyYWJKWTMzY...\n",
      "   Processing: https://news.google.com/rss/articles/CBMitwFBVV95cUxPV2ZTeTd4SlBNTTA5U...\n",
      "   Processing: https://news.google.com/rss/articles/CBMitwFBVV95cUxObEw3Unk0VEw0T3dRQ...\n",
      "   Processing: https://news.google.com/rss/articles/CBMinwFBVV95cUxOMk00eFBPTEF3R283N...\n",
      "   Processing: https://news.google.com/rss/articles/CBMisgFBVV95cUxPNXBZM3c2cVpLYWJ2Z...\n",
      "   Processing: https://news.google.com/rss/articles/CBMirgFBVV95cUxQNXM4ekZ3d3ludVZNS...\n",
      "   Processing: https://news.google.com/rss/articles/CBMi0wFBVV95cUxQNmZrNzBhVlJ1cTJLR...\n",
      "   Processing: https://news.google.com/rss/articles/CBMiqgFBVV95cUxPNkRZQ0ljYm5UX1lpO...\n",
      "   Processing: https://news.google.com/rss/articles/CBMi6wFBVV95cUxPc3BHWU1qT05heTZrQ...\n",
      "   Processing: https://news.google.com/rss/articles/CBMiZkFVX3lxTE5rS3J5Rlc4WXdaMDF0b...\n",
      "   Processing: https://news.google.com/rss/articles/CBMi1gFBVV95cUxOaVhKOE9HNXR0Q3Atc...\n",
      "   Processing: https://news.google.com/rss/articles/CBMicEFVX3lxTFBrTFc0d1NiYXZDWHNPV...\n",
      "   Processing: https://news.google.com/rss/articles/CBMivAFBVV95cUxPamdKekRmUGhvM29jR...\n",
      "   Processing: https://news.google.com/rss/articles/CBMi1AFBVV95cUxPdGVNSGlvUFUtU19JV...\n",
      "   Processing: https://news.google.com/rss/articles/CBMikAFBVV95cUxORE8wT1BZNkNpR3E3T...\n",
      "   Processing: https://news.google.com/rss/articles/CBMi1gFBVV95cUxPOHd4ZVczamFZWlBfY...\n",
      "   Processing: https://news.google.com/rss/articles/CBMinAFBVV95cUxQcGxnNGpJY1d5dGt5e...\n",
      "   Processing: https://news.google.com/rss/articles/CBMiYEFVX3lxTE50WDJ4WGdHR1NiWTk3d...\n",
      "   Processing: https://news.google.com/rss/articles/CBMi0AFBVV95cUxQV2R6c1VrbFFHRGEyQ...\n",
      "   Processing: https://news.google.com/rss/articles/CBMixwFBVV95cUxQbVhxYlB2WmJGenRVY...\n",
      "   Processing: https://news.google.com/rss/articles/CBMizgFBVV95cUxOQnU4QWxVc18xdXpEe...\n",
      "üîç EN: 2025-05-09 to 2025-05-16\n",
      "   ‚úÖ Found 19 articles\n",
      "   Processing: https://news.google.com/rss/articles/CBMipAFBVV95cUxNMi00bEZiNTRyb2RYe...\n",
      "   Processing: https://news.google.com/rss/articles/CBMitgFBVV95cUxOY1FXc0tLV1NSb1pYe...\n",
      "   Processing: https://news.google.com/rss/articles/CBMijAFBVV95cUxOMWpfNUhqcUdkc3h4U...\n",
      "   Processing: https://news.google.com/rss/articles/CBMirgFBVV95cUxQNXM4ekZ3d3ludVZNS...\n",
      "   Processing: https://news.google.com/rss/articles/CBMi0wFBVV95cUxQNmZrNzBhVlJ1cTJLR...\n",
      "   Processing: https://news.google.com/rss/articles/CBMipAFBVV95cUxQNG5BR004TGQ4bVl5U...\n",
      "   Processing: https://news.google.com/rss/articles/CBMirgFBVV95cUxQMzNuLWZseWdDeUtvV...\n",
      "   Processing: https://news.google.com/rss/articles/CBMiZkFVX3lxTE5rS3J5Rlc4WXdaMDF0b...\n",
      "   Processing: https://news.google.com/rss/articles/CBMiVkFVX3lxTE16c0lWSzB2RUJnODRfe...\n",
      "   Processing: https://news.google.com/rss/articles/CBMif0FVX3lxTE5xYU9YOGsyZWZ3WEVuN...\n",
      "   Processing: https://news.google.com/rss/articles/CBMingFBVV95cUxNNXUzb3gyQ1VxRURBM...\n",
      "   Processing: https://news.google.com/rss/articles/CBMingFBVV95cUxOdUdTUXo4eW8wMkhXc...\n",
      "   Processing: https://news.google.com/rss/articles/CBMiWkFVX3lxTFBzSGQxUW9Eb2J5X0Jsc...\n",
      "   Processing: https://news.google.com/rss/articles/CBMi5AFBVV95cUxPUnlrc0VDTEJkU1Fzd...\n",
      "   Processing: https://news.google.com/rss/articles/CBMiqgFBVV95cUxOUzU2YnpfaE5FVUhHT...\n",
      "   Processing: https://news.google.com/rss/articles/CBMimgFBVV95cUxOZk1DREN1bzlDVlpTS...\n",
      "   Processing: https://news.google.com/rss/articles/CBMimgFBVV95cUxPeGJNRkZscExoMWxpb...\n",
      "   Processing: https://news.google.com/rss/articles/CBMihwFBVV95cUxNLWNqYjZVTVo1dktJQ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f5acf13ed4db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"   Processing: {real_url[:70]}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                 \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_article_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-f5acf13ed4db>\u001b[0m in \u001b[0;36mextract_article_content\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0marticle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArticle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0marticle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0marticle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marticle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marticle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/newspaper/article.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self, input_html, title, recursion_counter)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput_html\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                 \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_html_2XX_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequestException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArticleDownloadState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFAILED_RESPONSE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/newspaper/network.py\u001b[0m in \u001b[0;36mget_html_2XX_only\u001b[0;34m(url, config, response)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_get_html_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     response = requests.get(\n\u001b[0m\u001b[1;32m     63\u001b[0m         url=url, **get_request_kwargs(timeout, useragent, proxies, headers))\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    528\u001b[0m         }\n\u001b[1;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    671\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;31m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    976\u001b[0m         \u001b[0;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sock\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_verified\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_default_certs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         self.sock = ssl_wrap_socket(\n\u001b[0m\u001b[1;32m    363\u001b[0m             \u001b[0msock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0mkeyfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/urllib3/util/ssl_.py\u001b[0m in \u001b[0;36mssl_wrap_socket\u001b[0;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data)\u001b[0m\n\u001b[1;32m    382\u001b[0m     ) or IS_SECURETRANSPORT:\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mHAS_SNI\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mserver_hostname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         warnings.warn(\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;31m# SSLSocket class handles server_hostname encoding before it calls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;31m# ctx._wrap_socket()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m         return self.sslsocket_class._create(\n\u001b[0m\u001b[1;32m    501\u001b[0m             \u001b[0msock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mserver_side\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_side\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36m_create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m   1038\u001b[0m                         \u001b[0;31m# non-blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"do_handshake_on_connect should not be specified for non-blocking sockets\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1307\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1309\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1310\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --- INSTALLATION ---\n",
    "# pip install gnews newspaper3k pandas requests\n",
    "\n",
    "from gnews import GNews\n",
    "from newspaper import Article, Config\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "USER_AGENT = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36'\n",
    "TIMEOUT = 15  # seconds\n",
    "\n",
    "# Configure newspaper\n",
    "config = Config()\n",
    "config.browser_user_agent = USER_AGENT\n",
    "config.request_timeout = TIMEOUT\n",
    "\n",
    "# --- FUNCTION TO RESOLVE REDIRECTS ---\n",
    "def resolve_real_url(google_news_url):\n",
    "    try:\n",
    "        response = requests.head(\n",
    "            google_news_url, \n",
    "            timeout=TIMEOUT,\n",
    "            allow_redirects=True,\n",
    "            headers={'User-Agent': USER_AGENT}\n",
    "        )\n",
    "        return response.url\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå URL resolution failed: {e}\")\n",
    "        return google_news_url  # Return original as fallback\n",
    "\n",
    "# --- FUNCTION TO EXTRACT ARTICLE CONTENT ---\n",
    "def extract_article_content(url):\n",
    "    try:\n",
    "        article = Article(url, config=config)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        return article.title, article.text\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Article extraction failed: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# --- PARAMETERS ---\n",
    "query = \"USAID Kenya\"\n",
    "start_date = datetime(2025, 3, 28)\n",
    "end_date = datetime(2025, 6, 3)\n",
    "chunk_days = 7\n",
    "max_results_per_chunk = 50\n",
    "languages = ['en', 'sw']  # English and Swahili\n",
    "\n",
    "# --- STORAGE ---\n",
    "all_articles = []\n",
    "\n",
    "# --- LOOP THROUGH LANGUAGES ---\n",
    "for lang in languages:\n",
    "    print(f\"\\nüåê Searching in language: {lang.upper()}\")\n",
    "    current_start = start_date\n",
    "    gnews = GNews(language=lang, country='KE', max_results=max_results_per_chunk)\n",
    "\n",
    "    while current_start < end_date:\n",
    "        current_end = min(current_start + timedelta(days=chunk_days), end_date)\n",
    "        gnews.start_date = current_start\n",
    "        gnews.end_date = current_end\n",
    "\n",
    "        print(f\"üîç {lang.upper()}: {current_start.date()} to {current_end.date()}\")\n",
    "\n",
    "        try:\n",
    "            results = gnews.get_news(query)\n",
    "            print(f\"   ‚úÖ Found {len(results)} articles\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Search error: {e}\")\n",
    "            results = []\n",
    "            time.sleep(5)  # Wait before retry\n",
    "\n",
    "        for article in results:\n",
    "            try:\n",
    "                real_url = resolve_real_url(article['url'])\n",
    "                print(f\"   Processing: {real_url[:70]}...\")\n",
    "                \n",
    "                title, text = extract_article_content(real_url)\n",
    "                \n",
    "                if not text:\n",
    "                    # Try with requests as fallback\n",
    "                    try:\n",
    "                        response = requests.get(real_url, timeout=TIMEOUT, headers={'User-Agent': USER_AGENT})\n",
    "                        text = response.text[:5000] + \"...\"  # Truncate long HTML\n",
    "                    except:\n",
    "                        text = \"CONTENT_EXTRACTION_FAILED\"\n",
    "                \n",
    "                all_articles.append({\n",
    "                    'title': title or article.get('title', 'NO_TITLE'),\n",
    "                    'url': real_url,\n",
    "                    'published_date': article.get('published date'),\n",
    "                    'source': article['publisher']['title'] if 'publisher' in article else 'UNKNOWN',\n",
    "                    'language': lang,\n",
    "                    'text': text\n",
    "                })\n",
    "                time.sleep(1)  # Be polite to servers\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ùå Article processing failed: {e}\")\n",
    "                continue\n",
    "\n",
    "        current_start += timedelta(days=chunk_days)\n",
    "\n",
    "# --- SAVE TO CSV ---\n",
    "df = pd.DataFrame(all_articles)\n",
    "df['published_date'] = pd.to_datetime(df['published_date'], errors='coerce')\n",
    "csv_path = \"../data/raw/gnews_usaid_kenya_full_en_sw.csv\"\n",
    "#df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Done. Saved {len(df)} articles to {csv_path}\")\n",
    "print(f\"Success rate: {len(df[df['text'].str.len() > 100])}/{len(df)} with content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d2b5473",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/raw/leo_newsapi_articles.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564ff37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "leo_newsapi_articles.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69e05c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1498 entries, 0 to 1497\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   keyword       1498 non-null   object\n",
      " 1   source        1498 non-null   object\n",
      " 2   author        1379 non-null   object\n",
      " 3   title         1494 non-null   object\n",
      " 4   description   1479 non-null   object\n",
      " 5   content       1498 non-null   object\n",
      " 6   url           1498 non-null   object\n",
      " 7   published_at  1498 non-null   object\n",
      "dtypes: object(8)\n",
      "memory usage: 93.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f794847a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>source</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>content</th>\n",
       "      <th>url</th>\n",
       "      <th>published_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USAID</td>\n",
       "      <td>Origo.hu</td>\n",
       "      <td>Origo</td>\n",
       "      <td>Ha Pride, akkor el a kezekkel az MTA-t√≥l!</td>\n",
       "      <td>K√∂sz√∂nj√ºk meg a biol√≥gusoknak, hogy a dolgot m...</td>\n",
       "      <td>Nem tett semmit az MTA biol√≥gusainak hada, csa...</td>\n",
       "      <td>https://www.origo.hu/itthon/2025/06/mta-biolog...</td>\n",
       "      <td>2025-06-18 13:41:20+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USAID</td>\n",
       "      <td>Nakedcapitalism.com</td>\n",
       "      <td>Yves Smith</td>\n",
       "      <td>Links 6/18/2025</td>\n",
       "      <td>Our punchy daily links: dodgy drugs, wild weat...</td>\n",
       "      <td>New York City Council Proposes Legislation to ...</td>\n",
       "      <td>https://www.nakedcapitalism.com/2025/06/links-...</td>\n",
       "      <td>2025-06-18 10:58:40+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USAID</td>\n",
       "      <td>Expansion.com</td>\n",
       "      <td>Martin Wolf</td>\n",
       "      <td>¬øPara qui√©n gobierna Trump?</td>\n",
       "      <td>¬øPara qui√©n gobierna Trump? ¬øA los intereses d...</td>\n",
       "      <td>La gran y hermosa ley fiscal es un ejemplo cl√°...</td>\n",
       "      <td>https://www.expansion.com/economia/financial-t...</td>\n",
       "      <td>2025-06-18 09:44:46+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USAID</td>\n",
       "      <td>Milenio</td>\n",
       "      <td>Martin Wolf</td>\n",
       "      <td>¬øPara qui√©n gobierna Donald Trump?</td>\n",
       "      <td>¬øA qui√©n beneficia Trump? ¬øA los intereses de ...</td>\n",
       "      <td>¬øA qui√©n beneficia Trump? ¬øA los intereses de ...</td>\n",
       "      <td>https://www.milenio.com/negocios/financial-tim...</td>\n",
       "      <td>2025-06-18 06:34:47+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USAID</td>\n",
       "      <td>Lewrockwell.com</td>\n",
       "      <td>Brandon Smith</td>\n",
       "      <td>Illegal Alien Economy: How Foreign Nations Exp...</td>\n",
       "      <td>This article was written by Brandon Smith and ...</td>\n",
       "      <td>This article was written by Brandon Smith and ...</td>\n",
       "      <td>https://www.lewrockwell.com/2025/06/brandon-sm...</td>\n",
       "      <td>2025-06-18 04:01:00+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  keyword               source         author  \\\n",
       "0   USAID             Origo.hu          Origo   \n",
       "1   USAID  Nakedcapitalism.com     Yves Smith   \n",
       "2   USAID        Expansion.com    Martin Wolf   \n",
       "3   USAID              Milenio    Martin Wolf   \n",
       "4   USAID      Lewrockwell.com  Brandon Smith   \n",
       "\n",
       "                                               title  \\\n",
       "0          Ha Pride, akkor el a kezekkel az MTA-t√≥l!   \n",
       "1                                    Links 6/18/2025   \n",
       "2                        ¬øPara qui√©n gobierna Trump?   \n",
       "3                 ¬øPara qui√©n gobierna Donald Trump?   \n",
       "4  Illegal Alien Economy: How Foreign Nations Exp...   \n",
       "\n",
       "                                         description  \\\n",
       "0  K√∂sz√∂nj√ºk meg a biol√≥gusoknak, hogy a dolgot m...   \n",
       "1  Our punchy daily links: dodgy drugs, wild weat...   \n",
       "2  ¬øPara qui√©n gobierna Trump? ¬øA los intereses d...   \n",
       "3  ¬øA qui√©n beneficia Trump? ¬øA los intereses de ...   \n",
       "4  This article was written by Brandon Smith and ...   \n",
       "\n",
       "                                             content  \\\n",
       "0  Nem tett semmit az MTA biol√≥gusainak hada, csa...   \n",
       "1  New York City Council Proposes Legislation to ...   \n",
       "2  La gran y hermosa ley fiscal es un ejemplo cl√°...   \n",
       "3  ¬øA qui√©n beneficia Trump? ¬øA los intereses de ...   \n",
       "4  This article was written by Brandon Smith and ...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.origo.hu/itthon/2025/06/mta-biolog...   \n",
       "1  https://www.nakedcapitalism.com/2025/06/links-...   \n",
       "2  https://www.expansion.com/economia/financial-t...   \n",
       "3  https://www.milenio.com/negocios/financial-tim...   \n",
       "4  https://www.lewrockwell.com/2025/06/brandon-sm...   \n",
       "\n",
       "                published_at  \n",
       "0  2025-06-18 13:41:20+00:00  \n",
       "1  2025-06-18 10:58:40+00:00  \n",
       "2  2025-06-18 09:44:46+00:00  \n",
       "3  2025-06-18 06:34:47+00:00  \n",
       "4  2025-06-18 04:01:00+00:00  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4459a850",
   "metadata": {},
   "source": [
    "## News from `RSS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c484003b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üåê Processing language: EN\n",
      "üîó Reading RSS: https://news.google.com/rss/search?q=USAID Kenya+when:30d&hl=en-KE&gl=KE&ceid=KE:en\n"
     ]
    },
    {
     "ename": "InvalidURL",
     "evalue": "URL can't contain control characters. '/rss/search?q=USAID Kenya+when:30d&hl=en-KE&gl=KE&ceid=KE:en' (found at least ' ')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidURL\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-11e6966ea1b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0murl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"üîó Reading RSS: {url}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mfeed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeedparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/feedparser/api.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(url_file_stream_or_string, etag, modified, agent, referrer, handlers, request_headers, response_headers, resolve_relative_uris, sanitize_html)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_resource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_file_stream_or_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodified\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreferrer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_headers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mURLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         result.update({\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/feedparser/api.py\u001b[0m in \u001b[0;36m_open_resource\u001b[0;34m(url_file_stream_or_string, etag, modified, agent, referrer, handlers, request_headers, result)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_file_stream_or_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m        \u001b[0;32mand\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_file_stream_or_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'http'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'https'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ftp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'file'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'feed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_file_stream_or_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodified\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreferrer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_headers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;31m# try to open with native open function (if url_file_stream_or_string is a filename)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/feedparser/http.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, etag, modified, agent, referrer, handlers, request_headers, result)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandlers\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_FeedURLHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# RMK - must clear so we only send our custom User-Agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'urllib.Request'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0m\u001b[1;32m    543\u001b[0m                                   '_open', req)\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1393\u001b[0;31m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0m\u001b[1;32m   1394\u001b[0m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[1;32m   1395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0m\u001b[1;32m   1351\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[1;32m   1352\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1253\u001b[0m                 encode_chunked=False):\n\u001b[1;32m   1254\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1264\u001b[0m             \u001b[0mskips\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'skip_accept_encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1266\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mputrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mskips\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m         \u001b[0;31m# chunked encoding will happen if HTTP/1.1 is used and either\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mputrequest\u001b[0;34m(self, method, url, skip_host, skip_accept_encoding)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'%s %s %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_http_vsn_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_validate_path\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m   1198\u001b[0m         \u001b[0mmatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_contains_disallowed_url_pchar_re\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m             raise InvalidURL(f\"URL can't contain control characters. {url!r} \"\n\u001b[0m\u001b[1;32m   1201\u001b[0m                              f\"(found at least {match.group()!r})\")\n\u001b[1;32m   1202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidURL\u001b[0m: URL can't contain control characters. '/rss/search?q=USAID Kenya+when:30d&hl=en-KE&gl=KE&ceid=KE:en' (found at least ' ')"
     ]
    }
   ],
   "source": [
    "# --- INSTALLATION ---\n",
    "# pip install feedparser newspaper3k pandas\n",
    "\n",
    "import feedparser\n",
    "from newspaper import Article\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# --- PARAMETERS ---\n",
    "query = \"USAID Kenya\"\n",
    "rss_feeds = {\n",
    "    'en': [\n",
    "        f\"https://news.google.com/rss/search?q={query}+when:30d&hl=en-KE&gl=KE&ceid=KE:en\"\n",
    "    ],\n",
    "    'sw': [\n",
    "        f\"https://news.google.com/rss/search?q={query}+when:30d&hl=sw&gl=KE&ceid=KE:sw\"\n",
    "    ]\n",
    "}\n",
    "start_date = datetime(2025, 3, 28)\n",
    "end_date = datetime(2025, 6, 3)\n",
    "\n",
    "# --- FETCH + EXTRACT ---\n",
    "articles = []\n",
    "\n",
    "for lang, feeds in rss_feeds.items():\n",
    "    print(f\"\\nüåê Processing language: {lang.upper()}\")\n",
    "    for url in feeds:\n",
    "        print(f\"üîó Reading RSS: {url}\")\n",
    "        feed = feedparser.parse(url)\n",
    "        \n",
    "        for entry in feed.entries:\n",
    "            try:\n",
    "                published = entry.get('published', '') or entry.get('updated', '')\n",
    "                published_dt = pd.to_datetime(published, errors='coerce')\n",
    "                if pd.isna(published_dt):\n",
    "                    continue\n",
    "                if not (start_date <= published_dt <= end_date):\n",
    "                    continue\n",
    "\n",
    "                article = Article(entry.link)\n",
    "                article.download()\n",
    "                article.parse()\n",
    "\n",
    "                articles.append({\n",
    "                    'title': article.title,\n",
    "                    'url': entry.link,\n",
    "                    'published_date': published_dt,\n",
    "                    'source': entry.get('source', {}).get('title', 'Unknown'),\n",
    "                    'language': lang,\n",
    "                    'text': article.text\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Failed to parse article: {entry.link} - {e}\")\n",
    "\n",
    "# --- SAVE TO CSV ---\n",
    "df = pd.DataFrame(articles)\n",
    "df.to_csv(\"../data/raw/rss_usaid_kenya_en_sw.csv\", index=False)\n",
    "print(f\"\\n‚úÖ Done. Saved {len(df)} full-text articles from RSS feeds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16e63aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>published_date</th>\n",
       "      <th>source</th>\n",
       "      <th>language</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Google News</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiowFBV...</td>\n",
       "      <td>2025-04-30 07:00:00+00:00</td>\n",
       "      <td>Tech In Africa</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>Google News</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiZEFVX...</td>\n",
       "      <td>2025-04-21 07:00:00+00:00</td>\n",
       "      <td>TRT Global</td>\n",
       "      <td>sw</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>Google News</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMie0FVX...</td>\n",
       "      <td>2025-06-02 07:00:00+00:00</td>\n",
       "      <td>TechCabal</td>\n",
       "      <td>sw</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>Google News</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMilgFBV...</td>\n",
       "      <td>2025-05-15 07:00:00+00:00</td>\n",
       "      <td>Daily Nation</td>\n",
       "      <td>sw</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>Google News</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiswFBV...</td>\n",
       "      <td>2025-05-22 07:00:00+00:00</td>\n",
       "      <td>Kenyans</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>Google News</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiX0FVX...</td>\n",
       "      <td>2025-06-02 07:00:00+00:00</td>\n",
       "      <td>Centers for Disease Control and Prevention | C...</td>\n",
       "      <td>sw</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Google News</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiowFBV...</td>\n",
       "      <td>2025-04-22 07:00:00+00:00</td>\n",
       "      <td>Times Higher Education</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Google News</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMitgFBV...</td>\n",
       "      <td>2025-05-20 07:00:00+00:00</td>\n",
       "      <td>Tuko News</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Google News</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMi1AFBV...</td>\n",
       "      <td>2025-05-02 07:00:00+00:00</td>\n",
       "      <td>Business Insider Africa</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Google News</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMi1AFBV...</td>\n",
       "      <td>2025-05-02 07:00:00+00:00</td>\n",
       "      <td>Business Insider Africa</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           title                                                url  \\\n",
       "79   Google News  https://news.google.com/rss/articles/CBMiowFBV...   \n",
       "316  Google News  https://news.google.com/rss/articles/CBMiZEFVX...   \n",
       "485  Google News  https://news.google.com/rss/articles/CBMie0FVX...   \n",
       "396  Google News  https://news.google.com/rss/articles/CBMilgFBV...   \n",
       "167  Google News  https://news.google.com/rss/articles/CBMiswFBV...   \n",
       "493  Google News  https://news.google.com/rss/articles/CBMiX0FVX...   \n",
       "63   Google News  https://news.google.com/rss/articles/CBMiowFBV...   \n",
       "185  Google News  https://news.google.com/rss/articles/CBMitgFBV...   \n",
       "84   Google News  https://news.google.com/rss/articles/CBMi1AFBV...   \n",
       "124  Google News  https://news.google.com/rss/articles/CBMi1AFBV...   \n",
       "\n",
       "               published_date  \\\n",
       "79  2025-04-30 07:00:00+00:00   \n",
       "316 2025-04-21 07:00:00+00:00   \n",
       "485 2025-06-02 07:00:00+00:00   \n",
       "396 2025-05-15 07:00:00+00:00   \n",
       "167 2025-05-22 07:00:00+00:00   \n",
       "493 2025-06-02 07:00:00+00:00   \n",
       "63  2025-04-22 07:00:00+00:00   \n",
       "185 2025-05-20 07:00:00+00:00   \n",
       "84  2025-05-02 07:00:00+00:00   \n",
       "124 2025-05-02 07:00:00+00:00   \n",
       "\n",
       "                                                source language text  \n",
       "79                                      Tech In Africa       en       \n",
       "316                                         TRT Global       sw       \n",
       "485                                          TechCabal       sw       \n",
       "396                                       Daily Nation       sw       \n",
       "167                                            Kenyans       en       \n",
       "493  Centers for Disease Control and Prevention | C...       sw       \n",
       "63                              Times Higher Education       en       \n",
       "185                                          Tuko News       en       \n",
       "84                             Business Insider Africa       en       \n",
       "124                            Business Insider Africa       en       "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(n=10,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd629b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# --- SAVE TO CSV ---\\ndf = pd.DataFrame(all_articles)\\ndf[\\'published_at\\'] = pd.to_datetime(df[\\'published_at\\'])\\ndf.to_csv(\\'data/newsapi_articles.csv\\', index=False)\\n\\nprint(f\"‚úÖ Fetched {len(df)} articles. Saved to data/newsapi_articles.csv.\")'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# --- SAVE TO CSV ---\n",
    "df = pd.DataFrame(all_articles)\n",
    "df['published_at'] = pd.to_datetime(df['published_at'])\n",
    "df.to_csv('data/newsapi_articles.csv', index=False)\n",
    "\n",
    "print(f\"‚úÖ Fetched {len(df)} articles. Saved to data/newsapi_articles.csv.\")\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfb23993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error: 426 - {'status': 'error', 'code': 'parameterInvalid', 'message': 'You are trying to request results too far in the past. Your plan permits you to request articles as far back as 2025-05-12, but you have requested 2025-05-04. You may need to upgrade to a paid plan.'}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "a must be greater than 0 unless no samples are taken",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-011d97cb255d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_articles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m#print(df[['title', 'source', 'published_at']])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, n, frac, replace, weights, random_state, axis)\u001b[0m\n\u001b[1;32m   4991\u001b[0m             )\n\u001b[1;32m   4992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4993\u001b[0;31m         \u001b[0mlocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4994\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: a must be greater than 0 unless no samples are taken"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# --- PARAMETERS ---\n",
    "api_key = 'bc6c52fd05ee4e63827b7cf45fa0bdb2'\n",
    "\n",
    "# More focused query\n",
    "query = '(USAID OR donor aid OR foreign aid OR healthcare funding) AND Kenya'\n",
    "from_date = '2025-05-04'\n",
    "page_size = 100  # NewsAPI max per page\n",
    "max_pages = 1    # Free tier limit is 100 articles total\n",
    "\n",
    "# Recommended reliable/regional domains (you can expand)\n",
    "domains = 'nation.africa,standardmedia.co.ke,citizen.digital,aljazeera.com,bbc.com,reuters.com,who.int,devex.com,un.org'\n",
    "\n",
    "# --- FETCH ARTICLES ---\n",
    "all_articles = []\n",
    "\n",
    "for page in range(1, max_pages + 1):\n",
    "    url = (\n",
    "        f'https://newsapi.org/v2/everything?'\n",
    "        f'q={query}&'\n",
    "        f'from={from_date}&'\n",
    "        f'sortBy=publishedAt&'\n",
    "        f'domains={domains}&'\n",
    "        f'pageSize={page_size}&'\n",
    "        f'page={page}&'\n",
    "        f'apiKey={api_key}'\n",
    "    )\n",
    "\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"‚ùå Error: {response.status_code} - {response.json()}\")\n",
    "        break\n",
    "\n",
    "    articles = response.json().get('articles', [])\n",
    "    if not articles:\n",
    "        break\n",
    "\n",
    "    for article in articles:\n",
    "        all_articles.append({\n",
    "            'source': article['source']['name'],\n",
    "            'author': article.get('author'),\n",
    "            'title': article.get('title'),\n",
    "            'description': article.get('description'),\n",
    "            'content': article.get('content'),\n",
    "            'url': article.get('url'),\n",
    "            'published_at': article.get('publishedAt')\n",
    "        })\n",
    "\n",
    "# --- Convert to DataFrame ---\n",
    "df = pd.DataFrame(all_articles)\n",
    "#print(df[['title', 'source', 'published_at']])\n",
    "df.sample(n=10,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f1f643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3219a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2 entries, 7 to 9\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   source        2 non-null      object\n",
      " 1   author        2 non-null      object\n",
      " 2   title         2 non-null      object\n",
      " 3   description   2 non-null      object\n",
      " 4   content       2 non-null      object\n",
      " 5   url           2 non-null      object\n",
      " 6   published_at  2 non-null      object\n",
      "dtypes: object(7)\n",
      "memory usage: 128.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_citizen = df[df['source']== 'Citizen.digital']\n",
    "df_citizen.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea13914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In 2024, the World Bank projected that the overall unemployment rate of the youth in Kenya was at 5.7 per cent. \\r\\nThe Federation of Kenya (FKE) says that the youth account for over 35 per cent of the‚Ä¶ [+8544 chars]'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "214"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df_citizen['content'].to_list()\n",
    "display( x[0])\n",
    "len(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5d3061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e32491c2",
   "metadata": {},
   "source": [
    "## 4. X Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42bc67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping tweets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error retrieving https://twitter.com/i/api/graphql/7jT5GT59P8IFjgxwqnEdQw/SearchTimeline?variables=%7B%22rawQuery%22%3A%22USAID%20Kenya%20lang%3Aen%20since%3A2024-12-01%20until%3A2025-06-01%22%2C%22count%22%3A20%2C%22product%22%3A%22Latest%22%2C%22withDownvotePerspective%22%3Afalse%2C%22withReactionsMetadata%22%3Afalse%2C%22withReactionsPerspective%22%3Afalse%7D&features=%7B%22rweb_lists_timeline_redesign_enabled%22%3Afalse%2C%22blue_business_profile_image_shape_enabled%22%3Afalse%2C%22responsive_web_graphql_exclude_directive_enabled%22%3Atrue%2C%22verified_phone_label_enabled%22%3Afalse%2C%22creator_subscriptions_tweet_preview_api_enabled%22%3Afalse%2C%22responsive_web_graphql_timeline_navigation_enabled%22%3Atrue%2C%22responsive_web_graphql_skip_user_profile_image_extensions_enabled%22%3Afalse%2C%22tweetypie_unmention_optimization_enabled%22%3Atrue%2C%22vibe_api_enabled%22%3Atrue%2C%22responsive_web_edit_tweet_api_enabled%22%3Atrue%2C%22graphql_is_translatable_rweb_tweet_is_translatable_enabled%22%3Atrue%2C%22view_counts_everywhere_api_enabled%22%3Atrue%2C%22longform_notetweets_consumption_enabled%22%3Atrue%2C%22tweet_awards_web_tipping_enabled%22%3Afalse%2C%22freedom_of_speech_not_reach_fetch_enabled%22%3Afalse%2C%22standardized_nudges_misinfo%22%3Atrue%2C%22tweet_with_visibility_results_prefer_gql_limited_actions_policy_enabled%22%3Afalse%2C%22interactive_text_enabled%22%3Atrue%2C%22responsive_web_text_conversations_enabled%22%3Afalse%2C%22longform_notetweets_rich_text_read_enabled%22%3Afalse%2C%22longform_notetweets_inline_media_enabled%22%3Afalse%2C%22responsive_web_enhance_cards_enabled%22%3Afalse%2C%22responsive_web_twitter_blue_verified_badge_is_enabled%22%3Atrue%7D: blocked (404)\n",
      "4 requests to https://twitter.com/i/api/graphql/7jT5GT59P8IFjgxwqnEdQw/SearchTimeline?variables=%7B%22rawQuery%22%3A%22USAID%20Kenya%20lang%3Aen%20since%3A2024-12-01%20until%3A2025-06-01%22%2C%22count%22%3A20%2C%22product%22%3A%22Latest%22%2C%22withDownvotePerspective%22%3Afalse%2C%22withReactionsMetadata%22%3Afalse%2C%22withReactionsPerspective%22%3Afalse%7D&features=%7B%22rweb_lists_timeline_redesign_enabled%22%3Afalse%2C%22blue_business_profile_image_shape_enabled%22%3Afalse%2C%22responsive_web_graphql_exclude_directive_enabled%22%3Atrue%2C%22verified_phone_label_enabled%22%3Afalse%2C%22creator_subscriptions_tweet_preview_api_enabled%22%3Afalse%2C%22responsive_web_graphql_timeline_navigation_enabled%22%3Atrue%2C%22responsive_web_graphql_skip_user_profile_image_extensions_enabled%22%3Afalse%2C%22tweetypie_unmention_optimization_enabled%22%3Atrue%2C%22vibe_api_enabled%22%3Atrue%2C%22responsive_web_edit_tweet_api_enabled%22%3Atrue%2C%22graphql_is_translatable_rweb_tweet_is_translatable_enabled%22%3Atrue%2C%22view_counts_everywhere_api_enabled%22%3Atrue%2C%22longform_notetweets_consumption_enabled%22%3Atrue%2C%22tweet_awards_web_tipping_enabled%22%3Afalse%2C%22freedom_of_speech_not_reach_fetch_enabled%22%3Afalse%2C%22standardized_nudges_misinfo%22%3Atrue%2C%22tweet_with_visibility_results_prefer_gql_limited_actions_policy_enabled%22%3Afalse%2C%22interactive_text_enabled%22%3Atrue%2C%22responsive_web_text_conversations_enabled%22%3Afalse%2C%22longform_notetweets_rich_text_read_enabled%22%3Afalse%2C%22longform_notetweets_inline_media_enabled%22%3Afalse%2C%22responsive_web_enhance_cards_enabled%22%3Afalse%2C%22responsive_web_twitter_blue_verified_badge_is_enabled%22%3Atrue%7D failed, giving up.\n",
      "Errors: blocked (404), blocked (404), blocked (404), blocked (404)\n",
      "  0%|          | 0/500 [00:13<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ScraperException",
     "evalue": "4 requests to https://twitter.com/i/api/graphql/7jT5GT59P8IFjgxwqnEdQw/SearchTimeline?variables=%7B%22rawQuery%22%3A%22USAID%20Kenya%20lang%3Aen%20since%3A2024-12-01%20until%3A2025-06-01%22%2C%22count%22%3A20%2C%22product%22%3A%22Latest%22%2C%22withDownvotePerspective%22%3Afalse%2C%22withReactionsMetadata%22%3Afalse%2C%22withReactionsPerspective%22%3Afalse%7D&features=%7B%22rweb_lists_timeline_redesign_enabled%22%3Afalse%2C%22blue_business_profile_image_shape_enabled%22%3Afalse%2C%22responsive_web_graphql_exclude_directive_enabled%22%3Atrue%2C%22verified_phone_label_enabled%22%3Afalse%2C%22creator_subscriptions_tweet_preview_api_enabled%22%3Afalse%2C%22responsive_web_graphql_timeline_navigation_enabled%22%3Atrue%2C%22responsive_web_graphql_skip_user_profile_image_extensions_enabled%22%3Afalse%2C%22tweetypie_unmention_optimization_enabled%22%3Atrue%2C%22vibe_api_enabled%22%3Atrue%2C%22responsive_web_edit_tweet_api_enabled%22%3Atrue%2C%22graphql_is_translatable_rweb_tweet_is_translatable_enabled%22%3Atrue%2C%22view_counts_everywhere_api_enabled%22%3Atrue%2C%22longform_notetweets_consumption_enabled%22%3Atrue%2C%22tweet_awards_web_tipping_enabled%22%3Afalse%2C%22freedom_of_speech_not_reach_fetch_enabled%22%3Afalse%2C%22standardized_nudges_misinfo%22%3Atrue%2C%22tweet_with_visibility_results_prefer_gql_limited_actions_policy_enabled%22%3Afalse%2C%22interactive_text_enabled%22%3Atrue%2C%22responsive_web_text_conversations_enabled%22%3Afalse%2C%22longform_notetweets_rich_text_read_enabled%22%3Afalse%2C%22longform_notetweets_inline_media_enabled%22%3Afalse%2C%22responsive_web_enhance_cards_enabled%22%3Afalse%2C%22responsive_web_twitter_blue_verified_badge_is_enabled%22%3Atrue%7D failed, giving up.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mScraperException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7264c2213323>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Scraping tweets...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msntwitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTwitterSearchScraper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mmax_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1165\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1166\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/snscrape/modules/twitter.py\u001b[0m in \u001b[0;36mget_items\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1761\u001b[0m                 \u001b[0mpaginationParams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'variables'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpaginationVariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'features'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1763\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_api_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://twitter.com/i/api/graphql/7jT5GT59P8IFjgxwqnEdQw/SearchTimeline'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_TwitterAPIType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGRAPHQL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaginationParams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstructionsPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'search_by_raw_query'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'search_timeline'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'timeline'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'instructions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1764\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graphql_timeline_instructions_to_tweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'search_by_raw_query'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'search_timeline'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'timeline'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'instructions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/snscrape/modules/twitter.py\u001b[0m in \u001b[0;36m_iter_api_data\u001b[0;34m(self, endpoint, apiType, params, paginationParams, cursor, direction, instructionsPath)\u001b[0m\n\u001b[1;32m    913\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m                         \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Retrieving scroll page {cursor}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m                         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_api_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapiType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreqParams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstructionsPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstructionsPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/snscrape/modules/twitter.py\u001b[0m in \u001b[0;36m_get_api_data\u001b[0;34m(self, endpoint, apiType, params, instructionsPath)\u001b[0m\n\u001b[1;32m    884\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mapiType\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0m_TwitterAPIType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGRAPHQL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m                         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseparators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m':'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquote_via\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquote\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 886\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apiHeaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponseOkCallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_api_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapiType\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapiType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstructionsPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstructionsPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_snscrapeObj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/snscrape/base.py\u001b[0m in \u001b[0;36m_get\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GET'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_post\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/snscrape/base.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, method, url, params, data, headers, timeout, responseOkCallback, allowRedirects, proxies)\u001b[0m\n\u001b[1;32m    269\u001b[0m                         \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfatal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                         \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfatal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Errors: {\", \".join(errors)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mScraperException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reached unreachable code'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mScraperException\u001b[0m: 4 requests to https://twitter.com/i/api/graphql/7jT5GT59P8IFjgxwqnEdQw/SearchTimeline?variables=%7B%22rawQuery%22%3A%22USAID%20Kenya%20lang%3Aen%20since%3A2024-12-01%20until%3A2025-06-01%22%2C%22count%22%3A20%2C%22product%22%3A%22Latest%22%2C%22withDownvotePerspective%22%3Afalse%2C%22withReactionsMetadata%22%3Afalse%2C%22withReactionsPerspective%22%3Afalse%7D&features=%7B%22rweb_lists_timeline_redesign_enabled%22%3Afalse%2C%22blue_business_profile_image_shape_enabled%22%3Afalse%2C%22responsive_web_graphql_exclude_directive_enabled%22%3Atrue%2C%22verified_phone_label_enabled%22%3Afalse%2C%22creator_subscriptions_tweet_preview_api_enabled%22%3Afalse%2C%22responsive_web_graphql_timeline_navigation_enabled%22%3Atrue%2C%22responsive_web_graphql_skip_user_profile_image_extensions_enabled%22%3Afalse%2C%22tweetypie_unmention_optimization_enabled%22%3Atrue%2C%22vibe_api_enabled%22%3Atrue%2C%22responsive_web_edit_tweet_api_enabled%22%3Atrue%2C%22graphql_is_translatable_rweb_tweet_is_translatable_enabled%22%3Atrue%2C%22view_counts_everywhere_api_enabled%22%3Atrue%2C%22longform_notetweets_consumption_enabled%22%3Atrue%2C%22tweet_awards_web_tipping_enabled%22%3Afalse%2C%22freedom_of_speech_not_reach_fetch_enabled%22%3Afalse%2C%22standardized_nudges_misinfo%22%3Atrue%2C%22tweet_with_visibility_results_prefer_gql_limited_actions_policy_enabled%22%3Afalse%2C%22interactive_text_enabled%22%3Atrue%2C%22responsive_web_text_conversations_enabled%22%3Afalse%2C%22longform_notetweets_rich_text_read_enabled%22%3Afalse%2C%22longform_notetweets_inline_media_enabled%22%3Afalse%2C%22responsive_web_enhance_cards_enabled%22%3Afalse%2C%22responsive_web_twitter_blue_verified_badge_is_enabled%22%3Atrue%7D failed, giving up."
     ]
    }
   ],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# List of keywords and common Kenyan locations (can expand)\n",
    "kenyan_locations = ['kenya', 'nairobi', 'mombasa', 'kisumu', 'eldoret', 'nakuru', 'ke']\n",
    "\n",
    "# Function to check if location mentions a Kenyan place\n",
    "def is_kenyan_location(loc):\n",
    "    if not loc:\n",
    "        return False\n",
    "    loc = loc.lower()\n",
    "    return any(place in loc for place in kenyan_locations)\n",
    "\n",
    "# Query Twitter for tweets mentioning USAID and Kenya\n",
    "query = 'USAID Kenya lang:en since:2024-12-01 until:2025-06-01'\n",
    "tweets = []\n",
    "max_results = 500  # increase if needed\n",
    "\n",
    "print(\"Scraping tweets...\")\n",
    "for i, tweet in enumerate(tqdm(sntwitter.TwitterSearchScraper(query).get_items(), total=max_results)):\n",
    "    if i >= max_results:\n",
    "        break\n",
    "    tweets.append({\n",
    "        'date': tweet.date,\n",
    "        'username': tweet.user.username,\n",
    "        'content': tweet.content,\n",
    "        'user_location': tweet.user.location,\n",
    "        'coordinates': tweet.coordinates\n",
    "    })\n",
    "\n",
    "# Load into DataFrame\n",
    "df = pd.DataFrame(tweets)\n",
    "\n",
    "# Filter tweets by user_location (Kenya-only)\n",
    "df['is_kenyan'] = df['user_location'].apply(is_kenyan_location)\n",
    "df_kenya = df[df['is_kenyan'] == True].reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nTotal tweets scraped: {len(df)}\")\n",
    "print(f\"Tweets with Kenyan location: {len(df_kenya)}\")\n",
    "\n",
    "# Preview\n",
    "print(\"\\nSample Kenyan tweet:\")\n",
    "print(df_kenya[['date', 'username', 'content', 'user_location']].iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5463a5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X API client initialized.\n",
      "\n",
      "--- Attempting to collect X data for 'USAID Kenya lang:en -is:retweet' from 2025-03-01T00:00:00Z ---\n",
      "NOTE: X API free/basic tiers typically limit searches to the last 7 days.\n",
      "Actual search window being attempted: from 2025-06-04T18:32:06Z to 2025-06-11T18:32:06Z\n",
      "Tweepy API Error: 401 Unauthorized\n",
      "Unauthorized\n",
      "This often indicates rate limits, invalid query, or insufficient access permissions (e.g., historical access blocked).\n"
     ]
    }
   ],
   "source": [
    "# src/x_collection.py\n",
    "import os\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "\n",
    "X_BEARER_TOKEN = os.getenv(\"X_BEARER_TOKEN\")\n",
    "\n",
    "try:\n",
    "    client = tweepy.Client(X_BEARER_TOKEN)\n",
    "    print(\"X API client initialized.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing X API client: {e}\")\n",
    "    print(\"Please ensure your X_BEARER_TOKEN is correct and valid. Skipping X data collection.\")\n",
    "    client = None\n",
    "\n",
    "if client:\n",
    "    # Define your keywords and a recent start date (REQUIRED FOR FREE/BASIC TIER)\n",
    "    query_keywords = \"USAID Kenya lang:en -is:retweet\" # English, exclude retweets\n",
    "\n",
    "    # For free tier, search is limited to the last 7 days.\n",
    "    # We will try to set the date to March 1st, 2025, but anticipate failure/no results\n",
    "    # if it's outside the 7-day window for your current execution date.\n",
    "    target_start_date_str = \"2025-03-01T00:00:00Z\" # ISO 8601 format\n",
    "    # The actual 'start_time' for search_recent_tweets must be within 7 days.\n",
    "    # We'll set it to 7 days ago to demonstrate functionality, but this will NOT get March 1st, 2025 data currently.\n",
    "    actual_start_time_for_search = (datetime.utcnow() - timedelta(days=7)).replace(microsecond=0)\n",
    "    end_time_for_search = datetime.utcnow().replace(microsecond=0)\n",
    "\n",
    "    print(f\"\\n--- Attempting to collect X data for '{query_keywords}' from {target_start_date_str} ---\")\n",
    "    print(f\"NOTE: X API free/basic tiers typically limit searches to the last 7 days.\")\n",
    "    print(f\"Actual search window being attempted: from {actual_start_time_for_search.isoformat()}Z to {end_time_for_search.isoformat()}Z\")\n",
    "\n",
    "    tweets_data = []\n",
    "    try:\n",
    "        # max_results is 100 for recent search endpoint on standard access.\n",
    "        # Free tier is even lower.\n",
    "        response = client.search_recent_tweets(\n",
    "            query=query_keywords,\n",
    "            start_time=actual_start_time_for_search,\n",
    "            end_time=end_time_for_search,\n",
    "            tweet_fields=[\"created_at\", \"public_metrics\", \"author_id\", \"lang\"],\n",
    "            expansions=[\"author_id\"],\n",
    "            max_results=100 # Adjust based on your tier and testing\n",
    "        )\n",
    "\n",
    "        if response and response.data:\n",
    "            users = {user[\"id\"]: user for user in response.includes.get(\"users\", [])}\n",
    "            for tweet in response.data:\n",
    "                author_username = users.get(tweet.author_id, {}).get(\"username\", \"[unknown]\")\n",
    "                tweets_data.append({\n",
    "                    \"id\": tweet.id,\n",
    "                    \"text\": tweet.text,\n",
    "                    \"created_at\": tweet.created_at,\n",
    "                    \"retweet_count\": tweet.public_metrics.get(\"retweet_count\", 0),\n",
    "                    \"reply_count\": tweet.public_metrics.get(\"reply_count\", 0),\n",
    "                    \"like_count\": tweet.public_metrics.get(\"like_count\", 0),\n",
    "                    \"quote_count\": tweet.public_metrics.get(\"quote_count\", 0),\n",
    "                    \"author_id\": tweet.author_id,\n",
    "                    \"author_username\": author_username\n",
    "                })\n",
    "            df_tweets = pd.DataFrame(tweets_data)\n",
    "            print(f\"\\n--- X Data Preview (first 5 relevant entries) ---\")\n",
    "            print(df_tweets[['text', 'author_username', 'created_at', 'like_count']].head())\n",
    "            print(f\"Total relevant X tweets collected: {len(df_tweets)}\")\n",
    "            df_tweets.to_csv(\"../data/raw/x_usaid_kenya_tweets.csv\", index=False)\n",
    "            print(\"\\nX data saved to ../data/raw/x_usaid_kenya_tweets.csv\")\n",
    "        else:\n",
    "            print(\"No tweets found for this query within the accessible time range or API limits reached.\")\n",
    "\n",
    "    except tweepy.TweepyException as e:\n",
    "        print(f\"Tweepy API Error: {e}\")\n",
    "        print(\"This often indicates rate limits, invalid query, or insufficient access permissions (e.g., historical access blocked).\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "else:\n",
    "    print(\"X API client not initialized. Skipping X data collection.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d5d252",
   "metadata": {},
   "source": [
    "## X Data Collection (Tweepy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cea1ebae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üåê Language: EN\n",
      "üîç Searching for keyword: USAID\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Sleeping for 795 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error for keyword 'USAID' in lang 'en': ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\n",
      "üîç Searching for keyword: foreign aid\n",
      "üîç Searching for keyword: aid cuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Sleeping for 900 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Searching for keyword: Trump aid cuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Sleeping for 900 seconds.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a19805e77602>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{kw} lang:{lang} -is:retweet -is:reply'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             response = client.search_recent_tweets(\n\u001b[0m\u001b[1;32m     48\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mmax_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/tweepy/client.py\u001b[0m in \u001b[0;36msearch_recent_tweets\u001b[0;34m(self, query, user_auth, **params)\u001b[0m\n\u001b[1;32m   1264\u001b[0m         \"\"\"\n\u001b[1;32m   1265\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"query\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1266\u001b[0;31m         return self._make_request(\n\u001b[0m\u001b[1;32m   1267\u001b[0m             \u001b[0;34m\"GET\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/2/tweets/search/recent\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m             endpoint_parameters=(\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/tweepy/client.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, method, route, params, endpoint_parameters, json, data_type, user_auth)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mrequest_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         response = self.request(method, route, params=request_params,\n\u001b[0m\u001b[1;32m    130\u001b[0m                                 json=json, user_auth=user_auth)\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/tweepy/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, route, params, json, user_auth)\u001b[0m\n\u001b[1;32m    110\u001b[0m                             \u001b[0;34mf\"Sleeping for {sleep_time} seconds.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                         )\n\u001b[0;32m--> 112\u001b[0;31m                         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msleep_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_auth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# --- AUTHENTICATION ---\n",
    "client = tweepy.Client(\n",
    "    bearer_token=\"AAAAAAAAAAAAAAAAAAAAAM7V2QEAAAAATxtwYJDH5s3p7OLG7SAX9%2FxIld4%3Dv3nMASZz36WlM95pBqU8EZgy1kiFIQGBvwQ8ZehZZm9WyqYvV1\",  \n",
    "    consumer_key=\"jbTBGlKFu4sYq3ZYDrt0LRzbA\",\n",
    "    consumer_secret=\"Z9EqdClibzJhwMeu83am8D0jMl2cRIWGB73inhcoitY2OwyDZb\",\n",
    "    wait_on_rate_limit=True\n",
    ")\n",
    "\n",
    "# --- PARAMETERS ---\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Only allow tweets from past 7 days (Twitter limitation for this endpoint)\n",
    "start_time = (datetime.utcnow() - timedelta(days=6)).isoformat(\"T\") + \"Z\"\n",
    "\n",
    "max_results = 100\n",
    "languages = [\"en\", \"sw\"]  # English and Swahili\n",
    "keywords = [\n",
    "    # USAID-related\n",
    "    \"USAID\", \"foreign aid\", \"aid cuts\", \"Trump aid cuts\", \"USAID funding\",\n",
    "    \"project shutdown\", \"development funding\", \"NGO funding\", \"foreign assistance\",\n",
    "    \"terminated projects\", \"PEPFAR\", \"Feed the Future\", \"Tusome\", \"Power Africa\",\n",
    "    \"USAID education\", \"USAID health\", \"nutrition assistance\", \"malaria program\",\n",
    "    \"HIV funding\", \"Crops and Dairy\", \"WASH\", \"USAID climate\", \"USAID governance\",\n",
    "    \"USAID transparency\", \"resilience programs\", \"USAID devolution\", \"Youth program\",\n",
    "    \"EECA\", \"RTI\", \"KPLP\", \"SoCha\", \"ABT\", \"Prosper Africa\", \"BCG\", \"IDG\",\n",
    "    \"KHPQS\", \"OVC\", \"Tujitegemee\", \"Tujenge Jamii\", \"supply chain\", \"PMI Evolve\",\n",
    "    \"sanitation project\", \"community resilience\", \"Owod project\", \"nutrition program\",\n",
    "    \"resilience project\", \"digital transformation\", \"Africa Water Facility\",\n",
    "    \"trade reforms\", \"solar health\", \"elections grant\"\n",
    "]\n",
    "\n",
    "# --- STORAGE ---\n",
    "all_tweets = []\n",
    "\n",
    "# --- SEARCH LOOP ---\n",
    "for lang in languages:\n",
    "    print(f\"\\nüåê Language: {lang.upper()}\")\n",
    "    for kw in keywords:\n",
    "        print(f\"üîç Searching for keyword: {kw}\")\n",
    "        try:\n",
    "            query = f'{kw} lang:{lang} -is:retweet -is:reply'\n",
    "\n",
    "            response = client.search_recent_tweets(\n",
    "                query=query,\n",
    "                max_results=min(100, max_results),\n",
    "                start_time=start_time,\n",
    "                tweet_fields=[\"created_at\", \"lang\", \"public_metrics\", \"author_id\", \"text\"],\n",
    "                user_fields=[\"location\"],  # Request user location\n",
    "                expansions=[\"author_id\"]   # Get user metadata\n",
    "            )\n",
    "\n",
    "            tweets = response.data if response.data else []\n",
    "            users = {u.id: u for u in response.includes['users']} if response.includes else {}\n",
    "\n",
    "            for tweet in tweets:\n",
    "                user = users.get(tweet.author_id)\n",
    "                location = user.location if user and hasattr(user, 'location') else None\n",
    "\n",
    "                # Optional filter: if you only want tweets with Kenya in location or text\n",
    "                # if not location or ('kenya' not in location.lower() and 'kenya' not in tweet.text.lower()):\n",
    "                #     continue\n",
    "\n",
    "                all_tweets.append({\n",
    "                    \"keyword\": kw,\n",
    "                    \"lang\": lang,\n",
    "                    \"tweet_id\": tweet.id,\n",
    "                    \"author_id\": tweet.author_id,\n",
    "                    \"user_location\": location,\n",
    "                    \"created_at\": tweet.created_at,\n",
    "                    \"text\": tweet.text,\n",
    "                    \"retweets\": tweet.public_metrics['retweet_count'],\n",
    "                    \"likes\": tweet.public_metrics['like_count'],\n",
    "                    \"replies\": tweet.public_metrics['reply_count']\n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error for keyword '{kw}' in lang '{lang}': {e}\")\n",
    "\n",
    "# --- SAVE TO CSV ---\n",
    "df = pd.DataFrame(all_tweets)\n",
    "save_path = \"../data/raw/leo_twitter_usaid_tweets_multilang.csv\"\n",
    "df.to_csv(save_path, index=False)\n",
    "print(f\"\\n‚úÖ Scraped {len(df)} tweets (EN + SW). Saved to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3db4a61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news_leo = pd.read_csv('../data/raw/leo_newsapi_articles.csv')\n",
    "df_reddit =  pd.read_csv('../data/raw/leo_reddit_posts.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f512661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1498 entries, 0 to 1497\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   keyword       1498 non-null   object\n",
      " 1   source        1498 non-null   object\n",
      " 2   author        1379 non-null   object\n",
      " 3   title         1494 non-null   object\n",
      " 4   description   1479 non-null   object\n",
      " 5   content       1498 non-null   object\n",
      " 6   url           1498 non-null   object\n",
      " 7   published_at  1498 non-null   object\n",
      " 8   full_text     1194 non-null   object\n",
      "dtypes: object(9)\n",
      "memory usage: 105.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_news_leo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b62004b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 151 entries, 0 to 150\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   subreddit     151 non-null    object \n",
      " 1   search_term   151 non-null    object \n",
      " 2   title         151 non-null    object \n",
      " 3   text          145 non-null    object \n",
      " 4   created_utc   151 non-null    float64\n",
      " 5   created_date  151 non-null    object \n",
      " 6   score         151 non-null    int64  \n",
      " 7   num_comments  151 non-null    int64  \n",
      " 8   permalink     151 non-null    object \n",
      " 9   url           151 non-null    object \n",
      "dtypes: float64(1), int64(2), object(7)\n",
      "memory usage: 11.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_reddit.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e988c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
