{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb4b5d20",
   "metadata": {},
   "source": [
    "# USAID FUNDING SENTIMENTAL ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51b6eb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: praw in c:\\users\\ahb\\anaconda3\\lib\\site-packages (7.8.1)\n",
      "Requirement already satisfied: prawcore<3,>=2.4 in c:\\users\\ahb\\anaconda3\\lib\\site-packages (from praw) (2.4.0)\n",
      "Requirement already satisfied: update_checker>=0.18 in c:\\users\\ahb\\anaconda3\\lib\\site-packages (from praw) (0.18.0)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in c:\\users\\ahb\\anaconda3\\lib\\site-packages (from praw) (0.58.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in c:\\users\\ahb\\anaconda3\\lib\\site-packages (from prawcore<3,>=2.4->praw) (2.31.0)\n",
      "Requirement already satisfied: six in c:\\users\\ahb\\anaconda3\\lib\\site-packages (from websocket-client>=0.54.0->praw) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ahb\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ahb\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ahb\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ahb\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install praw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b933cc7",
   "metadata": {},
   "source": [
    "# Reddit Data Extraction with the Reddit API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5fb3fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching new posts from r/Kenya\n",
      "Fetching new posts from r/Africa\n",
      "Fetching new posts from r/EastAfrica\n",
      "Saved 200 matching posts to CSV.\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Reddit API credentials\n",
    "reddit = praw.Reddit(\n",
    "    client_id='fgIEgG6e6I_bFHDqpWQYdQ',\n",
    "    client_secret='qd7w7BaeDRr6L7AvK3H4AYAr-AENsA',\n",
    "    user_agent='Ill-Chocolate-4761'\n",
    ")\n",
    "\n",
    "subreddits = ['Kenya', 'Africa', 'EastAfrica']\n",
    "queries = [\n",
    "    \"USAID\", \"funding\", \"donor\", \"health\",\n",
    "    \"development\", \"foreign aid\", \"aid\"\n",
    "]\n",
    "\n",
    "data = []\n",
    "\n",
    "#Loop through subreddits and collect matching posts\n",
    "for sub in subreddits:\n",
    "    subreddit = reddit.subreddit(sub)\n",
    "    print(f\"Fetching new posts from r/{sub}\")\n",
    "    for post in subreddit.new(limit=1000):\n",
    "        post_text = f\"{post.title} {post.selftext}\".lower()\n",
    "        if any(q.lower() in post_text for q in queries):\n",
    "            data.append({\n",
    "                'subreddit': sub,\n",
    "                'title': post.title,\n",
    "                'score': post.score,\n",
    "                'url': post.url,\n",
    "                'created_utc': datetime.utcfromtimestamp(post.created_utc).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                'num_comments': post.num_comments,\n",
    "                'selftext': post.selftext\n",
    "            })\n",
    "        if len(data) >= 200:\n",
    "            break  # Stop after collecting 100 matches\n",
    "\n",
    "# Create DataFrame and save\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('reddit_usaid_sentiment_sample.csv', index=False)\n",
    "print(f\"Saved {len(df)} matching posts to CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6c166ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>url</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>I asked ChatGPT the Top 10 Things Humans Consi...</td>\n",
       "      <td>11</td>\n",
       "      <td>https://www.reddit.com/r/Kenya/comments/1lexnt...</td>\n",
       "      <td>2025-06-19 00:52:49</td>\n",
       "      <td>6</td>\n",
       "      <td>Credit to : EfficientPudding90\\n\\n1. Working 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>Jaba, Khat, Miraa, Muguka, Qat, itâ€™s time to q...</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.reddit.com/gallery/1leqfhr</td>\n",
       "      <td>2025-06-18 19:37:38</td>\n",
       "      <td>19</td>\n",
       "      <td>Kenyans, itâ€™s time to quit Jaba or Khat (Miraa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>People pleaser</td>\n",
       "      <td>19</td>\n",
       "      <td>https://www.reddit.com/r/Kenya/comments/1lenzr...</td>\n",
       "      <td>2025-06-18 18:02:04</td>\n",
       "      <td>5</td>\n",
       "      <td>Wagwan wadau.24M ,got a job close to 2 year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>ðŸ‡°ðŸ‡ª Why Is Kenya So Spiritually Important,And W...</td>\n",
       "      <td>6</td>\n",
       "      <td>https://www.reddit.com/r/Kenya/comments/1leldm...</td>\n",
       "      <td>2025-06-18 16:21:05</td>\n",
       "      <td>27</td>\n",
       "      <td>Lately Iâ€™ve been thinking hard.\\nWith everythi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>Guys. Motolov cocktails and catapults.</td>\n",
       "      <td>3</td>\n",
       "      <td>https://www.reddit.com/r/Kenya/comments/1lekzq...</td>\n",
       "      <td>2025-06-18 16:05:42</td>\n",
       "      <td>7</td>\n",
       "      <td>Paid goons na number ni 1% ya crowd. A good ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit                                              title  score  \\\n",
       "0     Kenya  I asked ChatGPT the Top 10 Things Humans Consi...     11   \n",
       "1     Kenya  Jaba, Khat, Miraa, Muguka, Qat, itâ€™s time to q...      1   \n",
       "2     Kenya                                     People pleaser     19   \n",
       "3     Kenya  ðŸ‡°ðŸ‡ª Why Is Kenya So Spiritually Important,And W...      6   \n",
       "4     Kenya             Guys. Motolov cocktails and catapults.      3   \n",
       "\n",
       "                                                 url          created_utc  \\\n",
       "0  https://www.reddit.com/r/Kenya/comments/1lexnt...  2025-06-19 00:52:49   \n",
       "1             https://www.reddit.com/gallery/1leqfhr  2025-06-18 19:37:38   \n",
       "2  https://www.reddit.com/r/Kenya/comments/1lenzr...  2025-06-18 18:02:04   \n",
       "3  https://www.reddit.com/r/Kenya/comments/1leldm...  2025-06-18 16:21:05   \n",
       "4  https://www.reddit.com/r/Kenya/comments/1lekzq...  2025-06-18 16:05:42   \n",
       "\n",
       "   num_comments                                           selftext  \n",
       "0             6  Credit to : EfficientPudding90\\n\\n1. Working 4...  \n",
       "1            19  Kenyans, itâ€™s time to quit Jaba or Khat (Miraa...  \n",
       "2             5     Wagwan wadau.24M ,got a job close to 2 year...  \n",
       "3            27  Lately Iâ€™ve been thinking hard.\\nWith everythi...  \n",
       "4             7  Paid goons na number ni 1% ya crowd. A good ca...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a1a5e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1179cf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(r\"C:\\Users\\AHB\\Desktop\\my_quick_acess\\3.Projects\\projects pipeline\\2025\\USAID-Kenya-Sentiment-Analysis\\data\\reddit_kitasi2.csv\"\n",
    "df.to_csv(r\"C:\\Users\\AHB\\Desktop\\my_quick_acess\\3.Projects\\projects pipeline\\2025\\USAID-Kenya-Sentiment-Analysis\\data\\raw\\ruth_reddit.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1d09d7",
   "metadata": {},
   "source": [
    "# Extracting data from news using News API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d34de72",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34b5863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Your API Key\n",
    "api_key = '4ee66544d2954e7facf1b04e48b55ee3' \n",
    "\n",
    "# Query Parameters\n",
    "query = 'USAID funding Kenya'\n",
    "url = f'https://newsapi.org/v2/everything?q={query}&language=en&sortBy=publishedAt&pageSize=100&apiKey={api_key}'\n",
    "\n",
    "# Make request\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "# Convert to DataFrame\n",
    "articles = data['articles']\n",
    "\n",
    "df_news = pd.DataFrame([{\n",
    "    'source': article['source']['name'],\n",
    "    'title': article['title'],\n",
    "    'description': article['description'],\n",
    "    'content': article['content'],\n",
    "    'url': article['url'],\n",
    "    'publishedAt': article['publishedAt']\n",
    "} for article in articles])\n",
    "\n",
    "# Show sample data\n",
    "df_news.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599e849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c0d696",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news.to_csv(r\"C:\\Users\\AHB\\Desktop\\my_quick_acess\\3.Projects\\projects pipeline\\2025\\USAID-Kenya-Sentiment-Analysis\\data\\raw\\ruth_news.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be21f03",
   "metadata": {},
   "source": [
    "# Extracting data from Twitter using Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f60341",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tweepy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6b9f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "# Replace with your actual Bearer Token\n",
    "bearer_token = \"AAAAAAAAAAAAAAAAAAAAAK4%2F2gEAAAAA1TH8z2qhYiK850CchE07JVIULK0%3Dr0WqcoK6o1lrW90sqbDhRtMlI32NkfurzPIr13Tte5nu3DziV1\"\n",
    "\n",
    "# Connect to Twitter API\n",
    "client = tweepy.Client(bearer_token=bearer_token)\n",
    "\n",
    "# Search tweets containing the word \"Kenya\"\n",
    "query = \"USAID funding kenya\"\n",
    "tweets = client.search_recent_tweets(query=query, max_results=10)\n",
    "\n",
    "# Print the tweets\n",
    "for tweet in tweets.data:\n",
    "    print(tweet.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff6f80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "tweet_data = []\n",
    "\n",
    "for tweet in tweets.data:\n",
    "    tweet_data.append({\n",
    "        \"id\": tweet.id,\n",
    "        \"text\": tweet.text,\n",
    "        \"created_at\": tweet.created_at  # may need to add 'tweet.fields' param to see this\n",
    "    })\n",
    "\n",
    "df_tweets = pd.DataFrame(tweet_data)\n",
    "\n",
    "# Now you can use .head()\n",
    "df_tweets.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b9367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tweets.to_csv(r\"C:\\Users\\AHB\\Desktop\\my_quick_acess\\3.Projects\\projects pipeline\\2025\\USAID-Kenya-Sentiment-Analysis\\data\\news_data.csv\")\n",
    "df_tweets.to_csv(r\"C:\\Users\\AHB\\Desktop\\my_quick_acess\\3.Projects\\projects pipeline\\2025\\USAID-Kenya-Sentiment-Analysis\\data\\raw\\ruth_tweets.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831fc338",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
