{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5a8d279",
   "metadata": {},
   "source": [
    "## Collecting Reddit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03654ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[...] Searching r/Kenya\n",
      "[...] Searching r/Africa\n",
      "[...] Searching r/worldnews\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>url</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USAID left a month ago, do we have ARVs in Kenya?</td>\n",
       "      <td>Someone on a different group (different websit...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>muerki</td>\n",
       "      <td>2025-04-15 13:16:53</td>\n",
       "      <td>https://www.reddit.com/r/Kenya/comments/1jzrn2...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>usaid kenya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Classism in r/Kenya and r/nairobi</td>\n",
       "      <td>The classism I'm seeing in both subs is a good...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Morio_anzenza</td>\n",
       "      <td>2025-04-07 04:21:12</td>\n",
       "      <td>https://www.reddit.com/r/Kenya/comments/1jtcvb...</td>\n",
       "      <td>169</td>\n",
       "      <td>95</td>\n",
       "      <td>usaid kenya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EX-USAID people!! Let's talk</td>\n",
       "      <td>Are you still in contact with the organisation...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>vindtar</td>\n",
       "      <td>2025-04-05 19:09:10</td>\n",
       "      <td>https://www.reddit.com/r/Kenya/comments/1jsb14...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>usaid kenya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why western powers back Israel no matter what ...</td>\n",
       "      <td>I don't care what good book you read, but it's...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Gold_Smart</td>\n",
       "      <td>2025-03-25 08:18:04</td>\n",
       "      <td>https://www.reddit.com/r/Kenya/comments/1jjehw...</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>usaid kenya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is kenya capable of funding its needs now that...</td>\n",
       "      <td>How is kenya prepared to fill the vacuum of US...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>westmaxia</td>\n",
       "      <td>2025-03-08 08:08:58</td>\n",
       "      <td>https://www.reddit.com/r/Kenya/comments/1j6cjz...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>usaid kenya</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  USAID left a month ago, do we have ARVs in Kenya?   \n",
       "1                  Classism in r/Kenya and r/nairobi   \n",
       "2                       EX-USAID people!! Let's talk   \n",
       "3  Why western powers back Israel no matter what ...   \n",
       "4  Is kenya capable of funding its needs now that...   \n",
       "\n",
       "                                            selftext subreddit         author  \\\n",
       "0  Someone on a different group (different websit...     Kenya         muerki   \n",
       "1  The classism I'm seeing in both subs is a good...     Kenya  Morio_anzenza   \n",
       "2  Are you still in contact with the organisation...     Kenya        vindtar   \n",
       "3  I don't care what good book you read, but it's...     Kenya     Gold_Smart   \n",
       "4  How is kenya prepared to fill the vacuum of US...     Kenya      westmaxia   \n",
       "\n",
       "           created_utc                                                url  \\\n",
       "0  2025-04-15 13:16:53  https://www.reddit.com/r/Kenya/comments/1jzrn2...   \n",
       "1  2025-04-07 04:21:12  https://www.reddit.com/r/Kenya/comments/1jtcvb...   \n",
       "2  2025-04-05 19:09:10  https://www.reddit.com/r/Kenya/comments/1jsb14...   \n",
       "3  2025-03-25 08:18:04  https://www.reddit.com/r/Kenya/comments/1jjehw...   \n",
       "4  2025-03-08 08:08:58  https://www.reddit.com/r/Kenya/comments/1j6cjz...   \n",
       "\n",
       "   score  num_comments      keyword  \n",
       "0      3             5  usaid kenya  \n",
       "1    169            95  usaid kenya  \n",
       "2      2             2  usaid kenya  \n",
       "3     13            20  usaid kenya  \n",
       "4      1             6  usaid kenya  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# Allow import from parent directory (where config.py is)\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "# Import credentials from config.py\n",
    "from config import REDDIT_CLIENT_ID, REDDIT_CLIENT_SECRET, REDDIT_USER_AGENT, YOUR_IDENTIFIER\n",
    "\n",
    "# Define keywords, subreddits, and date filter\n",
    "keywords = [\n",
    "    \"usaid kenya\", \"usaid funding\", \"usaid budget cut\", \"kenya foreign aid\",\n",
    "    \"usaid kenya funding cut\", \"usaid suspended funding\", \"development aid kenya\",\n",
    "    \"kenya donor funding\"\n",
    "]\n",
    "\n",
    "subreddits = [\"Kenya\", \"Africa\", \"worldnews\"]\n",
    "\n",
    "\n",
    "# Start date: Jan 20, 2025 (Trump announcement)\n",
    "start_date = int(datetime(2025, 1, 20).timestamp())\n",
    "\n",
    "# Authenticate with Reddit using PRAW\n",
    "reddit = praw.Reddit(\n",
    "    client_id=REDDIT_CLIENT_ID,\n",
    "    client_secret=REDDIT_CLIENT_SECRET,\n",
    "    user_agent=REDDIT_USER_AGENT\n",
    ")\n",
    "\n",
    "# Scrape submissions from selected subreddits and keywords\n",
    "posts = []\n",
    "\n",
    "for subreddit_name in subreddits:\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    print(f\"[...] Searching r/{subreddit_name}\")\n",
    "    for keyword in keywords:\n",
    "        for submission in subreddit.search(keyword, sort=\"new\", limit=100):\n",
    "            if submission.created_utc >= start_date:\n",
    "                posts.append({\n",
    "                    \"title\": submission.title,\n",
    "                    \"selftext\": submission.selftext,\n",
    "                    \"subreddit\": submission.subreddit.display_name,\n",
    "                    \"author\": str(submission.author),\n",
    "                    \"created_utc\": datetime.utcfromtimestamp(submission.created_utc).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                    \"url\": submission.url,\n",
    "                    \"score\": submission.score,\n",
    "                    \"num_comments\": submission.num_comments,\n",
    "                    \"keyword\": keyword\n",
    "                })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_reddit = pd.DataFrame(posts)\n",
    "\n",
    "# Save to CSV in raw data folder\n",
    "output_path = r\"C:\\Users\\user\\Desktop\\USAID-Kenya-Sentiment-Analysis\\USAID-Kenya-Sentiment-Analysis\\data\\raw\\Agatha_reddit.csv\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "df_reddit.to_csv(output_path, index=False)\n",
    "\n",
    "df_reddit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a27d876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(466, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reddit.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78c558c",
   "metadata": {},
   "source": [
    "## Data collection from NewsAPI.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2b465b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>source</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>content</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>usaid kenya</td>\n",
       "      <td>Al Jazeera English</td>\n",
       "      <td>Al Jazeera</td>\n",
       "      <td>Has DOGE really saved the US government $180bn?</td>\n",
       "      <td>Elon Musk first claimed the department would m...</td>\n",
       "      <td>President Donald Trump and adviser Elon Musk c...</td>\n",
       "      <td>2025-06-06T11:21:51Z</td>\n",
       "      <td>https://www.aljazeera.com/news/2025/6/6/has-do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>usaid kenya</td>\n",
       "      <td>CleanTechnica</td>\n",
       "      <td>Guest Contributor</td>\n",
       "      <td>The Life Story of Ecomobilus Technologies Limi...</td>\n",
       "      <td>By Prof Geoffrey Gitau Here is a story showcas...</td>\n",
       "      <td>By Prof Geoffrey Gitau\\r\\nHere is a story show...</td>\n",
       "      <td>2025-05-26T17:13:41Z</td>\n",
       "      <td>https://cleantechnica.com/2025/05/26/the-life-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>usaid kenya</td>\n",
       "      <td>ProPublica</td>\n",
       "      <td>by Brett Murphy and Anna Maria Barry-Jester</td>\n",
       "      <td>Death, Sexual Violence and Human Trafficking: ...</td>\n",
       "      <td>by Brett Murphy and Anna Maria Barry-Jester \\n...</td>\n",
       "      <td>ProPublica is a nonprofit newsroom that invest...</td>\n",
       "      <td>2025-05-28T18:45:00Z</td>\n",
       "      <td>https://www.propublica.org/article/trump-usaid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>usaid kenya</td>\n",
       "      <td>Daily Signal</td>\n",
       "      <td>Mike Gonzalez</td>\n",
       "      <td>Congress Should Quickly Approve Trump’s Rescis...</td>\n",
       "      <td>President Donald Trump‘s rescission legislatio...</td>\n",
       "      <td>President Donald Trumps rescission legislation...</td>\n",
       "      <td>2025-06-10T12:00:00Z</td>\n",
       "      <td>https://www.dailysignal.com/2025/06/10/congres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>usaid kenya</td>\n",
       "      <td>Forbes</td>\n",
       "      <td>Danielle Nierenberg, Contributor, \\n Danielle ...</td>\n",
       "      <td>Food Safety Depends On Every Link In The Suppl...</td>\n",
       "      <td>Almost 1 in 10 people globally fall ill from c...</td>\n",
       "      <td>Colorful fish and vegetables can be purchased ...</td>\n",
       "      <td>2025-06-06T13:55:41Z</td>\n",
       "      <td>https://www.forbes.com/sites/daniellenierenber...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       keyword              source  \\\n",
       "0  usaid kenya  Al Jazeera English   \n",
       "1  usaid kenya       CleanTechnica   \n",
       "2  usaid kenya          ProPublica   \n",
       "3  usaid kenya        Daily Signal   \n",
       "4  usaid kenya              Forbes   \n",
       "\n",
       "                                              author  \\\n",
       "0                                         Al Jazeera   \n",
       "1                                  Guest Contributor   \n",
       "2        by Brett Murphy and Anna Maria Barry-Jester   \n",
       "3                                      Mike Gonzalez   \n",
       "4  Danielle Nierenberg, Contributor, \\n Danielle ...   \n",
       "\n",
       "                                               title  \\\n",
       "0    Has DOGE really saved the US government $180bn?   \n",
       "1  The Life Story of Ecomobilus Technologies Limi...   \n",
       "2  Death, Sexual Violence and Human Trafficking: ...   \n",
       "3  Congress Should Quickly Approve Trump’s Rescis...   \n",
       "4  Food Safety Depends On Every Link In The Suppl...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Elon Musk first claimed the department would m...   \n",
       "1  By Prof Geoffrey Gitau Here is a story showcas...   \n",
       "2  by Brett Murphy and Anna Maria Barry-Jester \\n...   \n",
       "3  President Donald Trump‘s rescission legislatio...   \n",
       "4  Almost 1 in 10 people globally fall ill from c...   \n",
       "\n",
       "                                             content           publishedAt  \\\n",
       "0  President Donald Trump and adviser Elon Musk c...  2025-06-06T11:21:51Z   \n",
       "1  By Prof Geoffrey Gitau\\r\\nHere is a story show...  2025-05-26T17:13:41Z   \n",
       "2  ProPublica is a nonprofit newsroom that invest...  2025-05-28T18:45:00Z   \n",
       "3  President Donald Trumps rescission legislation...  2025-06-10T12:00:00Z   \n",
       "4  Colorful fish and vegetables can be purchased ...  2025-06-06T13:55:41Z   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.aljazeera.com/news/2025/6/6/has-do...  \n",
       "1  https://cleantechnica.com/2025/05/26/the-life-...  \n",
       "2  https://www.propublica.org/article/trump-usaid...  \n",
       "3  https://www.dailysignal.com/2025/06/10/congres...  \n",
       "4  https://www.forbes.com/sites/daniellenierenber...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "# Allow import from parent directory (to access config.py)\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "# Import credentials\n",
    "from config import NEWS_API_KEY, YOUR_IDENTIFIER\n",
    "\n",
    "# Keywords (relevant to USAID and Kenya)\n",
    "keywords = [\n",
    "    \"usaid kenya\",\n",
    "    \"usaid funding\",\n",
    "    \"usaid budget cut\",\n",
    "    \"kenya foreign aid\",\n",
    "    \"usaid suspended funding\",\n",
    "    \"development aid kenya\",\n",
    "    \"kenya donor funding\",\n",
    "    \"foreign aid cut\",\n",
    "    \"foreign aid withdrawal\",\n",
    "    \"us foreign aid kenya\",\n",
    "    \"funding reduction kenya\"\n",
    "]\n",
    "\n",
    "#Time window: last 30 days (NewsAPI free tier limit)\n",
    "END_DATE = datetime.now(timezone.utc)\n",
    "START_DATE = END_DATE - timedelta(days=30)\n",
    "\n",
    "from_date = START_DATE.strftime('%Y-%m-%d')\n",
    "to_date = END_DATE.strftime('%Y-%m-%d')\n",
    "\n",
    "# NewsAPI endpoint\n",
    "url = \"https://newsapi.org/v2/everything\"\n",
    "\n",
    "# List to hold articles\n",
    "articles = []\n",
    "\n",
    "# Loop over each keyword and collect articles\n",
    "for keyword in keywords:\n",
    "    params = {\n",
    "        'q': keyword,\n",
    "        'from': from_date,\n",
    "        'to': to_date,\n",
    "        'language': 'en',\n",
    "        'sortBy': 'relevancy',\n",
    "        'pageSize': 100,  # Max per request\n",
    "        'apiKey': NEWS_API_KEY,\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        for article in data.get('articles', []):\n",
    "            articles.append({\n",
    "                \"keyword\": keyword,\n",
    "                \"source\": article[\"source\"][\"name\"],\n",
    "                \"author\": article[\"author\"],\n",
    "                \"title\": article[\"title\"],\n",
    "                \"description\": article[\"description\"],\n",
    "                \"content\": article[\"content\"],\n",
    "                \"publishedAt\": article[\"publishedAt\"],\n",
    "                \"url\": article[\"url\"]\n",
    "            })\n",
    "    else:\n",
    "        print(f\"[ERROR] Failed to fetch articles for '{keyword}' (status code: {response.status_code})\")\n",
    "\n",
    "# Convert list of articles to DataFrame\n",
    "df_news = pd.DataFrame(articles)\n",
    "\n",
    "# Save to CSV\n",
    "output_path = r\"C:\\Users\\user\\Desktop\\USAID-Kenya-Sentiment-Analysis\\USAID-Kenya-Sentiment-Analysis\\data\\raw\\Agatha_news.csv\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "df_news.to_csv(output_path, index=False)\n",
    "\n",
    "df_news.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56f0049e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(592, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
