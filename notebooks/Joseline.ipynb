{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d118fa4",
   "metadata": {},
   "source": [
    "# **USAID FUNDING SENTIMENTAL ANALYSIS**\n",
    "\n",
    "### **INTRODUCTION**\n",
    "\n",
    "The United States Agency for International Development (USAID) plays a pivotal role in supporting global development through strategic funding initiatives. In recent years, discussions around the withdrawal or reduction of USAID funding have sparked significant public response — both within the United States and in countries that have long relied on this aid.\n",
    "\n",
    "This project seeks to analyze the public sentiment surrounding USAID funding, particularly in relation to controversial political decisions or policy shifts. By leveraging social media data, news articles, and other textual sources, we aim to uncover how these funding changes are perceived by various stakeholders — including American citizens, government officials, development workers, and beneficiaries in aid-receiving countries such as Kenya.\n",
    "\n",
    "Through natural language processing (NLP) techniques, we perform sentiment classification and thematic analysis to better understand the emotional tone, concerns, and priorities reflected in public discourse. The findings from this analysis can offer valuable insights into the social and geopolitical implications of foreign aid decisions and their real-world human impact.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2c682a",
   "metadata": {},
   "source": [
    "### **PROBLEM STATEMENT**\n",
    "\n",
    "In recent years, shifts in U.S. foreign aid policy—particularly under different presidential administrations—have sparked varying public reactions, especially regarding USAID’s role in Kenya and across Africa. While news media and online communities like Reddit reflect public sentiment on these changes, there is limited structured analysis of how people perceive USAID's presence, impact, and funding shifts over time.\n",
    "\n",
    "This lack of insight poses a challenge for stakeholders (e.g., policymakers, development partners, NGOs) who need to understand community perceptions to align strategies, counter misinformation, and strengthen trust. There is, therefore, a need to systematically analyze and compare public sentiment toward USAID across social media and mainstream news platforms.\n",
    "\n",
    "---\n",
    "\n",
    "### **OJECTIVES**\n",
    "\n",
    "1. **Conduct sentiment analysis** using tools like VADER, TextBlob, or spaCy to classify posts and articles as positive, neutral, or negative.\n",
    "\n",
    "2. **Compare sentiment trends** across Reddit and news platforms to identify spikes, policy-driven reactions, or framing differences over time.\n",
    "\n",
    "3. **Visualize and report insights** using graphs, word clouds, and dashboards that highlight the tone and evolution of public opinion on USAID in Kenya.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696ca8d0",
   "metadata": {},
   "source": [
    " ## **DATA LOADING AND INSPECTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78f89626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>created_date</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>keyword</th>\n",
       "      <th>search_term</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>comments</th>\n",
       "      <th>url</th>\n",
       "      <th>permalink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USAID left a month ago, do we have ARVs in Kenya?</td>\n",
       "      <td>Someone on a different group (different websit...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>muerki</td>\n",
       "      <td>2025-04-15 13:16:53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>usaid kenya</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/Kenya/comments/1jzrn2...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Classism in r/Kenya and r/nairobi</td>\n",
       "      <td>The classism I'm seeing in both subs is a good...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Morio_anzenza</td>\n",
       "      <td>2025-04-07 04:21:12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>169.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>usaid kenya</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/Kenya/comments/1jtcvb...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EX-USAID people!! Let's talk</td>\n",
       "      <td>Are you still in contact with the organisation...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>vindtar</td>\n",
       "      <td>2025-04-05 19:09:10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>usaid kenya</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/Kenya/comments/1jsb14...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why western powers back Israel no matter what ...</td>\n",
       "      <td>I don't care what good book you read, but it's...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Gold_Smart</td>\n",
       "      <td>2025-03-25 08:18:04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>usaid kenya</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/Kenya/comments/1jjehw...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is kenya capable of funding its needs now that...</td>\n",
       "      <td>How is kenya prepared to fill the vacuum of US...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>westmaxia</td>\n",
       "      <td>2025-03-08 08:08:58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>usaid kenya</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/Kenya/comments/1j6cjz...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  USAID left a month ago, do we have ARVs in Kenya?   \n",
       "1                  Classism in r/Kenya and r/nairobi   \n",
       "2                       EX-USAID people!! Let's talk   \n",
       "3  Why western powers back Israel no matter what ...   \n",
       "4  Is kenya capable of funding its needs now that...   \n",
       "\n",
       "                                            selftext subreddit         author  \\\n",
       "0  Someone on a different group (different websit...     Kenya         muerki   \n",
       "1  The classism I'm seeing in both subs is a good...     Kenya  Morio_anzenza   \n",
       "2  Are you still in contact with the organisation...     Kenya        vindtar   \n",
       "3  I don't care what good book you read, but it's...     Kenya     Gold_Smart   \n",
       "4  How is kenya prepared to fill the vacuum of US...     Kenya      westmaxia   \n",
       "\n",
       "           created_utc created_date  score  num_comments      keyword  \\\n",
       "0  2025-04-15 13:16:53          NaN    3.0           5.0  usaid kenya   \n",
       "1  2025-04-07 04:21:12          NaN  169.0          95.0  usaid kenya   \n",
       "2  2025-04-05 19:09:10          NaN    2.0           2.0  usaid kenya   \n",
       "3  2025-03-25 08:18:04          NaN   13.0          20.0  usaid kenya   \n",
       "4  2025-03-08 08:08:58          NaN    1.0           6.0  usaid kenya   \n",
       "\n",
       "  search_term date_posted  upvotes  comments  \\\n",
       "0         NaN         NaN      NaN       NaN   \n",
       "1         NaN         NaN      NaN       NaN   \n",
       "2         NaN         NaN      NaN       NaN   \n",
       "3         NaN         NaN      NaN       NaN   \n",
       "4         NaN         NaN      NaN       NaN   \n",
       "\n",
       "                                                 url permalink  \n",
       "0  https://www.reddit.com/r/Kenya/comments/1jzrn2...       NaN  \n",
       "1  https://www.reddit.com/r/Kenya/comments/1jtcvb...       NaN  \n",
       "2  https://www.reddit.com/r/Kenya/comments/1jsb14...       NaN  \n",
       "3  https://www.reddit.com/r/Kenya/comments/1jjehw...       NaN  \n",
       "4  https://www.reddit.com/r/Kenya/comments/1j6cjz...       NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load the dataset\n",
    "\n",
    "df1 = pd.read_csv(r\"C:\\Users\\Admin\\OneDrive\\Documents\\USAID-Kenya-Sentiment-Analysis\\data\\processed\\reddit_data\\reddit_data.csv\", encoding='utf-8')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f69cbe4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>keyword</th>\n",
       "      <th>published_date</th>\n",
       "      <th>source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Has DOGE really saved the US government $180bn?</td>\n",
       "      <td>Elon Musk first claimed the department would m...</td>\n",
       "      <td>President Donald Trump and adviser Elon Musk c...</td>\n",
       "      <td>https://www.aljazeera.com/news/2025/6/6/has-do...</td>\n",
       "      <td>usaid kenya</td>\n",
       "      <td>2025-06-06</td>\n",
       "      <td>Agatha_news.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Life Story of Ecomobilus Technologies Limi...</td>\n",
       "      <td>By Prof Geoffrey Gitau Here is a story showcas...</td>\n",
       "      <td>By Prof Geoffrey Gitau\\r\\nHere is a story show...</td>\n",
       "      <td>https://cleantechnica.com/2025/05/26/the-life-...</td>\n",
       "      <td>usaid kenya</td>\n",
       "      <td>2025-05-26</td>\n",
       "      <td>Agatha_news.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Death, Sexual Violence and Human Trafficking: ...</td>\n",
       "      <td>by Brett Murphy and Anna Maria Barry-Jester \\n...</td>\n",
       "      <td>ProPublica is a nonprofit newsroom that invest...</td>\n",
       "      <td>https://www.propublica.org/article/trump-usaid...</td>\n",
       "      <td>usaid kenya</td>\n",
       "      <td>2025-05-28</td>\n",
       "      <td>Agatha_news.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Congress Should Quickly Approve Trump’s Rescis...</td>\n",
       "      <td>President Donald Trump‘s rescission legislatio...</td>\n",
       "      <td>President Donald Trumps rescission legislation...</td>\n",
       "      <td>https://www.dailysignal.com/2025/06/10/congres...</td>\n",
       "      <td>usaid kenya</td>\n",
       "      <td>2025-06-10</td>\n",
       "      <td>Agatha_news.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Food Safety Depends On Every Link In The Suppl...</td>\n",
       "      <td>Almost 1 in 10 people globally fall ill from c...</td>\n",
       "      <td>Colorful fish and vegetables can be purchased ...</td>\n",
       "      <td>https://www.forbes.com/sites/daniellenierenber...</td>\n",
       "      <td>usaid kenya</td>\n",
       "      <td>2025-06-06</td>\n",
       "      <td>Agatha_news.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0    Has DOGE really saved the US government $180bn?   \n",
       "1  The Life Story of Ecomobilus Technologies Limi...   \n",
       "2  Death, Sexual Violence and Human Trafficking: ...   \n",
       "3  Congress Should Quickly Approve Trump’s Rescis...   \n",
       "4  Food Safety Depends On Every Link In The Suppl...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Elon Musk first claimed the department would m...   \n",
       "1  By Prof Geoffrey Gitau Here is a story showcas...   \n",
       "2  by Brett Murphy and Anna Maria Barry-Jester \\n...   \n",
       "3  President Donald Trump‘s rescission legislatio...   \n",
       "4  Almost 1 in 10 people globally fall ill from c...   \n",
       "\n",
       "                                                text  \\\n",
       "0  President Donald Trump and adviser Elon Musk c...   \n",
       "1  By Prof Geoffrey Gitau\\r\\nHere is a story show...   \n",
       "2  ProPublica is a nonprofit newsroom that invest...   \n",
       "3  President Donald Trumps rescission legislation...   \n",
       "4  Colorful fish and vegetables can be purchased ...   \n",
       "\n",
       "                                                 url      keyword  \\\n",
       "0  https://www.aljazeera.com/news/2025/6/6/has-do...  usaid kenya   \n",
       "1  https://cleantechnica.com/2025/05/26/the-life-...  usaid kenya   \n",
       "2  https://www.propublica.org/article/trump-usaid...  usaid kenya   \n",
       "3  https://www.dailysignal.com/2025/06/10/congres...  usaid kenya   \n",
       "4  https://www.forbes.com/sites/daniellenierenber...  usaid kenya   \n",
       "\n",
       "  published_date      source_file  \n",
       "0     2025-06-06  Agatha_news.csv  \n",
       "1     2025-05-26  Agatha_news.csv  \n",
       "2     2025-05-28  Agatha_news.csv  \n",
       "3     2025-06-10  Agatha_news.csv  \n",
       "4     2025-06-06  Agatha_news.csv  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(r\"C:\\Users\\Admin\\OneDrive\\Documents\\USAID-Kenya-Sentiment-Analysis\\data\\processed\\news_data\\news_data.csv\", encoding='utf-8')\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f821c818",
   "metadata": {},
   "source": [
    "## **DATA CLEANING**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6b4c68",
   "metadata": {},
   "source": [
    "**Basic overview of the two data sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36b9fec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit Data Shape: (1289, 15)\n",
      "Reddit Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1289 entries, 0 to 1288\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   title         1289 non-null   object \n",
      " 1   selftext      901 non-null    object \n",
      " 2   subreddit     1289 non-null   object \n",
      " 3   author        466 non-null    object \n",
      " 4   created_utc   1013 non-null   object \n",
      " 5   created_date  150 non-null    object \n",
      " 6   score         1013 non-null   float64\n",
      " 7   num_comments  833 non-null    float64\n",
      " 8   keyword       742 non-null    object \n",
      " 9   search_term   150 non-null    object \n",
      " 10  date_posted   276 non-null    object \n",
      " 11  upvotes       276 non-null    float64\n",
      " 12  comments      276 non-null    float64\n",
      " 13  url           1289 non-null   object \n",
      " 14  permalink     426 non-null    object \n",
      "dtypes: float64(4), object(11)\n",
      "memory usage: 151.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Shape and general info of the datasets separately\n",
    "print(\"Reddit Data Shape:\", df1.shape)\n",
    "print(\"Reddit Data Info:\")\n",
    "print(df1.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf05ceea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "News Data Shape: (2549, 7)\n",
      "News Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2549 entries, 0 to 2548\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   title           2549 non-null   object\n",
      " 1   description     2533 non-null   object\n",
      " 2   text            2524 non-null   object\n",
      " 3   url             2547 non-null   object\n",
      " 4   keyword         2379 non-null   object\n",
      " 5   published_date  2450 non-null   object\n",
      " 6   source_file     2549 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 139.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNews Data Shape:\", df2.shape)\n",
    "print(\"News Data Info:\")    \n",
    "print(df2.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f3d4ee",
   "metadata": {},
   "source": [
    "### **Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48a4ebf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values in Reddit Data:\n",
      "selftext         388\n",
      "author           823\n",
      "created_utc      276\n",
      "created_date    1139\n",
      "score            276\n",
      "num_comments     456\n",
      "keyword          547\n",
      "search_term     1139\n",
      "date_posted     1013\n",
      "upvotes         1013\n",
      "comments        1013\n",
      "permalink        863\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#missing vakues for the reddit data\n",
    "missing_values_reddit = df1.isnull().sum()\n",
    "print(\"\\nMissing Values in Reddit Data:\")\n",
    "print(missing_values_reddit[missing_values_reddit > 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6593e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Duplicate Rows in Reddit Data: 25\n"
     ]
    }
   ],
   "source": [
    "#Checking for duplicate rows in the Reddit data\n",
    "duplicate_rows_reddit = df1.duplicated().sum()\n",
    "print(\"\\nDuplicate Rows in Reddit Data:\", duplicate_rows_reddit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9130cdb",
   "metadata": {},
   "source": [
    "**News Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46d9df19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values in News Data:\n",
      "description        16\n",
      "text               25\n",
      "url                 2\n",
      "keyword           170\n",
      "published_date     99\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Now let us check the missing values for the news data\n",
    "missing_values_news = df2.isnull().sum()\n",
    "print(\"\\nMissing Values in News Data:\")\n",
    "print(missing_values_news[missing_values_news > 0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d9f35fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Duplicate Rows in News Data: 98\n"
     ]
    }
   ],
   "source": [
    "#Check for duplicate rows in the news data\n",
    "duplicate_rows_news = df2.duplicated().sum()\n",
    "print(\"\\nDuplicate Rows in News Data:\", duplicate_rows_news)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c72056",
   "metadata": {},
   "source": [
    "**Removing duplicates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0338c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after removing duplicates: (1264, 15)\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicate rows\n",
    "df1_cleaned = df1.drop_duplicates()\n",
    "\n",
    "# Check new shape\n",
    "print(\"Shape after removing duplicates:\", df1_cleaned.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f37d41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after removing duplicates: (2451, 7)\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicate rows\n",
    "df2_cleaned = df2.drop_duplicates()\n",
    "\n",
    "# Check new shape\n",
    "print(\"Shape after removing duplicates:\", df2_cleaned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03a42f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Shape after full cleaning: (609, 15)\n",
      "title           0\n",
      "selftext        0\n",
      "subreddit       0\n",
      "author          0\n",
      "created_utc     0\n",
      "created_date    0\n",
      "score           0\n",
      "num_comments    0\n",
      "keyword         0\n",
      "search_term     0\n",
      "date_posted     0\n",
      "upvotes         0\n",
      "comments        0\n",
      "url             0\n",
      "permalink       0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-2b6ed6f711df>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1_cleaned['created_utc'] = pd.to_datetime(df1_cleaned['created_utc'], errors='coerce')\n",
      "<ipython-input-26-2b6ed6f711df>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1_cleaned['created_date'] = df1_cleaned['created_utc'].dt.date\n",
      "<ipython-input-26-2b6ed6f711df>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1_cleaned['date_posted'] = df1_cleaned['created_date']\n",
      "<ipython-input-26-2b6ed6f711df>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1_cleaned.dropna(subset=['created_utc'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Regenerate created_date and date_posted if created_utc is available\n",
    "df1_cleaned['created_utc'] = pd.to_datetime(df1_cleaned['created_utc'], errors='coerce')\n",
    "df1_cleaned['created_date'] = df1_cleaned['created_utc'].dt.date\n",
    "df1_cleaned['date_posted'] = df1_cleaned['created_date']\n",
    "\n",
    "# Fill missing values\n",
    "df1_cleaned['keyword'].fillna('Unknown', inplace=True)\n",
    "df1_cleaned['search_term'].fillna('Unknown', inplace=True)\n",
    "df1_cleaned['upvotes'].fillna(0, inplace=True)\n",
    "df1_cleaned['comments'].fillna('', inplace=True)\n",
    "df1_cleaned['permalink'].fillna('', inplace=True)\n",
    "\n",
    "# Drop rows where created_utc is still missing\n",
    "df1_cleaned.dropna(subset=['created_utc'], inplace=True)\n",
    "\n",
    "# Final check\n",
    "print(\"✅ Shape after full cleaning:\", df1_cleaned.shape)\n",
    "print(df1_cleaned.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95819640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>created_date</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>keyword</th>\n",
       "      <th>search_term</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>comments</th>\n",
       "      <th>url</th>\n",
       "      <th>permalink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USAID left a month ago, do we have ARVs in Kenya?</td>\n",
       "      <td>Someone on a different group (different websit...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>muerki</td>\n",
       "      <td>2025-04-15 13:16:53</td>\n",
       "      <td>2025-04-15</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>usaid kenya</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2025-04-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>https://www.reddit.com/r/Kenya/comments/1jzrn2...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Classism in r/Kenya and r/nairobi</td>\n",
       "      <td>The classism I'm seeing in both subs is a good...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Morio_anzenza</td>\n",
       "      <td>2025-04-07 04:21:12</td>\n",
       "      <td>2025-04-07</td>\n",
       "      <td>169.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>usaid kenya</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2025-04-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>https://www.reddit.com/r/Kenya/comments/1jtcvb...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EX-USAID people!! Let's talk</td>\n",
       "      <td>Are you still in contact with the organisation...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>vindtar</td>\n",
       "      <td>2025-04-05 19:09:10</td>\n",
       "      <td>2025-04-05</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>usaid kenya</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2025-04-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>https://www.reddit.com/r/Kenya/comments/1jsb14...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why western powers back Israel no matter what ...</td>\n",
       "      <td>I don't care what good book you read, but it's...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Gold_Smart</td>\n",
       "      <td>2025-03-25 08:18:04</td>\n",
       "      <td>2025-03-25</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>usaid kenya</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2025-03-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>https://www.reddit.com/r/Kenya/comments/1jjehw...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is kenya capable of funding its needs now that...</td>\n",
       "      <td>How is kenya prepared to fill the vacuum of US...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>westmaxia</td>\n",
       "      <td>2025-03-08 08:08:58</td>\n",
       "      <td>2025-03-08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>usaid kenya</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2025-03-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>https://www.reddit.com/r/Kenya/comments/1j6cjz...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  USAID left a month ago, do we have ARVs in Kenya?   \n",
       "1                  Classism in r/Kenya and r/nairobi   \n",
       "2                       EX-USAID people!! Let's talk   \n",
       "3  Why western powers back Israel no matter what ...   \n",
       "4  Is kenya capable of funding its needs now that...   \n",
       "\n",
       "                                            selftext subreddit         author  \\\n",
       "0  Someone on a different group (different websit...     Kenya         muerki   \n",
       "1  The classism I'm seeing in both subs is a good...     Kenya  Morio_anzenza   \n",
       "2  Are you still in contact with the organisation...     Kenya        vindtar   \n",
       "3  I don't care what good book you read, but it's...     Kenya     Gold_Smart   \n",
       "4  How is kenya prepared to fill the vacuum of US...     Kenya      westmaxia   \n",
       "\n",
       "          created_utc created_date  score  num_comments      keyword  \\\n",
       "0 2025-04-15 13:16:53   2025-04-15    3.0           5.0  usaid kenya   \n",
       "1 2025-04-07 04:21:12   2025-04-07  169.0          95.0  usaid kenya   \n",
       "2 2025-04-05 19:09:10   2025-04-05    2.0           2.0  usaid kenya   \n",
       "3 2025-03-25 08:18:04   2025-03-25   13.0          20.0  usaid kenya   \n",
       "4 2025-03-08 08:08:58   2025-03-08    1.0           6.0  usaid kenya   \n",
       "\n",
       "  search_term date_posted  upvotes comments  \\\n",
       "0     Unknown  2025-04-15      0.0            \n",
       "1     Unknown  2025-04-07      0.0            \n",
       "2     Unknown  2025-04-05      0.0            \n",
       "3     Unknown  2025-03-25      0.0            \n",
       "4     Unknown  2025-03-08      0.0            \n",
       "\n",
       "                                                 url permalink  \n",
       "0  https://www.reddit.com/r/Kenya/comments/1jzrn2...            \n",
       "1  https://www.reddit.com/r/Kenya/comments/1jtcvb...            \n",
       "2  https://www.reddit.com/r/Kenya/comments/1jsb14...            \n",
       "3  https://www.reddit.com/r/Kenya/comments/1jjehw...            \n",
       "4  https://www.reddit.com/r/Kenya/comments/1j6cjz...            "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d03a7684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned News Data Shape: (2328, 7)\n",
      "\n",
      "Remaining Missing Values in News Data:\n",
      " title              0\n",
      "description       15\n",
      "text               0\n",
      "url                0\n",
      "keyword           47\n",
      "published_date     0\n",
      "source_file        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with missing 'text' or 'published_date'\n",
    "df2_cleaned = df2.dropna(subset=['text', 'published_date']).copy()\n",
    "\n",
    "# Convert 'published_date' to datetime\n",
    "df2_cleaned['published_date'] = pd.to_datetime(df2_cleaned['published_date'], errors='coerce')\n",
    "\n",
    "# Drop any remaining rows where conversion failed (if any)\n",
    "df2_cleaned = df2_cleaned.dropna(subset=['published_date'])\n",
    "\n",
    "# Drop duplicates\n",
    "df2_cleaned = df2_cleaned.drop_duplicates()\n",
    "\n",
    "# Reset index\n",
    "df2_cleaned.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Check final shape and missing values\n",
    "print(\"Cleaned News Data Shape:\", df2_cleaned.shape)\n",
    "print(\"\\nRemaining Missing Values in News Data:\\n\", df2_cleaned.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1dd086fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Remaining Missing Values After Replacement:\n",
      "title             0\n",
      "description       0\n",
      "text              0\n",
      "url               0\n",
      "keyword           0\n",
      "published_date    0\n",
      "source_file       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Replace missing values with \"Unknown\"\n",
    "df2_cleaned['description'] = df2_cleaned['description'].fillna(\"Unknown\")\n",
    "df2_cleaned['keyword'] = df2_cleaned['keyword'].fillna(\"Unknown\")\n",
    "\n",
    "# Confirm there are no missing values left\n",
    "print(\"\\nRemaining Missing Values After Replacement:\")\n",
    "print(df2_cleaned.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b57ac4",
   "metadata": {},
   "source": [
    "### **Combining the datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06319016",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
