{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69f35898",
   "metadata": {},
   "source": [
    "### USAUD FUNDING CUTS SENTIMENT ANALYSIS "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b33964",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b68823a",
   "metadata": {},
   "source": [
    ".....(light intro text)\n",
    ".....(TBD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b15690d",
   "metadata": {},
   "source": [
    "### Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b0c730",
   "metadata": {},
   "source": [
    "This is data preparation phase for the project. The dataset used here is compiled from two primary sources: Reddit (via web scraping) and NewsAPI (via API calls). Each contributor collected data independently from these platforms, targeting relevant topics for analysis. Below, we begin by importing the collected datasets, merging them, and performing initial cleaning steps to prepare the data for further exploration and modeling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c78cbe",
   "metadata": {},
   "source": [
    "#### Data Importation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd92f453",
   "metadata": {},
   "source": [
    "##### news_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5fbe550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in Agatha_news.csv:\n",
      "['keyword', 'source', 'author', 'title', 'description', 'content', 'publishedAt', 'url']\n",
      "--------------------------------------------------\n",
      "Columns in cecilia.newsapi.csv:\n",
      "['keyword', 'source', 'title', 'description', 'url', 'publishedAt']\n",
      "--------------------------------------------------\n",
      "Columns in gnews_usaid_kenya_full.csv:\n",
      "['title', 'url', 'published_date', 'source', 'text']\n",
      "--------------------------------------------------\n",
      "Columns in gnews_usaid_kenya_full_en_sw.csv:\n",
      "['title', 'url', 'published_date', 'source', 'language', 'text']\n",
      "--------------------------------------------------\n",
      "Columns in leo_newsapi_articles.csv:\n",
      "['source', 'author', 'title', 'description', 'content', 'url', 'published_at']\n",
      "--------------------------------------------------\n",
      "Columns in leo_newsapi_articles_enriched.csv:\n",
      "['source', 'author', 'title', 'description', 'content', 'url', 'published_at', 'full_text']\n",
      "--------------------------------------------------\n",
      "Columns in Mbego_news_usaid_kenya_fulltext.csv:\n",
      "['source', 'author', 'title', 'description', 'url', 'publishedAt', 'summary', 'full_text']\n",
      "--------------------------------------------------\n",
      "Columns in Mbego_news_usaid_kenya_recent.csv:\n",
      "['source', 'author', 'title', 'description', 'url', 'publishedAt', 'content']\n",
      "--------------------------------------------------\n",
      "Columns in ruth_news.csv:\n",
      "['Unnamed: 0', 'source', 'title', 'description', 'content', 'url', 'publishedAt']\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Set the path to your news_data folder\n",
    "folder_path = r'N:\\Moringa\\afterM\\Leo NLP 004 USAID 01.06.2025\\USAID-Kenya-Sentiment-Analysis\\data\\raw\\news_data'\n",
    "\n",
    "# List all CSV files in the folder\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# Read and display columns for each CSV file\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, nrows=0)  # Read only headers\n",
    "        print(f\"Columns in {file}:\")\n",
    "        print(list(df.columns))\n",
    "        print(\"-\" * 50)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43cccdc",
   "metadata": {},
   "source": [
    "##### reddit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c6b954b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in Agatha_reddit.csv:\n",
      "['title', 'selftext', 'subreddit', 'author', 'created_utc', 'url', 'score', 'num_comments', 'keyword']\n",
      "--------------------------------------------------\n",
      "Columns in cecilia.redditsubs.csv:\n",
      "['subreddit', 'keyword', 'title', 'text', 'date_posted', 'upvotes', 'comments', 'url', 'permalink']\n",
      "--------------------------------------------------\n",
      "Columns in cecilia.reddit_nbo_ke_africa.csv:\n",
      "['subreddit', 'keyword', 'title', 'text', 'date_posted', 'upvotes', 'comments', 'url', 'permalink']\n",
      "--------------------------------------------------\n",
      "Columns in leo_reddit_posts.csv:\n",
      "['subreddit', 'search_term', 'title', 'text', 'created_utc', 'created_date', 'score', 'num_comments', 'permalink', 'url']\n",
      "--------------------------------------------------\n",
      "Columns in Mbego_reddit_usaid_kenya.csv:\n",
      "['title', 'score', 'url', 'created', 'subreddit', 'selftext']\n",
      "--------------------------------------------------\n",
      "Columns in Mbego_reddit_usaid_kenya2.csv:\n",
      "['title', 'score', 'url', 'created', 'subreddit', 'selftext']\n",
      "--------------------------------------------------\n",
      "Columns in reddit_usaid_sentiment.csv:\n",
      "['subreddit', 'title', 'score', 'url', 'created_utc', 'num_comments', 'selftext']\n",
      "--------------------------------------------------\n",
      "Columns in ruth_reddit.csv:\n",
      "['Unnamed: 0', 'subreddit', 'title', 'score', 'url', 'created_utc', 'num_comments', 'selftext']\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Set the path to your news_data folder\n",
    "folder_path = r'N:\\Moringa\\afterM\\Leo NLP 004 USAID 01.06.2025\\USAID-Kenya-Sentiment-Analysis\\data\\raw\\reddit_data'\n",
    "\n",
    "# List all CSV files in the folder\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# Read and display columns for each CSV file\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, nrows=0)  # Read only headers\n",
    "        print(f\"Columns in {file}:\")\n",
    "        print(list(df.columns))\n",
    "        print(\"-\" * 50)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f22927d",
   "metadata": {},
   "source": [
    "#### Data Merging "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9da281b",
   "metadata": {},
   "source": [
    "##### news_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6702b9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged: Agatha_news.csv\n",
      "✅ Merged: cecilia.newsapi.csv\n",
      "✅ Merged: gnews_usaid_kenya_full.csv\n",
      "✅ Merged: gnews_usaid_kenya_full_en_sw.csv\n",
      "✅ Merged: leo_newsapi_articles.csv\n",
      "✅ Merged: leo_newsapi_articles_enriched.csv\n",
      "✅ Merged: Mbego_news_usaid_kenya_fulltext.csv\n",
      "✅ Merged: Mbego_news_usaid_kenya_recent.csv\n",
      "✅ Merged: ruth_news.csv\n",
      "\n",
      "✅ All News files merged and saved to 'N:\\Moringa\\afterM\\Leo NLP 004 USAID 01.06.2025\\USAID-Kenya-Sentiment-Analysis\\data\\processed\\Mbego_all_news_merged.csv'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Folder containing all News CSVs\n",
    "folder_path = r'N:\\Moringa\\afterM\\Leo NLP 004 USAID 01.06.2025\\USAID-Kenya-Sentiment-Analysis\\data\\raw\\news_data'\n",
    "\n",
    "# Final save location\n",
    "save_path = r\"N:\\Moringa\\afterM\\Leo NLP 004 USAID 01.06.2025\\USAID-Kenya-Sentiment-Analysis\\data\\processed\"\n",
    "\n",
    "# All .csv files in the news_data folder\n",
    "news_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# Define the final standardized columns\n",
    "standard_news_cols = [\n",
    "    'keyword', 'source', 'author', 'title', 'description', 'content',\n",
    "    'summary', 'full_text', 'publishedAt', 'url', 'language'\n",
    "]\n",
    "\n",
    "# Create empty master DataFrame\n",
    "merged_news_df = pd.DataFrame(columns=standard_news_cols)\n",
    "\n",
    "# Loop through each file\n",
    "for file in news_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Drop index column if present\n",
    "        if 'Unnamed: 0' in df.columns:\n",
    "            df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "        # Standardize column names\n",
    "        df.rename(columns={\n",
    "            'published_at': 'publishedAt',\n",
    "            'published_date': 'publishedAt',\n",
    "            'text': 'content'\n",
    "        }, inplace=True)\n",
    "\n",
    "        # Add missing columns\n",
    "        for col in standard_news_cols:\n",
    "            if col not in df.columns:\n",
    "                df[col] = pd.NA\n",
    "\n",
    "        # Align column order\n",
    "        df = df[standard_news_cols]\n",
    "\n",
    "        # Add to master DataFrame\n",
    "        merged_news_df = pd.concat([merged_news_df, df], ignore_index=True)\n",
    "\n",
    "        print(f\"✅ Merged: {file}\")\n",
    "    except Exception as e:\n",
    "        print(f\" Error processing {file}: {e}\")\n",
    "\n",
    "# Save merged file\n",
    "output_path = os.path.join(save_path, 'Mbego_all_news_merged.csv')\n",
    "merged_news_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\n✅ All News files merged and saved to '{output_path}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e93497b",
   "metadata": {},
   "source": [
    "##### reddit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fce7145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged: Agatha_reddit.csv\n",
      "✅ Merged: cecilia.redditsubs.csv\n",
      "✅ Merged: cecilia.reddit_nbo_ke_africa.csv\n",
      "✅ Merged: leo_reddit_posts.csv\n",
      "✅ Merged: Mbego_reddit_usaid_kenya.csv\n",
      "✅ Merged: Mbego_reddit_usaid_kenya2.csv\n",
      "✅ Merged: reddit_usaid_sentiment.csv\n",
      "✅ Merged: ruth_reddit.csv\n",
      "\n",
      "✅ All Reddit files merged and saved to 'N:\\Moringa\\afterM\\Leo NLP 004 USAID 01.06.2025\\USAID-Kenya-Sentiment-Analysis\\data\\processed\\mbego_all_reddit_merged.csv'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define paths\n",
    "folder_path = r'N:\\Moringa\\afterM\\Leo NLP 004 USAID 01.06.2025\\USAID-Kenya-Sentiment-Analysis\\data\\raw\\reddit_data'\n",
    "save_path = r'N:\\Moringa\\afterM\\Leo NLP 004 USAID 01.06.2025\\USAID-Kenya-Sentiment-Analysis\\data\\processed'\n",
    "\n",
    "# Define standard columns\n",
    "standard_cols = [\n",
    "    'title', 'selftext', 'subreddit', 'author', 'created_utc',\n",
    "    'created_date', 'score', 'num_comments', 'keyword', 'search_term',\n",
    "    'date_posted', 'upvotes', 'comments', 'url', 'permalink'\n",
    "]\n",
    "\n",
    "# Initialize master DataFrame\n",
    "merged_df = pd.DataFrame(columns=standard_cols)\n",
    "\n",
    "# Get all CSV files in folder\n",
    "reddit_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# Loop through each CSV file\n",
    "for file in reddit_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Drop any unnamed index column\n",
    "        if 'Unnamed: 0' in df.columns:\n",
    "            df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "        # Rename common variations\n",
    "        df.rename(columns={\n",
    "            'text': 'selftext',\n",
    "            'created': 'created_utc'\n",
    "        }, inplace=True)\n",
    "\n",
    "        # Add missing columns as empty (NA)\n",
    "        for col in standard_cols:\n",
    "            if col not in df.columns:\n",
    "                df[col] = pd.NA\n",
    "\n",
    "        # Reorder columns to match standard\n",
    "        df = df[standard_cols]\n",
    "\n",
    "        # Append to the master DataFrame\n",
    "        merged_df = pd.concat([merged_df, df], ignore_index=True)\n",
    "\n",
    "        print(f\"✅ Merged: {file}\")\n",
    "    except Exception as e:\n",
    "        print(f\" Error processing {file}: {e}\")\n",
    "\n",
    "# Save merged result\n",
    "output_file = os.path.join(save_path, 'mbego_all_reddit_merged.csv')\n",
    "merged_df.to_csv(output_file, index=False)\n",
    "print(f\"\\n✅ All Reddit files merged and saved to '{output_file}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b314281",
   "metadata": {},
   "source": [
    "#### Data Understanding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42d7b09e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>source</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>content</th>\n",
       "      <th>summary</th>\n",
       "      <th>full_text</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>url</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>usaid kenya</td>\n",
       "      <td>Al Jazeera English</td>\n",
       "      <td>Al Jazeera</td>\n",
       "      <td>Has DOGE really saved the US government $180bn?</td>\n",
       "      <td>Elon Musk first claimed the department would m...</td>\n",
       "      <td>President Donald Trump and adviser Elon Musk c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-06-06T11:21:51Z</td>\n",
       "      <td>https://www.aljazeera.com/news/2025/6/6/has-do...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>usaid kenya</td>\n",
       "      <td>CleanTechnica</td>\n",
       "      <td>Guest Contributor</td>\n",
       "      <td>The Life Story of Ecomobilus Technologies Limi...</td>\n",
       "      <td>By Prof Geoffrey Gitau Here is a story showcas...</td>\n",
       "      <td>By Prof Geoffrey Gitau\\r\\nHere is a story show...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-05-26T17:13:41Z</td>\n",
       "      <td>https://cleantechnica.com/2025/05/26/the-life-...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>usaid kenya</td>\n",
       "      <td>ProPublica</td>\n",
       "      <td>by Brett Murphy and Anna Maria Barry-Jester</td>\n",
       "      <td>Death, Sexual Violence and Human Trafficking: ...</td>\n",
       "      <td>by Brett Murphy and Anna Maria Barry-Jester \\n...</td>\n",
       "      <td>ProPublica is a nonprofit newsroom that invest...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-05-28T18:45:00Z</td>\n",
       "      <td>https://www.propublica.org/article/trump-usaid...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       keyword              source  \\\n",
       "0  usaid kenya  Al Jazeera English   \n",
       "1  usaid kenya       CleanTechnica   \n",
       "2  usaid kenya          ProPublica   \n",
       "\n",
       "                                        author  \\\n",
       "0                                   Al Jazeera   \n",
       "1                            Guest Contributor   \n",
       "2  by Brett Murphy and Anna Maria Barry-Jester   \n",
       "\n",
       "                                               title  \\\n",
       "0    Has DOGE really saved the US government $180bn?   \n",
       "1  The Life Story of Ecomobilus Technologies Limi...   \n",
       "2  Death, Sexual Violence and Human Trafficking: ...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Elon Musk first claimed the department would m...   \n",
       "1  By Prof Geoffrey Gitau Here is a story showcas...   \n",
       "2  by Brett Murphy and Anna Maria Barry-Jester \\n...   \n",
       "\n",
       "                                             content summary full_text  \\\n",
       "0  President Donald Trump and adviser Elon Musk c...     NaN       NaN   \n",
       "1  By Prof Geoffrey Gitau\\r\\nHere is a story show...     NaN       NaN   \n",
       "2  ProPublica is a nonprofit newsroom that invest...     NaN       NaN   \n",
       "\n",
       "            publishedAt                                                url  \\\n",
       "0  2025-06-06T11:21:51Z  https://www.aljazeera.com/news/2025/6/6/has-do...   \n",
       "1  2025-05-26T17:13:41Z  https://cleantechnica.com/2025/05/26/the-life-...   \n",
       "2  2025-05-28T18:45:00Z  https://www.propublica.org/article/trump-usaid...   \n",
       "\n",
       "  language  \n",
       "0      NaN  \n",
       "1      NaN  \n",
       "2      NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "news_merged_path = r\"N:\\Moringa\\afterM\\Leo NLP 004 USAID 01.06.2025\\USAID-Kenya-Sentiment-Analysis\\data\\processed\\Mbego_all_news_merged.csv\"\n",
    "\n",
    "news_df = pd.read_csv(news_merged_path)\n",
    "\n",
    "news_df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7536852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>created_date</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>keyword</th>\n",
       "      <th>search_term</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>comments</th>\n",
       "      <th>url</th>\n",
       "      <th>permalink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USAID left a month ago, do we have ARVs in Kenya?</td>\n",
       "      <td>Someone on a different group (different websit...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>muerki</td>\n",
       "      <td>2025-04-15 13:16:53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>usaid kenya</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/Kenya/comments/1jzrn2...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Classism in r/Kenya and r/nairobi</td>\n",
       "      <td>The classism I'm seeing in both subs is a good...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Morio_anzenza</td>\n",
       "      <td>2025-04-07 04:21:12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>169.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>usaid kenya</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/Kenya/comments/1jtcvb...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EX-USAID people!! Let's talk</td>\n",
       "      <td>Are you still in contact with the organisation...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>vindtar</td>\n",
       "      <td>2025-04-05 19:09:10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>usaid kenya</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/Kenya/comments/1jsb14...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  USAID left a month ago, do we have ARVs in Kenya?   \n",
       "1                  Classism in r/Kenya and r/nairobi   \n",
       "2                       EX-USAID people!! Let's talk   \n",
       "\n",
       "                                            selftext subreddit         author  \\\n",
       "0  Someone on a different group (different websit...     Kenya         muerki   \n",
       "1  The classism I'm seeing in both subs is a good...     Kenya  Morio_anzenza   \n",
       "2  Are you still in contact with the organisation...     Kenya        vindtar   \n",
       "\n",
       "           created_utc created_date  score  num_comments      keyword  \\\n",
       "0  2025-04-15 13:16:53          NaN    3.0           5.0  usaid kenya   \n",
       "1  2025-04-07 04:21:12          NaN  169.0          95.0  usaid kenya   \n",
       "2  2025-04-05 19:09:10          NaN    2.0           2.0  usaid kenya   \n",
       "\n",
       "  search_term date_posted  upvotes  comments  \\\n",
       "0         NaN         NaN      NaN       NaN   \n",
       "1         NaN         NaN      NaN       NaN   \n",
       "2         NaN         NaN      NaN       NaN   \n",
       "\n",
       "                                                 url permalink  \n",
       "0  https://www.reddit.com/r/Kenya/comments/1jzrn2...       NaN  \n",
       "1  https://www.reddit.com/r/Kenya/comments/1jtcvb...       NaN  \n",
       "2  https://www.reddit.com/r/Kenya/comments/1jsb14...       NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "reddit_merged_path = r\"N:\\Moringa\\afterM\\Leo NLP 004 USAID 01.06.2025\\USAID-Kenya-Sentiment-Analysis\\data\\processed\\mbego_all_reddit_merged.csv\"\n",
    "\n",
    "reddit_df = pd.read_csv(reddit_merged_path)\n",
    "\n",
    "reddit_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4d01054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['keyword',\n",
       " 'source',\n",
       " 'author',\n",
       " 'title',\n",
       " 'description',\n",
       " 'content',\n",
       " 'summary',\n",
       " 'full_text',\n",
       " 'publishedAt',\n",
       " 'url',\n",
       " 'language']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "675eb69a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['title',\n",
       " 'selftext',\n",
       " 'subreddit',\n",
       " 'author',\n",
       " 'created_utc',\n",
       " 'created_date',\n",
       " 'score',\n",
       " 'num_comments',\n",
       " 'keyword',\n",
       " 'search_term',\n",
       " 'date_posted',\n",
       " 'upvotes',\n",
       " 'comments',\n",
       " 'url',\n",
       " 'permalink']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42559ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language\n",
       "en    248\n",
       "sw    248\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df['language'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dtascnce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
