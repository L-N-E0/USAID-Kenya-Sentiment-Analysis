{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69f35898",
   "metadata": {},
   "source": [
    "### USAUD FUNDING CUTS SENTIMENT ANALYSIS "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b33964",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b68823a",
   "metadata": {},
   "source": [
    ".....(light intro text)\n",
    ".....(TBD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b15690d",
   "metadata": {},
   "source": [
    "### Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b0c730",
   "metadata": {},
   "source": [
    "This is data preparation phase for the project. The dataset used here is compiled from two primary sources: Reddit (via web scraping) and NewsAPI (via API calls). Each contributor collected data independently from these platforms, targeting relevant topics for analysis. Below, we begin by importing the collected datasets, merging them, and performing initial cleaning steps to prepare the data for further exploration and modeling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c78cbe",
   "metadata": {},
   "source": [
    "#### Data Importation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd92f453",
   "metadata": {},
   "source": [
    "##### news_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5fbe550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in Agatha_news.csv:\n",
      "['keyword', 'source', 'author', 'title', 'description', 'content', 'publishedAt', 'url']\n",
      "--------------------------------------------------\n",
      "Columns in Agatha_news_fulltext.csv:\n",
      "['keyword', 'source', 'author', 'title', 'publishedAt', 'summary', 'text', 'url']\n",
      "--------------------------------------------------\n",
      "Columns in cecilia.newsapi.csv:\n",
      "['keyword', 'source', 'author', 'title', 'description', 'content', 'url', 'publishedAt', 'urlToImage']\n",
      "--------------------------------------------------\n",
      "Columns in leo_newsapi_articles_enriched.csv:\n",
      "['source', 'author', 'title', 'description', 'content', 'url', 'published_at', 'full_text']\n",
      "--------------------------------------------------\n",
      "Columns in Mbego_news_usaid_kenya_fulltext.csv:\n",
      "['source', 'author', 'title', 'description', 'url', 'publishedAt', 'summary', 'full_text']\n",
      "--------------------------------------------------\n",
      "Columns in Mbego_news_usaid_kenya_recent.csv:\n",
      "['source', 'author', 'title', 'description', 'url', 'publishedAt', 'content']\n",
      "--------------------------------------------------\n",
      "Columns in newsapi_usaid_articles.csv:\n",
      "['title', 'description', 'url', 'publishedAt', 'source', 'content']\n",
      "--------------------------------------------------\n",
      "Columns in ruth_news.csv:\n",
      "['Unnamed: 0', 'source', 'title', 'description', 'content', 'url', 'publishedAt']\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Set the path to your news_data folder\n",
    "folder_path = r'N:\\Moringa\\afterM\\Leo NLP 004 USAID 01.06.2025\\USAID-Kenya-Sentiment-Analysis\\data\\raw\\news_data'\n",
    "\n",
    "# List all CSV files in the folder\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# Read and display columns for each CSV file\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    try:\n",
    "        reddit_mbegoall_df = pd.read_csv(file_path, nrows=0)  # Read only headers\n",
    "        print(f\"Columns in {file}:\")\n",
    "        print(list(reddit_mbegoall_df.columns))\n",
    "        print(\"-\" * 50)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43cccdc",
   "metadata": {},
   "source": [
    "##### reddit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c6b954b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in Agatha_reddit.csv:\n",
      "['title', 'selftext', 'subreddit', 'author', 'created_utc', 'url', 'score', 'num_comments', 'keyword']\n",
      "--------------------------------------------------\n",
      "Columns in cecilia.redditsubs.csv:\n",
      "['subreddit', 'keyword', 'title', 'text', 'date_posted', 'upvotes', 'comments', 'url', 'permalink']\n",
      "--------------------------------------------------\n",
      "Columns in cecilia.reddit_nbo_ke_africa.csv:\n",
      "['subreddit', 'keyword', 'title', 'text', 'date_posted', 'upvotes', 'comments', 'url', 'permalink']\n",
      "--------------------------------------------------\n",
      "Columns in leo_reddit_posts.csv:\n",
      "['subreddit', 'search_term', 'title', 'text', 'created_utc', 'created_date', 'score', 'num_comments', 'permalink', 'url']\n",
      "--------------------------------------------------\n",
      "Columns in Mbego_reddit_usaid_kenya.csv:\n",
      "['title', 'score', 'url', 'created', 'subreddit', 'selftext']\n",
      "--------------------------------------------------\n",
      "Columns in Mbego_reddit_usaid_kenya2.csv:\n",
      "['title', 'score', 'url', 'created', 'subreddit', 'selftext']\n",
      "--------------------------------------------------\n",
      "Columns in reddit_usaid_kenya.csv:\n",
      "['title', 'score', 'url', 'created', 'subreddit', 'selftext']\n",
      "--------------------------------------------------\n",
      "Columns in reddit_usaid_sentiment.csv:\n",
      "['subreddit', 'title', 'score', 'url', 'created_utc', 'num_comments', 'selftext']\n",
      "--------------------------------------------------\n",
      "Columns in ruth_reddit.csv:\n",
      "['Unnamed: 0', 'subreddit', 'title', 'score', 'url', 'created_utc', 'num_comments', 'selftext']\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set the path to your news_data folder\n",
    "folder_path = r'N:\\Moringa\\afterM\\Leo NLP 004 USAID 01.06.2025\\USAID-Kenya-Sentiment-Analysis\\data\\raw\\reddit_data'\n",
    "\n",
    "# List all CSV files in the folder\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# Read and display columns for each CSV file\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    try:\n",
    "        reddit_mbegoall_df = pd.read_csv(file_path, nrows=0)  # Read only headers\n",
    "        print(f\"Columns in {file}:\")\n",
    "        print(list(reddit_mbegoall_df.columns))\n",
    "        print(\"-\" * 50)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f22927d",
   "metadata": {},
   "source": [
    "#### Data Merging "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9da281b",
   "metadata": {},
   "source": [
    "##### news_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6702b9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged: Agatha_news.csv\n",
      "✅ Merged: Agatha_news_fulltext.csv\n",
      "✅ Merged: cecilia.newsapi.csv\n",
      "✅ Merged: leo_newsapi_articles_enriched.csv\n",
      "✅ Merged: Mbego_news_usaid_kenya_fulltext.csv\n",
      "✅ Merged: Mbego_news_usaid_kenya_recent.csv\n",
      "✅ Merged: newsapi_usaid_articles.csv\n",
      "✅ Merged: ruth_news.csv\n",
      "\n",
      "✅ All News files merged and saved to 'N:\\Moringa\\afterM\\Leo NLP 004 USAID 01.06.2025\\USAID-Kenya-Sentiment-Analysis\\data\\processed\\individual datasets\\Mbego_all_news_merged.csv'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Folder containing all News CSVs\n",
    "folder_path = r'N:\\Moringa\\afterM\\Leo NLP 004 USAID 01.06.2025\\USAID-Kenya-Sentiment-Analysis\\data\\raw\\news_data'\n",
    "\n",
    "# Final save location\n",
    "save_path = r\"N:\\Moringa\\afterM\\Leo NLP 004 USAID 01.06.2025\\USAID-Kenya-Sentiment-Analysis\\data\\processed\\individual datasets\"\n",
    "\n",
    "# All .csv files in the news_data folder\n",
    "news_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# Define the final standardized columns\n",
    "standard_news_cols = [\n",
    "    'keyword', 'source', 'author', 'title', 'description', 'content',\n",
    "    'summary', 'full_text', 'publishedAt', 'url', 'language'\n",
    "]\n",
    "\n",
    "# Create empty master DataFrame\n",
    "merged_news_df = pd.DataFrame(columns=standard_news_cols)\n",
    "\n",
    "# Loop through each file\n",
    "for file in news_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    try:\n",
    "        reddit_mbegoall_df = pd.read_csv(file_path)\n",
    "\n",
    "        # Drop index column if present\n",
    "        if 'Unnamed: 0' in reddit_mbegoall_df.columns:\n",
    "            reddit_mbegoall_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "        # Standardize column names\n",
    "        reddit_mbegoall_df.rename(columns={\n",
    "            'published_at': 'publishedAt',\n",
    "            'published_date': 'publishedAt',\n",
    "            'text': 'content'\n",
    "        }, inplace=True)\n",
    "\n",
    "        # Add missing columns\n",
    "        for col in standard_news_cols:\n",
    "            if col not in reddit_mbegoall_df.columns:\n",
    "                reddit_mbegoall_df[col] = pd.NA\n",
    "\n",
    "        # Align column order\n",
    "        reddit_mbegoall_df = reddit_mbegoall_df[standard_news_cols]\n",
    "\n",
    "        # Add to master DataFrame\n",
    "        merged_news_df = pd.concat([merged_news_df, reddit_mbegoall_df], ignore_index=True)\n",
    "\n",
    "        print(f\"✅ Merged: {file}\")\n",
    "    except Exception as e:\n",
    "        print(f\" Error processing {file}: {e}\")\n",
    "\n",
    "# Save merged file\n",
    "output_path = os.path.join(save_path, 'Mbego_all_news_merged.csv')\n",
    "merged_news_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\n✅ All News files merged and saved to '{output_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b414361f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>source</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>content</th>\n",
       "      <th>summary</th>\n",
       "      <th>full_text</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>url</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>usaid kenya</td>\n",
       "      <td>Al Jazeera English</td>\n",
       "      <td>Al Jazeera</td>\n",
       "      <td>Has DOGE really saved the US government $180bn?</td>\n",
       "      <td>Elon Musk first claimed the department would m...</td>\n",
       "      <td>President Donald Trump and adviser Elon Musk c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-06-06T11:21:51Z</td>\n",
       "      <td>https://www.aljazeera.com/news/2025/6/6/has-do...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>usaid kenya</td>\n",
       "      <td>CleanTechnica</td>\n",
       "      <td>Guest Contributor</td>\n",
       "      <td>The Life Story of Ecomobilus Technologies Limi...</td>\n",
       "      <td>By Prof Geoffrey Gitau Here is a story showcas...</td>\n",
       "      <td>By Prof Geoffrey Gitau\\r\\nHere is a story show...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-05-26T17:13:41Z</td>\n",
       "      <td>https://cleantechnica.com/2025/05/26/the-life-...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>usaid kenya</td>\n",
       "      <td>ProPublica</td>\n",
       "      <td>by Brett Murphy and Anna Maria Barry-Jester</td>\n",
       "      <td>Death, Sexual Violence and Human Trafficking: ...</td>\n",
       "      <td>by Brett Murphy and Anna Maria Barry-Jester \\n...</td>\n",
       "      <td>ProPublica is a nonprofit newsroom that invest...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-05-28T18:45:00Z</td>\n",
       "      <td>https://www.propublica.org/article/trump-usaid...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       keyword              source  \\\n",
       "0  usaid kenya  Al Jazeera English   \n",
       "1  usaid kenya       CleanTechnica   \n",
       "2  usaid kenya          ProPublica   \n",
       "\n",
       "                                        author  \\\n",
       "0                                   Al Jazeera   \n",
       "1                            Guest Contributor   \n",
       "2  by Brett Murphy and Anna Maria Barry-Jester   \n",
       "\n",
       "                                               title  \\\n",
       "0    Has DOGE really saved the US government $180bn?   \n",
       "1  The Life Story of Ecomobilus Technologies Limi...   \n",
       "2  Death, Sexual Violence and Human Trafficking: ...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Elon Musk first claimed the department would m...   \n",
       "1  By Prof Geoffrey Gitau Here is a story showcas...   \n",
       "2  by Brett Murphy and Anna Maria Barry-Jester \\n...   \n",
       "\n",
       "                                             content summary full_text  \\\n",
       "0  President Donald Trump and adviser Elon Musk c...     NaN       NaN   \n",
       "1  By Prof Geoffrey Gitau\\r\\nHere is a story show...     NaN       NaN   \n",
       "2  ProPublica is a nonprofit newsroom that invest...     NaN       NaN   \n",
       "\n",
       "            publishedAt                                                url  \\\n",
       "0  2025-06-06T11:21:51Z  https://www.aljazeera.com/news/2025/6/6/has-do...   \n",
       "1  2025-05-26T17:13:41Z  https://cleantechnica.com/2025/05/26/the-life-...   \n",
       "2  2025-05-28T18:45:00Z  https://www.propublica.org/article/trump-usaid...   \n",
       "\n",
       "   language  \n",
       "0       NaN  \n",
       "1       NaN  \n",
       "2       NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "news_merged_path = r\"N:\\Moringa\\afterM\\Leo NLP 004 USAID 01.06.2025\\USAID-Kenya-Sentiment-Analysis\\data\\processed\\individual datasets\\Mbego_all_news_merged.csv\"\n",
    "\n",
    "news_mbegoall_df = pd.read_csv(news_merged_path)\n",
    "\n",
    "news_mbegoall_df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e93497b",
   "metadata": {},
   "source": [
    "##### reddit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fce7145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged: Agatha_reddit.csv\n",
      "✅ Merged: cecilia.redditsubs.csv\n",
      "✅ Merged: cecilia.reddit_nbo_ke_africa.csv\n",
      "✅ Merged: leo_reddit_posts.csv\n",
      "✅ Merged: Mbego_reddit_usaid_kenya.csv\n",
      "✅ Merged: Mbego_reddit_usaid_kenya2.csv\n",
      "✅ Merged: reddit_usaid_kenya.csv\n",
      "✅ Merged: reddit_usaid_sentiment.csv\n",
      "✅ Merged: ruth_reddit.csv\n",
      "\n",
      "✅ All Reddit files merged and saved to 'N:\\Moringa\\afterM\\Leo NLP 004 USAID 01.06.2025\\USAID-Kenya-Sentiment-Analysis\\data\\processed\\individual datasets\\mbego_all_reddit_merged.csv'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define paths\n",
    "folder_path = r'N:\\Moringa\\afterM\\Leo NLP 004 USAID 01.06.2025\\USAID-Kenya-Sentiment-Analysis\\data\\raw\\reddit_data'\n",
    "save_path = r'N:\\Moringa\\afterM\\Leo NLP 004 USAID 01.06.2025\\USAID-Kenya-Sentiment-Analysis\\data\\processed\\individual datasets'\n",
    "\n",
    "# Define standard columns\n",
    "standard_cols = [\n",
    "    'title', 'selftext', 'subreddit', 'author', 'created_utc',\n",
    "    'created_date', 'score', 'num_comments', 'keyword', 'search_term',\n",
    "    'date_posted', 'upvotes', 'comments', 'url', 'permalink'\n",
    "]\n",
    "\n",
    "# Initialize master DataFrame\n",
    "merged_df = pd.DataFrame(columns=standard_cols)\n",
    "\n",
    "# Get all CSV files in folder\n",
    "reddit_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# Loop through each CSV file\n",
    "for file in reddit_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    try:\n",
    "        reddit_mbegoall_df = pd.read_csv(file_path)\n",
    "\n",
    "        # Drop any unnamed index column\n",
    "        if 'Unnamed: 0' in reddit_mbegoall_df.columns:\n",
    "            reddit_mbegoall_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "        # Rename common variations\n",
    "        reddit_mbegoall_df.rename(columns={\n",
    "            'text': 'selftext',\n",
    "            'created': 'created_utc'\n",
    "        }, inplace=True)\n",
    "\n",
    "        # Add missing columns as empty (NA)\n",
    "        for col in standard_cols:\n",
    "            if col not in reddit_mbegoall_df.columns:\n",
    "                reddit_mbegoall_df[col] = pd.NA\n",
    "\n",
    "        # Reorder columns to match standard\n",
    "        reddit_mbegoall_df = reddit_mbegoall_df[standard_cols]\n",
    "\n",
    "        # Append to the master DataFrame\n",
    "        merged_df = pd.concat([merged_df, reddit_mbegoall_df], ignore_index=True)\n",
    "\n",
    "        print(f\"✅ Merged: {file}\")\n",
    "    except Exception as e:\n",
    "        print(f\" Error processing {file}: {e}\")\n",
    "\n",
    "# Save merged result\n",
    "output_file = os.path.join(save_path, 'mbego_all_reddit_merged.csv')\n",
    "merged_df.to_csv(output_file, index=False)\n",
    "print(f\"\\n✅ All Reddit files merged and saved to '{output_file}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7c67efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>created_date</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>keyword</th>\n",
       "      <th>search_term</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>comments</th>\n",
       "      <th>url</th>\n",
       "      <th>permalink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USAID left a month ago, do we have ARVs in Kenya?</td>\n",
       "      <td>Someone on a different group (different websit...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>muerki</td>\n",
       "      <td>2025-04-15 13:16:53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>usaid kenya</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/Kenya/comments/1jzrn2...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Classism in r/Kenya and r/nairobi</td>\n",
       "      <td>The classism I'm seeing in both subs is a good...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Morio_anzenza</td>\n",
       "      <td>2025-04-07 04:21:12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>169.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>usaid kenya</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/Kenya/comments/1jtcvb...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EX-USAID people!! Let's talk</td>\n",
       "      <td>Are you still in contact with the organisation...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>vindtar</td>\n",
       "      <td>2025-04-05 19:09:10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>usaid kenya</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/Kenya/comments/1jsb14...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  USAID left a month ago, do we have ARVs in Kenya?   \n",
       "1                  Classism in r/Kenya and r/nairobi   \n",
       "2                       EX-USAID people!! Let's talk   \n",
       "\n",
       "                                            selftext subreddit         author  \\\n",
       "0  Someone on a different group (different websit...     Kenya         muerki   \n",
       "1  The classism I'm seeing in both subs is a good...     Kenya  Morio_anzenza   \n",
       "2  Are you still in contact with the organisation...     Kenya        vindtar   \n",
       "\n",
       "           created_utc created_date  score  num_comments      keyword  \\\n",
       "0  2025-04-15 13:16:53          NaN    3.0           5.0  usaid kenya   \n",
       "1  2025-04-07 04:21:12          NaN  169.0          95.0  usaid kenya   \n",
       "2  2025-04-05 19:09:10          NaN    2.0           2.0  usaid kenya   \n",
       "\n",
       "  search_term date_posted  upvotes  comments  \\\n",
       "0         NaN         NaN      NaN       NaN   \n",
       "1         NaN         NaN      NaN       NaN   \n",
       "2         NaN         NaN      NaN       NaN   \n",
       "\n",
       "                                                 url permalink  \n",
       "0  https://www.reddit.com/r/Kenya/comments/1jzrn2...       NaN  \n",
       "1  https://www.reddit.com/r/Kenya/comments/1jtcvb...       NaN  \n",
       "2  https://www.reddit.com/r/Kenya/comments/1jsb14...       NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "reddit_merged_path = r\"N:\\Moringa\\afterM\\Leo NLP 004 USAID 01.06.2025\\USAID-Kenya-Sentiment-Analysis\\data\\processed\\individual datasets\\mbego_all_reddit_merged.csv\"\n",
    "\n",
    "reddit_mbegoall_df = pd.read_csv(reddit_merged_path)\n",
    "\n",
    "reddit_mbegoall_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb97fef",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b314281",
   "metadata": {},
   "source": [
    "#### Data Understanding "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4bcb57",
   "metadata": {},
   "source": [
    "##### News Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f287e1",
   "metadata": {},
   "source": [
    "Basic Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8b97ad94",
   "metadata": {},
   "outputs": [],
   "source": [
    "proccessed_final_path = r\"N:\\Moringa\\afterM\\Leo NLP 004 USAID 01.06.2025\\USAID-Kenya-Sentiment-Analysis\\data\\processed\\news_data\\news_data.csv\" \n",
    "\n",
    "news_df = pd.read_csv(proccessed_final_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3cddc290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>keyword</th>\n",
       "      <th>published_date</th>\n",
       "      <th>source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Has DOGE really saved the US government $180bn?</td>\n",
       "      <td>Elon Musk first claimed the department would m...</td>\n",
       "      <td>President Donald Trump and adviser Elon Musk c...</td>\n",
       "      <td>https://www.aljazeera.com/news/2025/6/6/has-do...</td>\n",
       "      <td>usaid kenya</td>\n",
       "      <td>2025-06-06</td>\n",
       "      <td>Agatha_news.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Life Story of Ecomobilus Technologies Limi...</td>\n",
       "      <td>By Prof Geoffrey Gitau Here is a story showcas...</td>\n",
       "      <td>By Prof Geoffrey Gitau\\r\\nHere is a story show...</td>\n",
       "      <td>https://cleantechnica.com/2025/05/26/the-life-...</td>\n",
       "      <td>usaid kenya</td>\n",
       "      <td>2025-05-26</td>\n",
       "      <td>Agatha_news.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Death, Sexual Violence and Human Trafficking: ...</td>\n",
       "      <td>by Brett Murphy and Anna Maria Barry-Jester \\n...</td>\n",
       "      <td>ProPublica is a nonprofit newsroom that invest...</td>\n",
       "      <td>https://www.propublica.org/article/trump-usaid...</td>\n",
       "      <td>usaid kenya</td>\n",
       "      <td>2025-05-28</td>\n",
       "      <td>Agatha_news.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Congress Should Quickly Approve Trump’s Rescis...</td>\n",
       "      <td>President Donald Trump‘s rescission legislatio...</td>\n",
       "      <td>President Donald Trumps rescission legislation...</td>\n",
       "      <td>https://www.dailysignal.com/2025/06/10/congres...</td>\n",
       "      <td>usaid kenya</td>\n",
       "      <td>2025-06-10</td>\n",
       "      <td>Agatha_news.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Food Safety Depends On Every Link In The Suppl...</td>\n",
       "      <td>Almost 1 in 10 people globally fall ill from c...</td>\n",
       "      <td>Colorful fish and vegetables can be purchased ...</td>\n",
       "      <td>https://www.forbes.com/sites/daniellenierenber...</td>\n",
       "      <td>usaid kenya</td>\n",
       "      <td>2025-06-06</td>\n",
       "      <td>Agatha_news.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0    Has DOGE really saved the US government $180bn?   \n",
       "1  The Life Story of Ecomobilus Technologies Limi...   \n",
       "2  Death, Sexual Violence and Human Trafficking: ...   \n",
       "3  Congress Should Quickly Approve Trump’s Rescis...   \n",
       "4  Food Safety Depends On Every Link In The Suppl...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Elon Musk first claimed the department would m...   \n",
       "1  By Prof Geoffrey Gitau Here is a story showcas...   \n",
       "2  by Brett Murphy and Anna Maria Barry-Jester \\n...   \n",
       "3  President Donald Trump‘s rescission legislatio...   \n",
       "4  Almost 1 in 10 people globally fall ill from c...   \n",
       "\n",
       "                                                text  \\\n",
       "0  President Donald Trump and adviser Elon Musk c...   \n",
       "1  By Prof Geoffrey Gitau\\r\\nHere is a story show...   \n",
       "2  ProPublica is a nonprofit newsroom that invest...   \n",
       "3  President Donald Trumps rescission legislation...   \n",
       "4  Colorful fish and vegetables can be purchased ...   \n",
       "\n",
       "                                                 url      keyword  \\\n",
       "0  https://www.aljazeera.com/news/2025/6/6/has-do...  usaid kenya   \n",
       "1  https://cleantechnica.com/2025/05/26/the-life-...  usaid kenya   \n",
       "2  https://www.propublica.org/article/trump-usaid...  usaid kenya   \n",
       "3  https://www.dailysignal.com/2025/06/10/congres...  usaid kenya   \n",
       "4  https://www.forbes.com/sites/daniellenierenber...  usaid kenya   \n",
       "\n",
       "  published_date      source_file  \n",
       "0     2025-06-06  Agatha_news.csv  \n",
       "1     2025-05-26  Agatha_news.csv  \n",
       "2     2025-05-28  Agatha_news.csv  \n",
       "3     2025-06-10  Agatha_news.csv  \n",
       "4     2025-06-06  Agatha_news.csv  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6728eeb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2549, 7)\n",
      "title             object\n",
      "description       object\n",
      "text              object\n",
      "url               object\n",
      "keyword           object\n",
      "published_date    object\n",
      "source_file       object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(news_df.shape)             # Rows and columns\n",
    "print(news_df.dtypes)           # Data types                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "44e8f1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = news_df.drop(columns= ['source_file','url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf4b0f2",
   "metadata": {},
   "source": [
    "Unique Values per Key Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "08e0aea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Sample keywords: ['usaid kenya' 'usaid funding' 'usaid budget cut' 'kenya foreign aid'\n",
      " 'usaid suspended funding']\n",
      "2. Unique text: 1401\n",
      "3. Unique description: 1411\n",
      "4. Unique title: 1410\n"
     ]
    }
   ],
   "source": [
    "print(\"1. Sample keywords:\", news_df['keyword'].dropna().unique()[:5])\n",
    "print(\"2. Unique text:\", news_df['text'].nunique())\n",
    "print(\"3. Unique description:\", news_df['description'].nunique())\n",
    "print(\"4. Unique title:\", news_df['title'].dropna().nunique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01467e8f",
   "metadata": {},
   "source": [
    "Date Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c09a5607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range: 2025-05-09 00:00:00 to 2025-06-23 00:00:00\n"
     ]
    }
   ],
   "source": [
    "news_df['published_date'] = pd.to_datetime(news_df['published_date'], errors='coerce')\n",
    "print(\"Date range:\", news_df['published_date'].min(), \"to\", news_df['published_date'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dfbcea",
   "metadata": {},
   "source": [
    "Sample Full Article Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "dad6de43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  title  \\\n",
      "1536  JUST IN: House Votes to Advance DOGE Cuts to N...   \n",
      "2088  Studies for breast cancer, ALS: Here are some ...   \n",
      "787   PBS sues Trump over funding cuts to public med...   \n",
      "\n",
      "                                            description  \\\n",
      "1536  The House of Representatives has advanced a $9...   \n",
      "2088  Grant terminations at Harvard have affected re...   \n",
      "787   PBS said in a lawsuit that the Trump administr...   \n",
      "\n",
      "                                                   text  \n",
      "1536  The House of Representatives has advanced a $9...  \n",
      "2088  Amid the Trump administration's battle with Ha...  \n",
      "787   PBS is taking the Trump administration to cour...  \n"
     ]
    }
   ],
   "source": [
    "sample = news_df[['title', 'description', 'text']].dropna().sample(3)\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38885d94",
   "metadata": {},
   "source": [
    "`Columns Importance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1efdeed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['title', 'description', 'text', 'keyword', 'published_date']\n"
     ]
    }
   ],
   "source": [
    "print(news_df.columns.tolist()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "eb98592a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#column_name:   brief info'\n",
    "\n",
    "# title:        Useful for headline analysis, summarization, keyword extraction, or sentiment approximation\n",
    "# description:  concise summary of the article\n",
    "# keyword:      metadata for filtering or guiding classification topics\n",
    "#*published_date:  Useful for temporal analysis, trend detection, or filtering by date (keeping at now if incase we tailor some visualizations as well)\n",
    "\n",
    "#missing after impt after group merge#\n",
    "# content:      Main body of the article. Crucial for any text-based NLP\n",
    "# source:       Helps identify bias or clustering by publisher; useful in framing analysis\n",
    "\n",
    "important_cols = ['title', 'description', 'published_date', 'text', 'keyword']\n",
    "news_df = news_df[important_cols] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f29d321",
   "metadata": {},
   "source": [
    "`Data cleaning (minor_ for quick cleaning)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b09882a",
   "metadata": {},
   "source": [
    "Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c20e8f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      " keyword           170\n",
      "published_date     99\n",
      "text               25\n",
      "description        16\n",
      "title               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing = news_df.isna().sum().sort_values(ascending=False)\n",
    "print(\"Missing values per column:\\n\", missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b7a3d3",
   "metadata": {},
   "source": [
    "Filling missing text columns with empty strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4b9da146",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df['text'] = news_df['text'].fillna('')\n",
    "news_df['description'] = news_df['description'].fillna('')\n",
    "news_df['keyword'] = news_df['keyword'].fillna('')\n",
    "\n",
    "# Drop rows where published_date is missing (NaT)\n",
    "news_df = news_df.dropna(subset=['published_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64d8967",
   "metadata": {},
   "source": [
    "creating a new column to enrich NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ca5fafb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the new combined column\n",
    "news_df['news_content'] = news_df['description'] + ' ' + news_df['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b48915",
   "metadata": {},
   "source": [
    "drop the two merged columns and retain new column `news_content`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "08f9272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = news_df.drop(columns=['text','description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e2be95",
   "metadata": {},
   "source": [
    "> TBD on news data begin from cell blocks before this so after this is the last step and it is pre included as it is important for data viewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0c7ada36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>published_date</th>\n",
       "      <th>keyword</th>\n",
       "      <th>news_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Has DOGE really saved the US government $180bn?</td>\n",
       "      <td>2025-06-06</td>\n",
       "      <td>usaid kenya</td>\n",
       "      <td>Elon Musk first claimed the department would m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Life Story of Ecomobilus Technologies Limi...</td>\n",
       "      <td>2025-05-26</td>\n",
       "      <td>usaid kenya</td>\n",
       "      <td>By Prof Geoffrey Gitau Here is a story showcas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Death, Sexual Violence and Human Trafficking: ...</td>\n",
       "      <td>2025-05-28</td>\n",
       "      <td>usaid kenya</td>\n",
       "      <td>by Brett Murphy and Anna Maria Barry-Jester \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Congress Should Quickly Approve Trump’s Rescis...</td>\n",
       "      <td>2025-06-10</td>\n",
       "      <td>usaid kenya</td>\n",
       "      <td>President Donald Trump‘s rescission legislatio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title published_date  \\\n",
       "0    Has DOGE really saved the US government $180bn?     2025-06-06   \n",
       "1  The Life Story of Ecomobilus Technologies Limi...     2025-05-26   \n",
       "2  Death, Sexual Violence and Human Trafficking: ...     2025-05-28   \n",
       "3  Congress Should Quickly Approve Trump’s Rescis...     2025-06-10   \n",
       "\n",
       "       keyword                                       news_content  \n",
       "0  usaid kenya  Elon Musk first claimed the department would m...  \n",
       "1  usaid kenya  By Prof Geoffrey Gitau Here is a story showcas...  \n",
       "2  usaid kenya  by Brett Murphy and Anna Maria Barry-Jester \\n...  \n",
       "3  usaid kenya  President Donald Trump‘s rescission legislatio...  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#assign my data to avoid re_runs\n",
    "temp_clean_newsdata = news_df\n",
    "temp_clean_newsdata.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274873fc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382cc9bc",
   "metadata": {},
   "source": [
    "##### Reddit Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee533ae",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6638882b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['title', 'selftext', 'subreddit', 'author', 'created_utc', 'created_date', 'score', 'num_comments', 'keyword', 'search_term', 'date_posted', 'upvotes', 'comments', 'url', 'permalink']\n"
     ]
    }
   ],
   "source": [
    "print(reddit_mbegoall_df.columns.tolist()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab1e954",
   "metadata": {},
   "source": [
    "Drop unneeded columns for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539671b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining columns:\n",
      "Index(['title', 'selftext', 'subreddit', 'score', 'num_comments', 'keyword',\n",
      "       'search_term', 'comments'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "columns_to_drop = ['created_utc', 'date_posted', 'upvotes', 'url', 'permalink', 'author','created_date']\n",
    "reddit_mbegoall_df = reddit_mbegoall_df.drop(columns=columns_to_drop, errors='ignore')  # errors='ignore' ensures it won’t crash if a column is missing\n",
    "\n",
    "#remaining columns\n",
    "print(\"Remaining columns:\")\n",
    "print(reddit_mbegoall_df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ed6eec",
   "metadata": {},
   "source": [
    "Null values check to determine how handle for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9957efd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "search_term     1156\n",
       "comments        1030\n",
       "keyword          564\n",
       "num_comments     473\n",
       "selftext         398\n",
       "score            276\n",
       "title              0\n",
       "subreddit          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_mbegoall_df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df19b4e7",
   "metadata": {},
   "source": [
    "Cleaning Code for null values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105f2af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where 'created_date' is missing\n",
    "#reddit_df = reddit_df.dropna(subset=['created_date'])\n",
    "\n",
    "# Drop 'search_term' if not needed\n",
    "reddit_mbegoall_df = reddit_mbegoall_df.drop(columns=['search_term'], errors='ignore')\n",
    "\n",
    "# Fill missing text fields with empty strings\n",
    "reddit_mbegoall_df['selftext'] = reddit_mbegoall_df['selftext'].fillna('')\n",
    "reddit_mbegoall_df['comments'] = reddit_mbegoall_df['comments'].fillna('')\n",
    "\n",
    "# Fill numeric fields with 0\n",
    "reddit_mbegoall_df['score'] = reddit_mbegoall_df['score'].fillna(0)\n",
    "reddit_mbegoall_df['num_comments'] = reddit_mbegoall_df['num_comments'].fillna(0)\n",
    "\n",
    "# Fill missing 'keyword' with 'subreddit' before dropping subreddit\n",
    "reddit_mbegoall_df['keyword'] = reddit_mbegoall_df['keyword'].fillna(reddit_mbegoall_df['subreddit'])\n",
    "\n",
    "# Normalize 'keyword' by stripping whitespace and lowercasing\n",
    "reddit_mbegoall_df['keyword'] = reddit_mbegoall_df['keyword'].str.strip().str.lower()\n",
    "\n",
    "# Drop 'subreddit' since it's now redundant\n",
    "reddit_mbegoall_df = reddit_mbegoall_df.drop(columns=['subreddit'], errors='ignore')\n",
    "\n",
    "# Create unified text field for NLP modeling\n",
    "reddit_mbegoall_df['full_text'] = reddit_mbegoall_df['title'] + ' ' + reddit_mbegoall_df['selftext']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4fec5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keyword          31\n",
       "comments         77\n",
       "num_comments    112\n",
       "score           238\n",
       "selftext        544\n",
       "title           828\n",
       "full_text       833\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_mbegoall_df.nunique().sort_values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c156d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>keyword</th>\n",
       "      <th>comments</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>Weekly Sub-Saharan Africa Security Situation a...</td>\n",
       "      <td>#Somalia 🇸🇴\\r\\n#Sudan 🇸🇩\\r\\nDemocratic Republi...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>africa</td>\n",
       "      <td></td>\n",
       "      <td>Weekly Sub-Saharan Africa Security Situation a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>No evidence that Burkina Faso paid off all its...</td>\n",
       "      <td></td>\n",
       "      <td>52.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>africa</td>\n",
       "      <td></td>\n",
       "      <td>No evidence that Burkina Faso paid off all its...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>Ghana orders foreigners to exit gold market by...</td>\n",
       "      <td>Ghana has ordered foreigners to exit its gold ...</td>\n",
       "      <td>101.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>africa</td>\n",
       "      <td></td>\n",
       "      <td>Ghana orders foreigners to exit gold market by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>Unending Frustration Regarding Sudan War.</td>\n",
       "      <td>https://www.reuters.com/world/britain-boosts-a...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>africa</td>\n",
       "      <td></td>\n",
       "      <td>Unending Frustration Regarding Sudan War. http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>Tanzania's Authoritarian Government Has Just B...</td>\n",
       "      <td>Tanzania's main opposition party has been barr...</td>\n",
       "      <td>52.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>africa</td>\n",
       "      <td></td>\n",
       "      <td>Tanzania's Authoritarian Government Has Just B...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "1301  Weekly Sub-Saharan Africa Security Situation a...   \n",
       "1302  No evidence that Burkina Faso paid off all its...   \n",
       "1303  Ghana orders foreigners to exit gold market by...   \n",
       "1304          Unending Frustration Regarding Sudan War.   \n",
       "1305  Tanzania's Authoritarian Government Has Just B...   \n",
       "\n",
       "                                               selftext  score  num_comments  \\\n",
       "1301  #Somalia 🇸🇴\\r\\n#Sudan 🇸🇩\\r\\nDemocratic Republi...    3.0           2.0   \n",
       "1302                                                      52.0          25.0   \n",
       "1303  Ghana has ordered foreigners to exit its gold ...  101.0          12.0   \n",
       "1304  https://www.reuters.com/world/britain-boosts-a...   11.0           8.0   \n",
       "1305  Tanzania's main opposition party has been barr...   52.0          14.0   \n",
       "\n",
       "     keyword comments                                          full_text  \n",
       "1301  africa           Weekly Sub-Saharan Africa Security Situation a...  \n",
       "1302  africa           No evidence that Burkina Faso paid off all its...  \n",
       "1303  africa           Ghana orders foreigners to exit gold market by...  \n",
       "1304  africa           Unending Frustration Regarding Sudan War. http...  \n",
       "1305  africa           Tanzania's Authoritarian Government Has Just B...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_mbegoall_df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd09237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1306, 7)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_mbegoall_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcba6dc",
   "metadata": {},
   "source": [
    "Top 20 most frequent keywords (after normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98cf151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keyword\n",
       "kenya                                   342\n",
       "foreign aid, foreign aid                157\n",
       "worldnews                               138\n",
       "usaid kenya funding cut                 129\n",
       "kenya foreign aid                       105\n",
       "development aid kenya                    99\n",
       "africa                                   81\n",
       "usaid                                    66\n",
       "kenya donor funding                      56\n",
       "usaid budget cut                         27\n",
       "usaid, foreign aid, foreign aid          24\n",
       "usaid suspended funding                  22\n",
       "usaid funding                            18\n",
       "usaid kenya                              10\n",
       "aid withdrawal                            3\n",
       "usaid, usaid money, donors, ngos          3\n",
       "foreign aid, foreign aid, trump cuts      3\n",
       "usaid, usaid money                        3\n",
       "internationaldev                          3\n",
       "usaid, ngos                               2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_mbegoall_df['keyword'].value_counts().head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b232743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['title', 'description', 'content', 'publishedAt', 'source', 'language', 'keyword']\n"
     ]
    }
   ],
   "source": [
    "print(news_df.columns.tolist()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c388ad5e",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dtascnce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
