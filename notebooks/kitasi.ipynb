{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb4b5d20",
   "metadata": {},
   "source": [
    "# USAID FUNDING SENTIMENTAL ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51b6eb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: praw in c:\\users\\ahb\\anaconda3\\lib\\site-packages (7.8.1)\n",
      "Requirement already satisfied: prawcore<3,>=2.4 in c:\\users\\ahb\\anaconda3\\lib\\site-packages (from praw) (2.4.0)\n",
      "Requirement already satisfied: update_checker>=0.18 in c:\\users\\ahb\\anaconda3\\lib\\site-packages (from praw) (0.18.0)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in c:\\users\\ahb\\anaconda3\\lib\\site-packages (from praw) (0.58.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in c:\\users\\ahb\\anaconda3\\lib\\site-packages (from prawcore<3,>=2.4->praw) (2.31.0)\n",
      "Requirement already satisfied: six in c:\\users\\ahb\\anaconda3\\lib\\site-packages (from websocket-client>=0.54.0->praw) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ahb\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ahb\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ahb\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ahb\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install praw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b933cc7",
   "metadata": {},
   "source": [
    "# Reddit API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fb3fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching new posts from r/Kenya\n",
      "Fetching new posts from r/Africa\n",
      "Fetching new posts from r/EastAfrica\n",
      "Saved 101 matching posts to CSV.\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "# Reddit API credentials\n",
    "reddit = praw.Reddit(\n",
    "    client_id='-mmdTmkFnUV80NGQv0l-Yw',\n",
    "    client_secret='B6id7sl16V2HDuHX6aeTuGiQ2eDGLw',\n",
    "    user_agent='Ill-Chocolate-4761'\n",
    ")\n",
    "\n",
    "subreddits = ['Kenya', 'Africa', 'EastAfrica']\n",
    "queries = [\n",
    "    \"USAID\", \"funding\", \"donor\", \"health\",\n",
    "    \"development\", \"foreign aid\", \"aid\"\n",
    "]\n",
    "\n",
    "data = []\n",
    "\n",
    "# Loop through subreddits and collect matching posts\n",
    "for sub in subreddits:\n",
    "    subreddit = reddit.subreddit(sub)\n",
    "    print(f\"Fetching new posts from r/{sub}\")\n",
    "    for post in subreddit.new(limit=1000):  # Try fetching 1000 to filter from\n",
    "        post_text = f\"{post.title} {post.selftext}\".lower()\n",
    "        if any(q.lower() in post_text for q in queries):\n",
    "            data.append({\n",
    "                'subreddit': sub,\n",
    "                'title': post.title,\n",
    "                'score': post.score,\n",
    "                'url': post.url,\n",
    "                'created_utc': datetime.utcfromtimestamp(post.created_utc).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                'num_comments': post.num_comments,\n",
    "                'selftext': post.selftext\n",
    "            })\n",
    "        if len(data) >= 100:\n",
    "            break  # Stop after collecting 100 matches\n",
    "\n",
    "# Create DataFrame and save\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('reddit_usaid_sentiment_sample.csv', index=False)\n",
    "print(f\"Saved {len(df)} matching posts to CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6c166ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>url</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>Have You Tried Healix AI? A Cool New Tool to O...</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.reddit.com/gallery/1ld84b5</td>\n",
       "      <td>2025-06-16 23:28:51</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey Kenya! ðŸ‡°ðŸ‡ª\\n\\nIâ€™ve recently been using an A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>What is an unwritten rule that everyone should...</td>\n",
       "      <td>5</td>\n",
       "      <td>https://www.reddit.com/r/Kenya/comments/1ld51s...</td>\n",
       "      <td>2025-06-16 21:18:34</td>\n",
       "      <td>2</td>\n",
       "      <td>For me:\\n\\nAlways do what you say you are goin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>It's complicated but I still can't leave.</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.reddit.com/r/Kenya/comments/1ld4ar...</td>\n",
       "      <td>2025-06-16 20:49:23</td>\n",
       "      <td>4</td>\n",
       "      <td>This guy has been our regular at my place of w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>Car rental</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.reddit.com/r/Kenya/comments/1ld195...</td>\n",
       "      <td>2025-06-16 18:51:24</td>\n",
       "      <td>5</td>\n",
       "      <td>My friends and I will be renting two cars in N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>Ex girlfriends</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.reddit.com/r/Kenya/s/S90oI4ryOp</td>\n",
       "      <td>2025-06-16 18:25:00</td>\n",
       "      <td>4</td>\n",
       "      <td>Last time i talked here about an ex gf who wan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit                                              title  score  \\\n",
       "0     Kenya  Have You Tried Healix AI? A Cool New Tool to O...      1   \n",
       "1     Kenya  What is an unwritten rule that everyone should...      5   \n",
       "2     Kenya          It's complicated but I still can't leave.      1   \n",
       "3     Kenya                                         Car rental      2   \n",
       "4     Kenya                                     Ex girlfriends      2   \n",
       "\n",
       "                                                 url          created_utc  \\\n",
       "0             https://www.reddit.com/gallery/1ld84b5  2025-06-16 23:28:51   \n",
       "1  https://www.reddit.com/r/Kenya/comments/1ld51s...  2025-06-16 21:18:34   \n",
       "2  https://www.reddit.com/r/Kenya/comments/1ld4ar...  2025-06-16 20:49:23   \n",
       "3  https://www.reddit.com/r/Kenya/comments/1ld195...  2025-06-16 18:51:24   \n",
       "4        https://www.reddit.com/r/Kenya/s/S90oI4ryOp  2025-06-16 18:25:00   \n",
       "\n",
       "   num_comments                                           selftext  \n",
       "0             0  Hey Kenya! ðŸ‡°ðŸ‡ª\\n\\nIâ€™ve recently been using an A...  \n",
       "1             2  For me:\\n\\nAlways do what you say you are goin...  \n",
       "2             4  This guy has been our regular at my place of w...  \n",
       "3             5  My friends and I will be renting two cars in N...  \n",
       "4             4  Last time i talked here about an ex gf who wan...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1179cf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(r\"C:\\Users\\AHB\\Desktop\\my_quick_acess\\3.Projects\\projects pipeline\\2025\\USAID-Kenya-Sentiment-Analysis\\data\\reddit_kitasi2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1d09d7",
   "metadata": {},
   "source": [
    "# Extracting data from News API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d34de72",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34b5863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Your API Key\n",
    "api_key = '4ee66544d2954e7facf1b04e48b55ee3'  # Replace with your NewsAPI key\n",
    "\n",
    "# Query Parameters\n",
    "query = 'USAID Kenya funding'\n",
    "url = f'https://newsapi.org/v2/everything?q={query}&language=en&sortBy=publishedAt&pageSize=100&apiKey={api_key}'\n",
    "\n",
    "# Make request\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "# Convert to DataFrame\n",
    "articles = data['articles']\n",
    "\n",
    "df_news = pd.DataFrame([{\n",
    "    'source': article['source']['name'],\n",
    "    'title': article['title'],\n",
    "    'description': article['description'],\n",
    "    'content': article['content'],\n",
    "    'url': article['url'],\n",
    "    'publishedAt': article['publishedAt']\n",
    "} for article in articles])\n",
    "\n",
    "# Show sample data\n",
    "df_news.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c0d696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_news.to_csv(r\"C:\\Users\\AHB\\Desktop\\my_quick_acess\\3.Projects\\projects pipeline\\2025\\USAID-Kenya-Sentiment-Analysis\\data\\news_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
