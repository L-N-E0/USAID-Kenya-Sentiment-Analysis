{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "942c2a9a",
   "metadata": {},
   "source": [
    "# USAID FUNDING SENTIMENTAL ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ede6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# agatha_r = pd.read_csv(r'C:\\Users\\AHB\\Desktop\\my_quick_acess\\3.Projects\\projects pipeline\\2025\\USAID-Kenya-Sentiment-Analysis\\data\\raw\\Agatha_reddit.csv')\n",
    "# cecil1_r = pd.read_csv(r'C:\\Users\\AHB\\Desktop\\my_quick_acess\\3.Projects\\projects pipeline\\2025\\USAID-Kenya-Sentiment-Analysis\\data\\raw\\cecilia.reddit_nbo_ke_africa.csv')\n",
    "# cecil2_r = pd.read_csv(r'C:\\Users\\AHB\\Desktop\\my_quick_acess\\3.Projects\\projects pipeline\\2025\\USAID-Kenya-Sentiment-Analysis\\data\\raw\\cecilia.redditsubs.csv')\n",
    "# leonad_r = pd.read_csv(r'C:\\Users\\AHB\\Desktop\\my_quick_acess\\3.Projects\\projects pipeline\\2025\\USAID-Kenya-Sentiment-Analysis\\data\\raw\\leo_reddit_posts.csv')\n",
    "# john1_r = pd.read_csv(r'C:\\Users\\AHB\\Desktop\\my_quick_acess\\3.Projects\\projects pipeline\\2025\\USAID-Kenya-Sentiment-Analysis\\data\\raw\\Mbego_reddit_usaid_kenya.csv')\n",
    "# john2_r = pd.read_csv(r'C:\\Users\\AHB\\Desktop\\my_quick_acess\\3.Projects\\projects pipeline\\2025\\USAID-Kenya-Sentiment-Analysis\\data\\raw\\Mbego_reddit_usaid_kenya2.csv')\n",
    "# ruth_r = pd.read_csv(r'C:\\Users\\AHB\\Desktop\\my_quick_acess\\3.Projects\\projects pipeline\\2025\\USAID-Kenya-Sentiment-Analysis\\data\\raw\\ruth_reddit.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ddccc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "base_path = r'C:\\Users\\AHB\\Desktop\\my_quick_acess\\3.Projects\\projects pipeline\\2025\\USAID-Kenya-Sentiment-Analysis\\data\\raw'\n",
    "\n",
    "agatha_r = pd.read_csv(f'{base_path}\\\\Agatha_reddit.csv')\n",
    "cecil1_r = pd.read_csv(f'{base_path}\\\\cecilia.reddit_nbo_ke_africa.csv')\n",
    "cecil2_r = pd.read_csv(f'{base_path}\\\\cecilia.redditsubs.csv')\n",
    "leonad_r = pd.read_csv(f'{base_path}\\\\leo_reddit_posts.csv')\n",
    "john1_r = pd.read_csv(f'{base_path}\\\\Mbego_reddit_usaid_kenya.csv')\n",
    "john2_r = pd.read_csv(f'{base_path}\\\\Mbego_reddit_usaid_kenya2.csv')\n",
    "ruth_r = pd.read_csv(f'{base_path}\\\\ruth_reddit.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "118da580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agatha_reddit: (466, 9)\n",
      "cecilia.reddit_nbo_ke_africa: (29, 9)\n",
      "cecilia.redditsubs: (251, 9)\n",
      "leo_reddit_posts: (150, 10)\n",
      "Mbego_reddit_usaid_kenya: (17, 6)\n",
      "Mbego_reddit_usaid_kenya2: (163, 6)\n",
      "ruth_reddit: (200, 8)\n"
     ]
    }
   ],
   "source": [
    "# Put your DataFrames in a dictionary\n",
    "datasets = {\n",
    "    'Agatha_reddit': agatha_r,\n",
    "    'cecilia.reddit_nbo_ke_africa': cecil1_r,\n",
    "    'cecilia.redditsubs': cecil2_r,\n",
    "    'leo_reddit_posts': leonad_r,\n",
    "    'Mbego_reddit_usaid_kenya': john1_r,\n",
    "    'Mbego_reddit_usaid_kenya2': john2_r,\n",
    "    'ruth_reddit': ruth_r\n",
    "}\n",
    "\n",
    "# Loop through and print the shape of each\n",
    "for name, df in datasets.items():\n",
    "    print(f\"{name}: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b71fb2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agatha_reddit: Index(['title', 'selftext', 'subreddit', 'author', 'created_utc', 'url',\n",
      "       'score', 'num_comments', 'keyword'],\n",
      "      dtype='object')\n",
      "cecilia.reddit_nbo_ke_africa: Index(['subreddit', 'keyword', 'title', 'text', 'date_posted', 'upvotes',\n",
      "       'comments', 'url', 'permalink'],\n",
      "      dtype='object')\n",
      "cecilia.redditsubs: Index(['subreddit', 'keyword', 'title', 'text', 'date_posted', 'upvotes',\n",
      "       'comments', 'url', 'permalink'],\n",
      "      dtype='object')\n",
      "leo_reddit_posts: Index(['subreddit', 'search_term', 'title', 'text', 'created_utc',\n",
      "       'created_date', 'score', 'num_comments', 'permalink', 'url'],\n",
      "      dtype='object')\n",
      "Mbego_reddit_usaid_kenya: Index(['title', 'score', 'url', 'created', 'subreddit', 'selftext'], dtype='object')\n",
      "Mbego_reddit_usaid_kenya2: Index(['title', 'score', 'url', 'created', 'subreddit', 'selftext'], dtype='object')\n",
      "ruth_reddit: Index(['Unnamed: 0', 'subreddit', 'title', 'score', 'url', 'created_utc',\n",
      "       'num_comments', 'selftext'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Loop through and print the column of each\n",
    "for name, df in datasets.items():\n",
    "    print(f\"{name}: {df.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb0551f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge files"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
